{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/75d694db9b7db389904430eaaee4cfe3f9d592e9", "commit_message": "core: optimize generated connection matching a bit\n\nDo a quick check to see if the connetion is compatible with the device\nbefore we start doing a relatively heavy connection comparison.", "code_diff": "@@ -1755,18 +1755,22 @@ get_existing_connection (NMManager *manager, NMDevice *device)\n \tfor (iter = connections; iter; iter = iter->next) {\n \t\tNMConnection *candidate = NM_CONNECTION (iter->data);\n \n-\t\tif (nm_connection_compare (connection, candidate, NM_SETTING_COMPARE_FLAG_INFERRABLE)) {\n-\t\t\tnm_log_info (LOGD_DEVICE, \"(%s): found matching connection '%s'\",\n-\t\t\t\t\t\t nm_device_get_iface (device),\n-\t\t\t\t\t\t nm_connection_get_id (candidate));\n-\t\t\tg_object_unref (connection);\n-\t\t\treturn candidate;\n-\t\t}\n+\t\tif (!nm_device_check_connection_compatible (device, candidate, NULL))\n+\t\t\tcontinue;\n+\n+\t\tif (!nm_connection_compare (connection, candidate, NM_SETTING_COMPARE_FLAG_INFERRABLE))\n+\t\t\tcontinue;\n+\n+\t\tnm_log_info (LOGD_DEVICE, \"(%s): found matching connection '%s'\",\n+\t\t             nm_device_get_iface (device),\n+\t\t             nm_connection_get_id (candidate));\n+\t\tg_object_unref (connection);\n+\t\treturn candidate;\n \t}\n \n \tnm_log_dbg (LOGD_DEVICE, \"(%s): generated connection '%s'\",\n-\t\t\t\tnm_device_get_iface (device),\n-\t\t\t\tnm_connection_get_id (connection));\n+\t            nm_device_get_iface (device),\n+\t            nm_connection_get_id (connection));\n \n \tadded = nm_settings_add_connection (priv->settings, connection, FALSE, &error);\n \tif (!added) {\n", "changed_method_name": "get_existing_connection"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/fedf7ca3034ed3708b8fb11d14e3e33b04bf28eb", "commit_message": "libnm-util: optimize nm_utils_hwaddr_ntoa_len()\n\nSigned-off-by: Thomas Haller <thaller@redhat.com>", "code_diff": "@@ -2154,18 +2154,26 @@ char *\n nm_utils_hwaddr_ntoa_len (gconstpointer addr, gsize length)\n {\n \tconst guint8 *in = addr;\n-\tGString *out;\n+\tchar *out, *result;\n+\tconst char *LOOKUP = \"0123456789ABCDEF\";\n \n-\tg_return_val_if_fail (addr && length, g_strdup (\"\"));\n-\n-\tout = g_string_new (NULL);\n-\twhile (length--) {\n-\t\tif (out->len)\n-\t\t\tg_string_append_c (out, ':');\n-\t\tg_string_append_printf (out, \"%02X\", *in++);\n+\tif (!addr || !length) {\n+\t\tg_return_val_if_reached (g_strdup (\"\"));\n+\t\treturn g_strdup (\"\");\n \t}\n \n-\treturn g_string_free (out, FALSE);\n+\tresult = out = g_malloc (length * 3);\n+\tfor (;;) {\n+\t\tguint8 v = *in++;\n+\n+\t\t*out++ = LOOKUP[v >> 4];\n+\t\t*out++ = LOOKUP[v & 0x0F];\n+\t\tif (--length == 0) {\n+\t\t\t*out = 0;\n+\t\t\treturn result;\n+\t\t}\n+\t\t*out++ = ':';\n+\t}\n }\n \n /**\n", "changed_method_name": "nm_utils_hwaddr_ntoa_len"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/59f2c0fb3e9a7266ff39f4e1212024e9d845be75", "commit_message": "core/policy: refactor auto_activate_device() to use a GPtrArray\n\nNext we want to sort the array, g_slist_sort() is not guaranteed to be\nstable, while g_ptr_array_sort() is. Also, sorting a GSList has\nworse performance.\n\nSigned-off-by: Thomas Haller <thaller@redhat.com>", "code_diff": "@@ -42,6 +42,7 @@\n #include \"nm-firewall-manager.h\"\n #include \"nm-dispatcher.h\"\n #include \"nm-utils.h\"\n+#include \"nm-core-internal.h\"\n #include \"nm-glib-compat.h\"\n #include \"nm-manager.h\"\n #include \"nm-settings.h\"\n@@ -990,7 +991,9 @@ auto_activate_device (gpointer user_data)\n \tNMPolicyPrivate *priv;\n \tNMConnection *best_connection;\n \tchar *specific_object = NULL;\n-\tGSList *connections, *iter;\n+\tGPtrArray *connections;\n+\tGSList *connection_list;\n+\tguint i;\n \n \tg_assert (data);\n \tpolicy = data->policy;\n@@ -1005,12 +1008,17 @@ auto_activate_device (gpointer user_data)\n \tif (nm_device_get_act_request (data->device))\n \t\tgoto out;\n \n-\tconnections = nm_manager_get_activatable_connections (priv->manager);\n+\tconnection_list = nm_manager_get_activatable_connections (priv->manager);\n+\tif (!connection_list)\n+\t\tgoto out;\n+\n+\tconnections = _nm_utils_copy_slist_to_array (connection_list, NULL, NULL);\n+\tg_slist_free (connection_list);\n \n \t/* Find the first connection that should be auto-activated */\n \tbest_connection = NULL;\n-\tfor (iter = connections; iter; iter = g_slist_next (iter)) {\n-\t\tNMSettingsConnection *candidate = NM_SETTINGS_CONNECTION (iter->data);\n+\tfor (i = 0; i < connections->len; i++) {\n+\t\tNMSettingsConnection *candidate = NM_SETTINGS_CONNECTION (connections->pdata[i]);\n \n \t\tif (!nm_settings_connection_can_autoconnect (candidate))\n \t\t\tcontinue;\n@@ -1019,7 +1027,7 @@ auto_activate_device (gpointer user_data)\n \t\t\tbreak;\n \t\t}\n \t}\n-\tg_slist_free (connections);\n+\tg_ptr_array_free (connections, TRUE);\n \n \tif (best_connection) {\n \t\tGError *error = NULL;\n", "changed_method_name": "auto_activate_device"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/de9848aa66d2ef97a53ad04c537df4859baea243", "commit_message": "core: optimize nm_match_spec_s390_subchannels() to return early\n\nNo need to parse the subchannels if the spec list is empty.\n\nThis isn't actually an issue, because nm_match_spec_s390_subchannels()\nwas never called with empty spec list.", "code_diff": "@@ -1108,6 +1108,9 @@ nm_match_spec_s390_subchannels (const GSList *specs, const char *subchannels)\n \n \tg_return_val_if_fail (subchannels != NULL, NM_MATCH_SPEC_NO_MATCH);\n \n+\tif (!specs)\n+\t\treturn NM_MATCH_SPEC_NO_MATCH;\n+\n \tif (!parse_subchannels (subchannels, &a, &b, &c))\n \t\treturn NM_MATCH_SPEC_NO_MATCH;\n \n", "changed_method_name": "nm_match_spec_s390_subchannels"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/e93abf0552cf67c7fac5af9d365a833e747192f5", "commit_message": "device: optimize nm_manager_get_connection_iface()", "code_diff": "@@ -987,6 +987,20 @@ nm_manager_get_connection_iface (NMManager *self,\n \t\treturn NULL;\n \t}\n \n+\tif (   !out_parent\n+\t    && !NM_DEVICE_FACTORY_GET_INTERFACE (factory)->get_connection_iface) {\n+\t\t/* optimization. Shortcut lookup of the partent device. */\n+\t\tiface = g_strdup (nm_connection_get_interface_name (connection));\n+\t\tif (!iface) {\n+\t\t\tg_set_error (error,\n+\t\t\t             NM_MANAGER_ERROR,\n+\t\t\t             NM_MANAGER_ERROR_FAILED,\n+\t\t\t             \"failed to determine interface name: error determine name for %s\",\n+\t\t\t             nm_connection_get_connection_type (connection));\n+\t\t}\n+\t\treturn iface;\n+\t}\n+\n \tparent = find_parent_device_for_connection (self, connection, factory);\n \tiface = nm_device_factory_get_connection_iface (factory,\n \t                                                connection,\n", "changed_method_name": "nm_manager_get_connection_iface"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/b913e1d641e98c99f27936d76828998ae5534fbb", "commit_message": "platform: optimize sysctl_set() to use stack allocated buffer\n\nThe value written to sysctl is usually a short string. It makes sense\nto optimize for this case and avoid allocating a temporary string\non the heap.\n\nAn alternative would be to use writev(), which effectively does the same\nand also creates a temporary buffer (preferably stack allocated).\n\nhttps://mail.gnome.org/archives/networkmanager-list/2016-February/msg00070.html", "code_diff": "@@ -2452,8 +2452,11 @@ _log_dbg_sysctl_set_impl (NMPlatform *platform, const char *path, const char *va\n static gboolean\n sysctl_set (NMPlatform *platform, const char *path, const char *value)\n {\n-\tint fd, len, nwrote, tries;\n+\tint fd, tries;\n+\tgssize nwrote;\n+\tgsize len;\n \tchar *actual;\n+\tgs_free char *actual_free = NULL;\n \n \tg_return_val_if_fail (path != NULL, FALSE);\n \tg_return_val_if_fail (value != NULL, FALSE);\n@@ -2483,10 +2486,16 @@ sysctl_set (NMPlatform *platform, const char *path, const char *value)\n \t * sysctl support partial writes so the LF must be added to the string we're\n \t * about to write.\n \t */\n-\tactual = g_strdup_printf (\"%s\\n\", value);\n+\tlen = strlen (value) + 1;\n+\tif (len > 512)\n+\t\tactual = actual_free = g_malloc (len + 1);\n+\telse\n+\t\tactual = g_alloca (len + 1);\n+\tmemcpy (actual, value, len - 1);\n+\tactual[len - 1] = '\\n';\n+\tactual[len] = '\\0';\n \n \t/* Try to write the entire value three times if a partial write occurs */\n-\tlen = strlen (actual);\n \tfor (tries = 0, nwrote = 0; tries < 3 && nwrote != len; tries++) {\n \t\tnwrote = write (fd, actual, len);\n \t\tif (nwrote == -1) {\n@@ -2505,7 +2514,6 @@ sysctl_set (NMPlatform *platform, const char *path, const char *value)\n \t\t       path, value);\n \t}\n \n-\tg_free (actual);\n \tclose (fd);\n \treturn (nwrote == len);\n }\n", "changed_method_name": "sysctl_set"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/e3d2fc861b86bbde2bfa3987e3f89a414046219a", "commit_message": "dhcp: support _LOGx_ENABLED() macro in dhcp-client\n\nThe macro _LOGx_ENABLED() is defined with a default implementation\nthat depends on _NMLOG_DOMAIN. Although that default does not\ncheck for LOGD_DHCP4 vs. LOGD_DHCP6, still provide it.\nDetermining the correct domain might involve a larger performance\nimpact that what we would safe.", "code_diff": "@@ -25,11 +25,18 @@\n #include \"nm-dhcp-client.h\"\n \n #define _NMLOG_PREFIX_NAME    \"dhcp\"\n+#define _NMLOG_DOMAIN         LOGD_DHCP\n #define _NMLOG(level, ...) \\\n     G_STMT_START { \\\n         const NMLogLevel _level = (level); \\\n         \\\n-        if (nm_logging_enabled (_level, LOGD_DHCP)) { \\\n+        /* we check first for LOGD_DHCP instead of the correct domain.\n+         * In the worst case, we guess wrong and enter the block.\n+         *\n+         * Same for the _NMLOG_ENABLED() macro. Probably it would be more\n+         * expensive to determine the correct value then what we could\n+         * safe. */ \\\n+        if (nm_logging_enabled (_level, _NMLOG_DOMAIN)) { \\\n             NMDhcpClient *_self = (NMDhcpClient *) (self); \\\n             const char *__ifname = _self ? nm_dhcp_client_get_iface (_self) : NULL; \\\n             const NMLogDomain _domain = !_self \\\n", "changed_method_name": "if"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/60cc501a665ad7fcfedcdba37557860458dca9a9", "commit_message": "device: optimize hashtable usage for shared_ips\n\nNo point ins storing \"TRUE\" as value in the @shared_ips hash\ntable. That forces glib to allocate a separate storage for the\nvalue. Just use g_hash_table_add() instead.", "code_diff": "@@ -4672,10 +4672,7 @@ reserve_shared_ip (NMDevice *self, NMSettingIPConfig *s_ip4, NMPlatformIP4Addres\n \t\t\t}\n \t\t}\n \t\tnm_platform_ip4_address_set_addr (address, start + count, 24);\n-\n-\t\tg_hash_table_insert (shared_ips,\n-\t\t                     GUINT_TO_POINTER (address->address),\n-\t\t                     GUINT_TO_POINTER (TRUE));\n+\t\tg_hash_table_add (shared_ips, GUINT_TO_POINTER (address->address));\n \t}\n \n \treturn TRUE;\n", "changed_method_name": "reserve_shared_ip"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/1a070f6a44a0f1a39c174425be96dd8834bea25e", "commit_message": "logging: remove assertion in nm_logging_enabled() from production builds\n\nWe really expect this assertion not to be violated.\n\nAs we want for nm_logging_enabled() to become smaller and inline,\nremove the runtime assertion from regular builds.\n\nLive fast and dangerous.", "code_diff": "@@ -447,8 +447,7 @@ nm_logging_all_domains_to_string (void)\n gboolean\n nm_logging_enabled (NMLogLevel level, NMLogDomain domain)\n {\n-\tif ((guint) level >= G_N_ELEMENTS (global.logging))\n-\t\tg_return_val_if_reached (FALSE);\n+\tnm_assert (((guint) level) < G_N_ELEMENTS (global.logging));\n \n \treturn !!(global.logging[level] & domain);\n }\n", "changed_method_name": "nm_logging_enabled"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/1fb3d5d7944e20e3fd70296f763af5b23bb0efe1", "commit_message": "ifcfg-rh: don't call svSetValue with verbatim=TRUE\n\nThis is at best a performance optimization. In the next step\nget rid of the verbatim argument, so ensure we pass FALSE everwhere.", "code_diff": "@@ -934,17 +934,17 @@ write_wireless_setting (NMConnection *connection,\n \t\tg_free (keys_path);\n \t}\n \n-\tsvSetValue (ifcfg, \"SSID_HIDDEN\", nm_setting_wireless_get_hidden (s_wireless) ? \"yes\" : NULL, TRUE);\n+\tsvSetValue (ifcfg, \"SSID_HIDDEN\", nm_setting_wireless_get_hidden (s_wireless) ? \"yes\" : NULL, FALSE);\n \n \tswitch (nm_setting_wireless_get_powersave (s_wireless)) {\n \tcase NM_SETTING_WIRELESS_POWERSAVE_IGNORE:\n-\t\tsvSetValue (ifcfg, \"POWERSAVE\", \"ignore\", TRUE);\n+\t\tsvSetValue (ifcfg, \"POWERSAVE\", \"ignore\", FALSE);\n \t\tbreak;\n \tcase NM_SETTING_WIRELESS_POWERSAVE_DISABLE:\n-\t\tsvSetValue (ifcfg, \"POWERSAVE\", \"disable\", TRUE);\n+\t\tsvSetValue (ifcfg, \"POWERSAVE\", \"disable\", FALSE);\n \t\tbreak;\n \tcase NM_SETTING_WIRELESS_POWERSAVE_ENABLE:\n-\t\tsvSetValue (ifcfg, \"POWERSAVE\", \"enable\", TRUE);\n+\t\tsvSetValue (ifcfg, \"POWERSAVE\", \"enable\", FALSE);\n \t\tbreak;\n \tdefault:\n \tcase NM_SETTING_WIRELESS_POWERSAVE_DEFAULT:\n@@ -955,14 +955,14 @@ write_wireless_setting (NMConnection *connection,\n \tsvUnsetValue (ifcfg, \"MAC_ADDRESS_RANDOMIZATION\");\n \tswitch (nm_setting_wireless_get_mac_address_randomization (s_wireless)) {\n \tcase NM_SETTING_MAC_RANDOMIZATION_DEFAULT:\n-\t\tsvSetValue (ifcfg, \"MAC_ADDRESS_RANDOMIZATION\", \"default\", TRUE);\n+\t\tsvSetValue (ifcfg, \"MAC_ADDRESS_RANDOMIZATION\", \"default\", FALSE);\n \t\tbreak;\n \tcase NM_SETTING_MAC_RANDOMIZATION_ALWAYS:\n-\t\tsvSetValue (ifcfg, \"MAC_ADDRESS_RANDOMIZATION\", \"always\", TRUE);\n+\t\tsvSetValue (ifcfg, \"MAC_ADDRESS_RANDOMIZATION\", \"always\", FALSE);\n \t\tbreak;\n \tdefault:\n \tcase NM_SETTING_MAC_RANDOMIZATION_NEVER:\n-\t\tsvSetValue (ifcfg, \"MAC_ADDRESS_RANDOMIZATION\", \"never\", TRUE);\n+\t\tsvSetValue (ifcfg, \"MAC_ADDRESS_RANDOMIZATION\", \"never\", FALSE);\n \t\tbreak;\n \t}\n \n", "changed_method_name": "write_wireless_setting"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/4417b8bf3eef8ca7cf45dc973ab107249bd10d67", "commit_message": "core: add nm_utils_get_monotonic_timestamp_ns_cached() helper\n\nAdd a helper function to cache the current timestamp and return\nit. The caching is a performance optimization, but it serves a\nmuch more important purpose: repeatedly getting the timestamp\nlikely will yield different timings. So, commonly, within a\ncertain context we want to get the current time once, and stick\nto that as \"now\".", "code_diff": "@@ -239,6 +239,13 @@ gint64 nm_utils_get_monotonic_timestamp_ms (void);\n gint32 nm_utils_get_monotonic_timestamp_s (void);\n gint64 nm_utils_monotonic_timestamp_as_boottime (gint64 timestamp, gint64 timestamp_ticks_per_ns);\n \n+static inline gint64\n+nm_utils_get_monotonic_timestamp_ns_cached (gint64 *cache_now)\n+{\n+\treturn    (*cache_now)\n+\t       ?: (*cache_now = nm_utils_get_monotonic_timestamp_ns ());\n+}\n+\n gboolean    nm_utils_is_valid_path_component (const char *name);\n const char *NM_ASSERT_VALID_PATH_COMPONENT (const char *name);\n \n", "changed_method_name": "nm_utils_get_monotonic_timestamp_ns_cached"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/de5d07392da488113c956fbf1aca94fa280c3302", "commit_message": "libnm: optimize nm_simple_connection_new_clone() to not needlessly set the path\n\nServer never sets the path, so this is entirely unused server-side.\nAlso NMConnection is a glib interface and stores it's private date\nin the GObject's data. It's less efficient to look it up. Just\navoid it.", "code_diff": "@@ -113,11 +113,16 @@ NMConnection *\n nm_simple_connection_new_clone (NMConnection *connection)\n {\n \tNMConnection *clone;\n+\tconst char *path;\n \n \tg_return_val_if_fail (NM_IS_CONNECTION (connection), NULL);\n \n \tclone = nm_simple_connection_new ();\n-\tnm_connection_set_path (clone, nm_connection_get_path (connection));\n+\n+\tpath = nm_connection_get_path (connection);\n+\tif (path)\n+\t\tnm_connection_set_path (clone, path);\n+\n \tnm_connection_replace_settings_from_connection (clone, connection);\n \n \treturn clone;\n", "changed_method_name": "nm_simple_connection_new_clone"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/f8b74e19ea1e01781d22fccc6e96129d88e6814e", "commit_message": "auth-manager: emit signal by ID\n\nIt's more efficient, as it saves a lookup by name. Also,\nit's more idiomatic to do it this way. I didn't find where\nthe signal gets emitted at first, because usually we don't emit\nby name.", "code_diff": "@@ -353,7 +353,7 @@ static void\n _emit_changed_signal (NMAuthManager *self)\n {\n \t_LOGD (\"emit changed signal\");\n-\tg_signal_emit_by_name (self, NM_AUTH_MANAGER_SIGNAL_CHANGED);\n+\tg_signal_emit (self, signals[CHANGED_SIGNAL], 0);\n }\n \n static void\n", "changed_method_name": "_emit_changed_signal"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/bac7a2821f3a52107f5c5dc447f337fdc56e3233", "commit_message": "core: cleanup NMManager's validate_activation_request()\n\n- there are only two callers of validate_activation_request(). One of them,\n  might already lookup the device before calling the validate function.\n  Safe to looking up again. But this is not only an optimization, more importantly,\n  it feels odd to first lookup a device, and then later look it up again. Are\n  we guaranteed to use the same path? Why? Just avoid that question.\n- re-order some error checking for missing device, so that it is clearer.\n- use cleanup attribute to handle return value and drop the \"goto error\".", "code_diff": "@@ -4205,6 +4205,9 @@ nm_manager_activate_connection (NMManager *self,\n  * @connection: the partial or complete #NMConnection to be activated\n  * @device_path: the object path of the device to be activated, or NULL\n  * @out_device: on successful reutrn, the #NMDevice to be activated with @connection\n+ *   The caller may pass in a device which shortcuts the lookup by path.\n+ *   In this case, the passed in device must have the matching @device_path\n+ *   already.\n  * @out_vpn: on successful return, %TRUE if @connection is a VPN connection\n  * @error: location to store an error on failure\n  *\n@@ -4226,7 +4229,7 @@ validate_activation_request (NMManager *self,\n {\n \tNMDevice *device = NULL;\n \tgboolean vpn = FALSE;\n-\tNMAuthSubject *subject = NULL;\n+\tgs_free NMAuthSubject *subject = NULL;\n \n \tnm_assert (NM_IS_CONNECTION (connection));\n \tnm_assert (out_device);\n@@ -4247,60 +4250,62 @@ validate_activation_request (NMManager *self,\n \t                                          NM_MANAGER_ERROR,\n \t                                          NM_MANAGER_ERROR_PERMISSION_DENIED,\n \t                                          error))\n-\t\tgoto error;\n+\t\treturn NULL;\n \n \tif (   nm_connection_get_setting_vpn (connection)\n \t    || nm_connection_is_type (connection, NM_SETTING_VPN_SETTING_NAME))\n \t\tvpn = TRUE;\n \n-\tif (device_path) {\n+\tif (*out_device) {\n+\t\tdevice = *out_device;\n+\t\tnm_assert (NM_IS_DEVICE (device));\n+\t\tnm_assert (device_path);\n+\t\tnm_assert (nm_streq0 (device_path, nm_dbus_object_get_path (NM_DBUS_OBJECT (device))));\n+\t\tnm_assert (device == nm_manager_get_device_by_path (self, device_path));\n+\t} else if (device_path) {\n \t\tdevice = nm_manager_get_device_by_path (self, device_path);\n \t\tif (!device) {\n \t\t\tg_set_error_literal (error,\n \t\t\t                     NM_MANAGER_ERROR,\n \t\t\t                     NM_MANAGER_ERROR_UNKNOWN_DEVICE,\n \t\t\t                     \"Device not found\");\n-\t\t\tgoto error;\n+\t\t\treturn NULL;\n \t\t}\n-\t} else\n+\t} else {\n \t\tdevice = nm_manager_get_best_device_for_connection (self, connection, TRUE, NULL);\n+\t\tif (   !device\n+\t\t    && !vpn) {\n+\t\t\tgs_free char *iface = NULL;\n+\n+\t\t\t/* VPN and software-device connections don't need a device yet,\n+\t\t\t * but non-virtual connections do ... */\n+\t\t\tif (!nm_connection_is_virtual (connection)) {\n+\t\t\t\tg_set_error_literal (error,\n+\t\t\t\t                     NM_MANAGER_ERROR,\n+\t\t\t\t                     NM_MANAGER_ERROR_UNKNOWN_DEVICE,\n+\t\t\t\t                     \"No suitable device found for this connection.\");\n+\t\t\t\treturn NULL;\n+\t\t\t}\n \n-\tif (!device && !vpn) {\n-\t\tgs_free char *iface = NULL;\n+\t\t\t/* Look for an existing device with the connection's interface name */\n+\t\t\tiface = nm_manager_get_connection_iface (self, connection, NULL, error);\n+\t\t\tif (!iface)\n+\t\t\t\treturn NULL;\n \n-\t\t/* VPN and software-device connections don't need a device yet,\n-\t\t * but non-virtual connections do ... */\n-\t\tif (!nm_connection_is_virtual (connection)) {\n-\t\t\tg_set_error_literal (error,\n-\t\t\t                     NM_MANAGER_ERROR,\n-\t\t\t                     NM_MANAGER_ERROR_UNKNOWN_DEVICE,\n-\t\t\t                     \"No suitable device found for this connection.\");\n-\t\t\tgoto error;\n+\t\t\tdevice = find_device_by_iface (self, iface, connection, NULL);\n+\t\t\tif (!device) {\n+\t\t\t\tg_set_error_literal (error,\n+\t\t\t\t                     NM_MANAGER_ERROR,\n+\t\t\t\t                     NM_MANAGER_ERROR_UNKNOWN_DEVICE,\n+\t\t\t\t                     \"Failed to find a compatible device for this connection\");\n+\t\t\t\treturn NULL;\n+\t\t\t}\n \t\t}\n-\n-\t\t/* Look for an existing device with the connection's interface name */\n-\t\tiface = nm_manager_get_connection_iface (self, connection, NULL, error);\n-\t\tif (!iface)\n-\t\t\tgoto error;\n-\n-\t\tdevice = find_device_by_iface (self, iface, connection, NULL);\n-\t}\n-\n-\tif ((!vpn || device_path) && !device) {\n-\t\tg_set_error_literal (error,\n-\t\t                     NM_MANAGER_ERROR,\n-\t\t                     NM_MANAGER_ERROR_UNKNOWN_DEVICE,\n-\t\t                     \"Failed to find a compatible device for this connection\");\n-\t\tgoto error;\n \t}\n \n \t*out_device = device;\n \t*out_vpn = vpn;\n-\treturn subject;\n-\n-error:\n-\tg_object_unref (subject);\n-\treturn NULL;\n+\treturn g_steal_pointer (&subject);\n }\n \n /*****************************************************************************/\n", "changed_method_name": "validate_activation_request"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/e9321713a90a2f1098afbdbbfbb462638c54a368", "commit_message": "ifcfg: make_ip6_setting cleanup & optimization 2/2\n\nget rid of svGetValueStr_cp() in favor of svGetValueStr() in the\nmake_ip6_setting() function", "code_diff": "@@ -1685,11 +1685,13 @@ make_ip6_setting (shvarFile *ifcfg,\n {\n \tNMSettingIPConfig *s_ip6 = NULL;\n \tconst char *v;\n-\tchar *value = NULL;\n+\tgs_free char *value = NULL;\n \tchar *route6_path = NULL;\n \tgboolean ipv6init, ipv6forwarding, dhcp6 = FALSE;\n \tchar *method = NM_SETTING_IP6_CONFIG_METHOD_MANUAL;\n-\tchar *ipv6addr, *ipv6addr_secondaries;\n+\tconst char *ipv6addr, *ipv6addr_secondaries;\n+\tgs_free char *ipv6addr_to_free = NULL;\n+\tgs_free char *ipv6addr_secondaries_to_free = NULL;\n \tgs_free const char **list = NULL;\n \tconst char *const *iter;\n \tguint32 i;\n@@ -1715,13 +1717,16 @@ make_ip6_setting (shvarFile *ifcfg,\n \t * When both are set, the device specified in IPV6_DEFAULTGW takes preference.\n \t */\n \tif (network_ifcfg) {\n-\t\tchar *ipv6_defaultgw, *ipv6_defaultdev;\n-\t\tchar *default_dev = NULL;\n+\t\tconst char *ipv6_defaultgw, *ipv6_defaultdev;\n+\t\tgs_free char *ipv6_defaultgw_to_free = NULL;\n+\t\tgs_free char *ipv6_defaultdev_to_free = NULL;\n+\t\tconst char *default_dev = NULL;\n \n \t\t/* Get the connection ifcfg device name and the global default route device */\n-\t\tvalue = svGetValueStr_cp (ifcfg, \"DEVICE\");\n-\t\tipv6_defaultgw = svGetValueStr_cp (network_ifcfg, \"IPV6_DEFAULTGW\");\n-\t\tipv6_defaultdev = svGetValueStr_cp (network_ifcfg, \"IPV6_DEFAULTDEV\");\n+\t\tnm_clear_g_free (&value);\n+\t\tv = svGetValueStr (ifcfg, \"DEVICE\", &value);\n+\t\tipv6_defaultgw = svGetValueStr (network_ifcfg, \"IPV6_DEFAULTGW\", &ipv6_defaultgw_to_free);\n+\t\tipv6_defaultdev = svGetValueStr (network_ifcfg, \"IPV6_DEFAULTDEV\", &ipv6_defaultdev_to_free);\n \n \t\tif (ipv6_defaultgw) {\n \t\t\tdefault_dev = strchr (ipv6_defaultgw, '%');\n@@ -1734,66 +1739,64 @@ make_ip6_setting (shvarFile *ifcfg,\n \t\t/* If there was a global default route device specified, then only connections\n \t\t * for that device can be the default connection.\n \t\t */\n-\t\tif (default_dev && value)\n-\t\t\tnever_default = !!strcmp (value, default_dev);\n-\n-\t\tg_free (ipv6_defaultgw);\n-\t\tg_free (ipv6_defaultdev);\n-\t\tg_free (value);\n+\t\tif (default_dev && v)\n+\t\t\tnever_default = !!strcmp (v, default_dev);\n \t}\n \n \t/* Find out method property */\n \t/* Is IPV6 enabled? Set method to \"ignored\", when not enabled */\n-\tvalue = svGetValueStr_cp (ifcfg, \"IPV6INIT\");\n+\tnm_clear_g_free (&value);\n+\tv = svGetValueStr (ifcfg, \"IPV6INIT\", &value);\n \tipv6init = svGetValueBoolean (ifcfg, \"IPV6INIT\", FALSE);\n-\tif (!value) {\n+\tif (!v) {\n \t\tif (network_ifcfg)\n \t\t\tipv6init = svGetValueBoolean (network_ifcfg, \"IPV6INIT\", FALSE);\n \t}\n-\tg_free (value);\n \n \tif (!ipv6init)\n \t\tmethod = NM_SETTING_IP6_CONFIG_METHOD_IGNORE;  /* IPv6 is disabled */\n \telse {\n \t\tipv6forwarding = svGetValueBoolean (ifcfg, \"IPV6FORWARDING\", FALSE);\n-\t\tvalue = svGetValueStr_cp (ifcfg, \"IPV6_AUTOCONF\");\n+\t\tnm_clear_g_free (&value);\n+\t\tv = svGetValueStr (ifcfg, \"IPV6_AUTOCONF\", &value);\n \t\tdhcp6 = svGetValueBoolean (ifcfg, \"DHCPV6C\", FALSE);\n \n-\t\tif (!g_strcmp0 (value, \"shared\"))\n+\t\tif (!g_strcmp0 (v, \"shared\"))\n \t\t\tmethod = NM_SETTING_IP6_CONFIG_METHOD_SHARED;\n-\t\telse if (svParseBoolean (value, !ipv6forwarding))\n+\t\telse if (svParseBoolean (v, !ipv6forwarding))\n \t\t\tmethod = NM_SETTING_IP6_CONFIG_METHOD_AUTO;\n \t\telse if (dhcp6)\n \t\t\tmethod = NM_SETTING_IP6_CONFIG_METHOD_DHCP;\n \t\telse {\n \t\t\t/* IPV6_AUTOCONF=no and no IPv6 address -> method 'link-local' */\n-\t\t\tg_free (value);\n-\t\t\tvalue = svGetValueStr_cp (ifcfg, \"IPV6ADDR\");\n-\t\t\tif (!value)\n-\t\t\t\tvalue = svGetValueStr_cp (ifcfg, \"IPV6ADDR_SECONDARIES\");\n+\t\t\tnm_clear_g_free (&value);\n+\t\t\tv = svGetValueStr (ifcfg, \"IPV6ADDR\", &value);\n+\t\t\tif (!v) {\n+\t\t\t\tnm_clear_g_free (&value);\n+\t\t\t\tv = svGetValueStr (ifcfg, \"IPV6ADDR_SECONDARIES\", &value);\n+\t\t\t}\n \n-\t\t\tif (!value)\n+\t\t\tif (!v)\n \t\t\t\tmethod = NM_SETTING_IP6_CONFIG_METHOD_LINK_LOCAL;\n \t\t}\n-\t\tg_free (value);\n \t}\n \t/* TODO - handle other methods */\n \n \t/* Read IPv6 Privacy Extensions configuration */\n-\tvalue = svGetValueStr_cp (ifcfg, \"IPV6_PRIVACY\");\n-\tif (value) {\n-\t\tip6_privacy = svParseBoolean (value, FALSE);\n+\tnm_clear_g_free (&value);\n+\tv = svGetValueStr (ifcfg, \"IPV6_PRIVACY\", &value);\n+\tif (v) {\n+\t\tip6_privacy = svParseBoolean (v, FALSE);\n \t\tif (!ip6_privacy)\n-\t\t\tip6_privacy = (g_strcmp0 (value, \"rfc4941\") == 0) ||\n-\t\t\t              (g_strcmp0 (value, \"rfc3041\") == 0);\n+\t\t\tip6_privacy = (g_strcmp0 (v, \"rfc4941\") == 0) ||\n+\t\t\t              (g_strcmp0 (v, \"rfc3041\") == 0);\n \t}\n \tip6_privacy_prefer_public_ip = svGetValueBoolean (ifcfg, \"IPV6_PRIVACY_PREFER_PUBLIC_IP\", FALSE);\n-\tip6_privacy_val = value ?\n+\tip6_privacy_val = v ?\n \t                      (ip6_privacy ?\n \t                          (ip6_privacy_prefer_public_ip ? NM_SETTING_IP6_CONFIG_PRIVACY_PREFER_PUBLIC_ADDR : NM_SETTING_IP6_CONFIG_PRIVACY_PREFER_TEMP_ADDR) :\n \t                          NM_SETTING_IP6_CONFIG_PRIVACY_DISABLED) :\n \t                      NM_SETTING_IP6_CONFIG_PRIVACY_UNKNOWN;\n-\tg_free (value);\n \n \t/* the route table (policy routing) is ignored if we don't handle routes. */\n \troute_table = svGetValueInt64 (ifcfg, \"IPV6_ROUTE_TABLE\", 10,\n@@ -1820,19 +1823,20 @@ make_ip6_setting (shvarFile *ifcfg,\n \tif (strcmp (method, NM_SETTING_IP6_CONFIG_METHOD_IGNORE) == 0)\n \t\treturn NM_SETTING (s_ip6);\n \n-\tvalue = svGetValueStr_cp (ifcfg, \"DHCPV6_HOSTNAME\");\n+\tnm_clear_g_free (&value);\n+\tv = svGetValueStr (ifcfg, \"DHCPV6_HOSTNAME\", &value);\n \t/* Use DHCP_HOSTNAME as fallback if it is in FQDN format and ipv6.method is\n \t * auto or dhcp: this is required to support old ifcfg files\n \t */\n-\tif (!value && (   !strcmp (method, NM_SETTING_IP6_CONFIG_METHOD_AUTO)\n+\tif (!v && (   !strcmp (method, NM_SETTING_IP6_CONFIG_METHOD_AUTO)\n \t\t       || !strcmp (method, NM_SETTING_IP6_CONFIG_METHOD_DHCP))) {\n-\t\tvalue = svGetValueStr_cp (ifcfg, \"DHCP_HOSTNAME\");\n-\t\tif (value && !strchr (value, '.'))\n-\t\t\tg_clear_pointer (&value, g_free);\n+\t\tnm_clear_g_free (&value);\n+\t\tv = svGetValueStr (ifcfg, \"DHCP_HOSTNAME\", &value);\n+\t\tif (v && !strchr (v, '.'))\n+\t\t\tv = NULL;\n \t}\n-\tif (value)\n-\t\tg_object_set (s_ip6, NM_SETTING_IP_CONFIG_DHCP_HOSTNAME, value, NULL);\n-\tg_free (value);\n+\tif (v)\n+\t\tg_object_set (s_ip6, NM_SETTING_IP_CONFIG_DHCP_HOSTNAME, v, NULL);\n \n \tg_object_set (s_ip6, NM_SETTING_IP_CONFIG_DHCP_SEND_HOSTNAME,\n \t\t      svGetValueBoolean (ifcfg, \"DHCPV6_SEND_HOSTNAME\", TRUE), NULL);\n@@ -1842,18 +1846,16 @@ make_ip6_setting (shvarFile *ifcfg,\n \t * added to the automatic ones. Note that this is not currently supported by\n \t * the legacy 'network' service (ifup-eth).\n \t */\n-\tipv6addr = svGetValueStr_cp (ifcfg, \"IPV6ADDR\");\n-\tipv6addr_secondaries = svGetValueStr_cp (ifcfg, \"IPV6ADDR_SECONDARIES\");\n+\tipv6addr = svGetValueStr (ifcfg, \"IPV6ADDR\", &ipv6addr_to_free);\n+\tipv6addr_secondaries = svGetValueStr (ifcfg, \"IPV6ADDR_SECONDARIES\", &ipv6addr_secondaries_to_free);\n \n+\tnm_clear_g_free (&value);\n \tvalue = g_strjoin (ipv6addr && ipv6addr_secondaries ? \" \" : NULL,\n \t                   ipv6addr ?: \"\",\n \t                   ipv6addr_secondaries ?: \"\",\n \t                   NULL);\n-\tg_free (ipv6addr);\n-\tg_free (ipv6addr_secondaries);\n \n \tlist = nm_utils_strsplit_set (value, \" \");\n-\tg_free (value);\n \tfor (iter = list, i = 0; iter && *iter; iter++, i++) {\n \t\tNMIPAddress *addr = NULL;\n \n@@ -1867,25 +1869,26 @@ make_ip6_setting (shvarFile *ifcfg,\n \n \t/* Gateway */\n \tif (nm_setting_ip_config_get_num_addresses (s_ip6)) {\n-\t\tvalue = svGetValueStr_cp (ifcfg, \"IPV6_DEFAULTGW\");\n-\t\tif (!value) {\n+\t\tnm_clear_g_free (&value);\n+\t\tv = svGetValueStr (ifcfg, \"IPV6_DEFAULTGW\", &value);\n+\t\tif (!v) {\n \t\t\t/* If no gateway in the ifcfg, try global /etc/sysconfig/network instead */\n-\t\t\tif (network_ifcfg)\n-\t\t\t\tvalue = svGetValueStr_cp (network_ifcfg, \"IPV6_DEFAULTGW\");\n+\t\t\tif (network_ifcfg) {\n+\t\t\t\tnm_clear_g_free (&value);\n+\t\t\t\tv = svGetValueStr (network_ifcfg, \"IPV6_DEFAULTGW\", &value);\n+\t\t\t}\n \t\t}\n-\t\tif (value) {\n+\t\tif (v) {\n \t\t\tchar *ptr;\n-\t\t\tif ((ptr = strchr (value, '%')) != NULL)\n+\t\t\tif ((ptr = strchr (v, '%')) != NULL)\n \t\t\t\t*ptr = '\\0';  /* remove %interface prefix if present */\n-\t\t\tif (!nm_utils_ipaddr_valid (AF_INET6, value)) {\n+\t\t\tif (!nm_utils_ipaddr_valid (AF_INET6, v)) {\n \t\t\t\tg_set_error (error, NM_SETTINGS_ERROR, NM_SETTINGS_ERROR_INVALID_CONNECTION,\n-\t\t\t\t             \"Invalid IP6 address '%s'\", value);\n-\t\t\t\tg_free (value);\n+\t\t\t\t             \"Invalid IP6 address '%s'\", v);\n \t\t\t\tgoto error;\n \t\t\t}\n \n-\t\t\tg_object_set (s_ip6, NM_SETTING_IP_CONFIG_GATEWAY, value, NULL);\n-\t\t\tg_free (value);\n+\t\t\tg_object_set (s_ip6, NM_SETTING_IP_CONFIG_GATEWAY, v, NULL);\n \t\t}\n \t}\n \n@@ -1899,11 +1902,10 @@ make_ip6_setting (shvarFile *ifcfg,\n \tg_object_set (s_ip6, NM_SETTING_IP6_CONFIG_ADDR_GEN_MODE, i_val, NULL);\n \n \t/* IPv6 tokenized interface identifier */\n-\tvalue = svGetValueStr_cp (ifcfg, \"IPV6_TOKEN\");\n-\tif (value) {\n-\t\tg_object_set (s_ip6, NM_SETTING_IP6_CONFIG_TOKEN, value, NULL);\n-\t\tg_free (value);\n-\t}\n+\tnm_clear_g_free (&value);\n+\tv = svGetValueStr (ifcfg, \"IPV6_TOKEN\", &value);\n+\tif (v)\n+\t\tg_object_set (s_ip6, NM_SETTING_IP6_CONFIG_TOKEN, v, NULL);\n \n \t/* DNS servers\n \t * Pick up just IPv6 addresses (IPv4 addresses are taken by make_ip4_setting())\n@@ -1912,24 +1914,22 @@ make_ip6_setting (shvarFile *ifcfg,\n \t\tchar tag[256];\n \n \t\tnumbered_tag (tag, \"DNS\", i);\n-\t\tvalue = svGetValueStr_cp (ifcfg, tag);\n-\t\tif (!value) {\n+\t\tnm_clear_g_free (&value);\n+\t\tv = svGetValueStr (ifcfg, tag, &value);\n+\t\tif (!v) {\n \t\t\t/* all done */\n \t\t\tbreak;\n \t\t}\n \n-\t\tif (nm_utils_ipaddr_valid (AF_INET6, value)) {\n-\t\t\tif (!nm_setting_ip_config_add_dns (s_ip6, value))\n+\t\tif (nm_utils_ipaddr_valid (AF_INET6, v)) {\n+\t\t\tif (!nm_setting_ip_config_add_dns (s_ip6, v))\n \t\t\t\tPARSE_WARNING (\"duplicate DNS server %s\", tag);\n-\t\t} else if (nm_utils_ipaddr_valid (AF_INET, value)) {\n+\t\t} else if (nm_utils_ipaddr_valid (AF_INET, v)) {\n \t\t\t/* Ignore IPv4 addresses */\n \t\t} else {\n-\t\t\tPARSE_WARNING (\"invalid DNS server address %s\", value);\n-\t\t\tg_free (value);\n+\t\t\tPARSE_WARNING (\"invalid DNS server address %s\", v);\n \t\t\tgoto error;\n \t\t}\n-\n-\t\tg_free (value);\n \t}\n \n \tif (!routes_read) {\n@@ -1960,7 +1960,6 @@ make_ip6_setting (shvarFile *ifcfg,\n \t/* DNS options */\n \tnm_clear_g_free (&value);\n \tparse_dns_options (s_ip6, svGetValue (ifcfg, \"IPV6_RES_OPTIONS\", &value));\n-\tg_free (value);\n \n \t/* DNS priority */\n \tpriority = svGetValueInt64 (ifcfg, \"IPV6_DNS_PRIORITY\", 10, G_MININT32, G_MAXINT32, 0);\n", "changed_method_name": "make_ip6_setting"}
{"commit_url": "https://github.com/NetworkManager/NetworkManager/commit/50403cccee28c7dcd54b138a0d3b3f69ea0204fe", "commit_message": "sd-dhcp6: make dhcp6_option_parse_domainname() not store empty domain\n\nThis improves performance of fuzzer.\nC.f. oss-fuzz#11019.\n\n(cherry picked from commit 3c72b6ed4252e7ff5f7704bfe44557ec197b47fa)", "code_diff": "@@ -555,6 +555,7 @@ int dhcp6_option_parse_domainname(const uint8_t *optval, uint16_t optlen, char *\n                 bool first = true;\n \n                 for (;;) {\n+                        const char *label;\n                         uint8_t c;\n \n                         c = optval[pos++];\n@@ -562,47 +563,41 @@ int dhcp6_option_parse_domainname(const uint8_t *optval, uint16_t optlen, char *\n                         if (c == 0)\n                                 /* End of name */\n                                 break;\n-                        else if (c <= 63) {\n-                                const char *label;\n-\n-                                /* Literal label */\n-                                label = (const char *)&optval[pos];\n-                                pos += c;\n-                                if (pos >= optlen)\n-                                        return -EMSGSIZE;\n-\n-                                if (!GREEDY_REALLOC(ret, allocated, n + !first + DNS_LABEL_ESCAPED_MAX)) {\n-                                        r = -ENOMEM;\n-                                        goto fail;\n-                                }\n-\n-                                if (first)\n-                                        first = false;\n-                                else\n-                                        ret[n++] = '.';\n-\n-                                r = dns_label_escape(label, c, ret + n, DNS_LABEL_ESCAPED_MAX);\n-                                if (r < 0)\n-                                        goto fail;\n-\n-                                n += r;\n-                                continue;\n-                        } else {\n-                                r = -EBADMSG;\n-                                goto fail;\n-                        }\n-                }\n+                        if (c > 63)\n+                                return -EBADMSG;\n+\n+                        /* Literal label */\n+                        label = (const char *)&optval[pos];\n+                        pos += c;\n+                        if (pos >= optlen)\n+                                return -EMSGSIZE;\n+\n+                        if (!GREEDY_REALLOC(ret, allocated, n + !first + DNS_LABEL_ESCAPED_MAX))\n+                                return -ENOMEM;\n+\n+                        if (first)\n+                                first = false;\n+                        else\n+                                ret[n++] = '.';\n+\n+                        r = dns_label_escape(label, c, ret + n, DNS_LABEL_ESCAPED_MAX);\n+                        if (r < 0)\n+                                return r;\n \n-                if (!GREEDY_REALLOC(ret, allocated, n + 1)) {\n-                        r = -ENOMEM;\n-                        goto fail;\n+                        n += r;\n                 }\n \n+                if (n == 0)\n+                        continue;\n+\n+                if (!GREEDY_REALLOC(ret, allocated, n + 1))\n+                        return -ENOMEM;\n+\n                 ret[n] = 0;\n \n                 r = strv_extend(&names, ret);\n                 if (r < 0)\n-                        goto fail;\n+                        return r;\n \n                 idx++;\n         }\n@@ -610,7 +605,4 @@ int dhcp6_option_parse_domainname(const uint8_t *optval, uint16_t optlen, char *\n         *str_arr = TAKE_PTR(names);\n \n         return idx;\n-\n-fail:\n-        return r;\n }\n", "changed_method_name": "dhcp6_option_parse_domainname"}
{"commit_url": "https://github.com/pulseaudio/pulseaudio/commit/78df02dba61d4d9e4f89225ddf69d5cfcdc9d184", "commit_message": "device-port: Return early from pa_device_port_set_latency_offset() if the offset doesn't change.\n\nThis avoids sending change notifications when nothing changes.", "code_diff": "@@ -104,6 +104,9 @@ void pa_device_port_set_latency_offset(pa_device_port *p, int64_t offset) {\n \n     pa_assert(p);\n \n+    if (offset == p->latency_offset)\n+        return;\n+\n     p->latency_offset = offset;\n \n     if (p->is_output) {\n", "changed_method_name": "pa_device_port_set_latency_offset"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/49d1203b3582f7d637af11a226386a4df186e687", "commit_message": "optimize: iscntrl() seems to be surprisingly slow\n\nat least so tells the profiler...", "code_diff": "@@ -362,11 +362,10 @@ SanitizeMsg(msg_t *pMsg)\n \t */\n \tint bNeedSanitize = 0;\n \tfor(iSrc = 0 ; iSrc < lenMsg ; iSrc++) {\n-\t\tif(iscntrl(pszMsg[iSrc])) {\n+\t\tif(pszMsg[iSrc] < 32) {\n \t\t\tif(bSpaceLFOnRcv && pszMsg[iSrc] == '\\n')\n \t\t\t\tpszMsg[iSrc] = ' ';\n-\t\t\telse\n-\t\t\tif(pszMsg[iSrc] == '\\0' || bEscapeCCOnRcv) {\n+\t\t\telse if(pszMsg[iSrc] == '\\0' || bEscapeCCOnRcv) {\n \t\t\t\tbNeedSanitize = 1;\n \t\t\t\tif (!bSpaceLFOnRcv)\n \t\t\t\t\tbreak;\n@@ -394,7 +393,7 @@ SanitizeMsg(msg_t *pMsg)\n \t\tCHKmalloc(pDst = MALLOC(sizeof(uchar) * (iMaxLine + 1)));\n \tiSrc = iDst = 0;\n \twhile(iSrc < lenMsg && iDst < maxDest - 3) { /* leave some space if last char must be escaped */\n-\t\tif(iscntrl((int) pszMsg[iSrc]) && (pszMsg[iSrc] != '\\t' || bEscapeTab)) {\n+\t\tif((pszMsg[iSrc] < 32) && (pszMsg[iSrc] != '\\t' || bEscapeTab)) {\n \t\t\t/* note: \\0 must always be escaped, the rest of the code currently\n \t\t\t * can not handle it! -- rgerhards, 2009-08-26\n \t\t\t */\n", "changed_method_name": "SanitizeMsg"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/beed1bda6969b70b608ff9e606f52ac6d41cc8c1", "commit_message": "optimize: save inspection of already-inspected data\n\nthis is just a small improvement, but let's get the benefit ;)", "code_diff": "@@ -382,7 +382,9 @@ SanitizeMsg(msg_t *pMsg)\n \t\tFINALIZE;\n \t}\n \n-\t/* now copy over the message and sanitize it */\n+\t/* now copy over the message and sanitize it. Note that up to iSrc-1 there was\n+\t * obviously no need to sanitize, so we can go over that quickly...\n+\t */\n \tiMaxLine = glbl.GetMaxLine();\n \tmaxDest = lenMsg * 4; /* message can grow at most four-fold */\n \tif(maxDest > iMaxLine)\n@@ -391,7 +393,11 @@ SanitizeMsg(msg_t *pMsg)\n \t\tpDst = szSanBuf;\n \telse \n \t\tCHKmalloc(pDst = MALLOC(sizeof(uchar) * (iMaxLine + 1)));\n-\tiSrc = iDst = 0;\n+\tif(iSrc > 0) {\n+\t\tiSrc--; /* go back to where everything is OK */\n+\t\tmemcpy(pDst, pszMsg, iSrc); /* fast copy known good */\n+\t}\n+\tiDst = iSrc;\n \twhile(iSrc < lenMsg && iDst < maxDest - 3) { /* leave some space if last char must be escaped */\n \t\tif((pszMsg[iSrc] < 32) && (pszMsg[iSrc] != '\\t' || bEscapeTab)) {\n \t\t\t/* note: \\0 must always be escaped, the rest of the code currently\n", "changed_method_name": "SanitizeMsg"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/eb97d25219a279daceca29c08e68c864b5629901", "commit_message": "optimize: use built-in str comparison, as this is optimized in assembly\n\ndo only when possible. However, the profiler only shows as *very* minimal\neffect.", "code_diff": "@@ -870,13 +870,7 @@ int rsCStrSzStrCmp(cstr_t *pCS1, uchar *psz, size_t iLenSz)\n \t\t\t * length, so we need to actually check if they\n \t\t\t * are equal.\n \t\t\t */\n-\t\t\tregister size_t i;\n-\t\t\tfor(i = 0 ; i < iLenSz ; ++i) {\n-\t\t\t\tif(pCS1->pBuf[i] != psz[i])\n-\t\t\t\t\treturn pCS1->pBuf[i] - psz[i];\n-\t\t\t}\n-\t\t\t/* if we arrive here, the strings are equal */\n-\t\t\treturn 0;\n+\t\t\treturn strncmp((char*)pCS1->pBuf, (char*)psz, iLenSz);\n \t\t}\n \telse\n \t\treturn pCS1->iStrLen - iLenSz;\n", "changed_method_name": "rsCStrSzStrCmp"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/855b68e1be652b4c51052969a9550d33b2aec612", "commit_message": "optimize: re-use already computed value!", "code_diff": "@@ -401,12 +401,12 @@ evalPROPFILT(struct cnfstmt *stmt, msg_t *pMsg)\n \t\tbreak;\n \tcase FIOP_ISEQUAL:\n \t\tif(rsCStrSzStrCmp(stmt->d.s_propfilt.pCSCompValue,\n-\t\t\t\t  pszPropVal, ustrlen(pszPropVal)) == 0)\n+\t\t\t\t  pszPropVal, propLen) == 0)\n \t\t\tbRet = 1; /* process message! */\n \t\tbreak;\n \tcase FIOP_STARTSWITH:\n \t\tif(rsCStrSzStrStartsWithCStr(stmt->d.s_propfilt.pCSCompValue,\n-\t\t\t\t  pszPropVal, ustrlen(pszPropVal)) == 0)\n+\t\t\t\t  pszPropVal, propLen) == 0)\n \t\t\tbRet = 1; /* process message! */\n \t\tbreak;\n \tcase FIOP_REGEX:\n", "changed_method_name": "evalPROPFILT"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/bb9650eb583fa5fce62543a437e46456701b7695", "commit_message": "optimize: do not iterate over batch items if unneeded ;)", "code_diff": "@@ -852,6 +852,9 @@ static rsRetVal releaseBatch(action_t *pAction, batch_t *pBatch)\n \n \tASSERT(pAction != NULL);\n \n+\tif(pAction->eParamPassing == ACT_STRING_PASSING || pAction->eParamPassing == ACT_MSG_PASSING)\n+\t\tgoto done; /* we need to do nothing with these types! */\n+\n \tfor(i = 0 ; i < batchNumMsgs(pBatch) && !*(pBatch->pbShutdownImmediate) ; ++i) {\n \t\tpElem = &(pBatch->pElem[i]);\n \t\tif(batchIsValidElem(pBatch, i)) {\n@@ -871,10 +874,6 @@ static rsRetVal releaseBatch(action_t *pAction, batch_t *pBatch)\n \t\t\t\t\t}\n \t\t\t\t}\n \t\t\t\tbreak;\n-\t\t\tcase ACT_STRING_PASSING:\n-\t\t\tcase ACT_MSG_PASSING:\n-\t\t\t\t/* nothing to do in that case */\n-\t\t\t\tbreak;\n \t\t\tcase ACT_JSON_PASSING:\n \t\t\t\tfor(j = 0 ; j < pAction->iNumTpls ; ++j) {\n \t\t\t\t\tjson_object_put((struct json_object*)\n@@ -882,11 +881,15 @@ static rsRetVal releaseBatch(action_t *pAction, batch_t *pBatch)\n \t\t\t\t\tpElem->staticActParams[j] = NULL;\n \t\t\t\t}\n \t\t\t\tbreak;\n+\t\t\tcase ACT_STRING_PASSING:\n+\t\t\tcase ACT_MSG_PASSING:\n+\t\t\t\t/* can never happen, just to keep compiler happy! */\n+\t\t\t\tbreak;\n \t\t\t}\n \t\t}\n \t}\n \n-\tRETiRet;\n+done:\tRETiRet;\n }\n \n \n", "changed_method_name": "releaseBatch"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/123143d0f1f5e99b04f963c5d785a8f8918decdc", "commit_message": "optimize: another round of removing isdigit()", "code_diff": "@@ -362,7 +362,7 @@ processDataRcvd(tcps_sess_t *pThis, char c, struct syslogTime *stTime, time_t tt\n \tISOBJ_TYPE_assert(pThis, tcps_sess);\n \n \tif(pThis->inputState == eAtStrtFram) {\n-\t\tif(pThis->bSuppOctetFram && isdigit((int) c)) {\n+\t\tif(pThis->bSuppOctetFram && c >= '0' && c <= '9') {\n \t\t\tpThis->inputState = eInOctetCnt;\n \t\t\tpThis->iOctetsRemain = 0;\n \t\t\tpThis->eFraming = TCP_FRAMING_OCTET_COUNTING;\n@@ -373,7 +373,7 @@ processDataRcvd(tcps_sess_t *pThis, char c, struct syslogTime *stTime, time_t tt\n \t}\n \n \tif(pThis->inputState == eInOctetCnt) {\n-\t\tif(isdigit(c)) {\n+\t\tif(c >= '0' && c <= '9') { /* isdigit() the faster way */\n \t\t\tpThis->iOctetsRemain = pThis->iOctetsRemain * 10 + c - '0';\n \t\t} else { /* done with the octet count, so this must be the SP terminator */\n \t\t\tDBGPRINTF(\"TCP Message with octet-counter, size %d.\\n\", pThis->iOctetsRemain);\n", "changed_method_name": "processDataRcvd"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/39b35a32b4a45ccb6506e15b02780c30ca8c3973", "commit_message": "Improved field translate performance.\n\n\tmodified:   imjournal.c", "code_diff": "@@ -126,6 +126,7 @@ readjournal() {\n \tchar *sys_iden_help;\n \n \tconst void *get;\n+\tuchar *parse;\n \tchar *get2;\n \tsize_t length;\n \n@@ -149,7 +150,7 @@ readjournal() {\n \n \t/* Get message text */\n \tif (sd_journal_get_data(j, \"MESSAGE\", &get, &length) < 0) {\n-\t\tlogmsgInternal(NO_ERRCODE, LOG_SYSLOG|LOG_INFO, \"log message from journal doesn't have MESSAGE\", 0);\n+\t\tlogmsgInternal(NO_ERRCODE, LOG_SYSLOG|LOG_INFO, (uchar *)\"log message from journal doesn't have MESSAGE\", 0);\n \t\tiRet = RS_RET_OK;\n \t\tgoto ret;\n \t}\n@@ -212,21 +213,38 @@ readjournal() {\n \t\t/* get length of journal data prefix */\n \t\tprefixlen = ((char *)equal_sign - (char *)get);\n \n-\t\t/* translate name fields to lumberjack names XXX not very effective */\n-\t\tif (!strncmp(get, \"_PID\", 4)) {\n-\t\t\tname = strdup(\"pid\");\n-\t\t} else if (!strncmp(get, \"_GID\", 4)) {\n-\t\t\tname = strdup(\"gid\");\n-\t\t} else if (!strncmp(get, \"_UID\", 4)) {\n-\t\t\tname = strdup(\"uid\");\n-\t\t} else if (!strncmp(get, \"_COMM\", 5)) {\n-\t\t\tname = strdup(\"appname\");\n-\t\t} else if (!strncmp(get, \"_EXE\", 4)) {\n-\t\t\tname = strdup(\"exe\");\n-\t\t} else if (!strncmp(get, \"_CMDLINE\", 8)) {\n-\t\t\tname = strdup(\"cmd\");\n-\t\t} else {\n+\t\t/* translate name fields to lumberjack names */\n+\t\tparse = (uchar *)get;\n+\n+\t\tswitch (*parse)\n+\t\t{\n+\t\tcase '_':\n+\t\t\t++parse;\n+\t\t\tif (*parse == 'P') {\n+\t\t\t\tname = strdup(\"pid\");\n+\t\t\t} else if (*parse == 'G') {\n+\t\t\t\tname = strdup(\"gid\");\n+\t\t\t} else if (*parse == 'U') {\n+\t\t\t\tname = strdup(\"uid\");\n+\t\t\t} else if (*parse == 'E') {\n+\t\t\t\tname = strdup(\"exe\");\n+\t\t\t} else if (*parse == 'C') {\n+\t\t\t\tparse++;\n+\t\t\t\tif (*parse == 'O') {\n+\t\t\t\t\tname = strdup(\"appname\");\n+\t\t\t\t} else if (*parse == 'M') {\n+\t\t\t\t\tname = strdup(\"cmd\");\n+\t\t\t\t} else {\n+\t\t\t\t\tname = strndup(get, prefixlen);\n+\t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\tname = strndup(get, prefixlen);\n+\t\t\t}\n+\t\t\tbreak;\n+\n+\t\tdefault:\n \t\t\tname = strndup(get, prefixlen);\n+\t\t\tbreak;\n \t\t}\n \n \t\tif (name == NULL) {\n", "changed_method_name": "readjournal"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/33fe6e484c8b3f8aeaad4a7e4c417ac837a81aac", "commit_message": "imjournal: very slight optimization\n\n... well, it's actually questionable if it is a real optimization\nor not ;)", "code_diff": "@@ -239,25 +239,25 @@ readjournal() {\n \t\tcase '_':\n \t\t\t++parse;\n \t\t\tif (*parse == 'P') {\n-\t\t\t\tif (!strncmp(parse, \"PID=\", 4)) {\n+\t\t\t\tif (!strncmp(parse+1, \"ID=\", 4)) {\n \t\t\t\t\tname = strdup(\"pid\");\n \t\t\t\t} else {\n \t\t\t\t\tname = strndup(get, prefixlen);\n \t\t\t\t}\n \t\t\t} else if (*parse == 'G') {\n-\t\t\t\tif (!strncmp(parse, \"GID=\", 4)) {\n+\t\t\t\tif (!strncmp(parse+1, \"ID=\", 4)) {\n \t\t\t\t\tname = strdup(\"gid\");\n \t\t\t\t} else {\n \t\t\t\t\tname = strndup(get, prefixlen);\n \t\t\t\t}\n \t\t\t} else if (*parse == 'U') {\n-\t\t\t\tif (!strncmp(parse, \"UID=\", 4)) {\n+\t\t\t\tif (!strncmp(parse+1, \"ID=\", 4)) {\n \t\t\t\t\tname = strdup(\"uid\");\n \t\t\t\t} else {\n \t\t\t\t\tname = strndup(get, prefixlen);\n \t\t\t\t}\n \t\t\t} else if (*parse == 'E') {\n-\t\t\t\tif (!strncmp(parse, \"EXE=\", 4)) {\n+\t\t\t\tif (!strncmp(parse+1, \"XE=\", 4)) {\n \t\t\t\t\tname = strdup(\"exe\");\n \t\t\t\t} else {\n \t\t\t\t\tname = strndup(get, prefixlen);\n@@ -265,13 +265,13 @@ readjournal() {\n \t\t\t} else if (*parse == 'C') {\n \t\t\t\tparse++;\n \t\t\t\tif (*parse == 'O') {\n-\t\t\t\t\tif (!strncmp(parse, \"OMM=\", 4)) {\n+\t\t\t\t\tif (!strncmp(parse+1, \"MM=\", 4)) {\n \t\t\t\t\t\tname = strdup(\"appname\");\n \t\t\t\t\t} else {\n \t\t\t\t\t\tname = strndup(get, prefixlen);\n \t\t\t\t\t}\n \t\t\t\t} else if (*parse == 'M') {\n-\t\t\t\t\tif (!strncmp(parse, \"MDLINE=\", 7)) {\n+\t\t\t\t\tif (!strncmp(parse+1, \"DLINE=\", 7)) {\n \t\t\t\t\t\tname = strdup(\"cmd\");\n \t\t\t\t\t} else {\n \t\t\t\t\t\tname = strndup(get, prefixlen);\n", "changed_method_name": "readjournal"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/fa8ff7601de0340fbc0d3892b418a5dbb32a6e24", "commit_message": "slight optimizations: avoid unnecessary writes\n\nbut this happens only during config load, so no real gain", "code_diff": "@@ -543,8 +543,10 @@ rsRetVal cstrTrimTrailingWhiteSpace(cstr_t *pThis)\n \t\t--i;\n \t}\n \t/* i now is the new string length! */\n-\tpThis->iStrLen = i;\n-\tpThis->pBuf[pThis->iStrLen] = '\\0'; /* we always have this space */\n+\tif(i != pThis->iStrLen) {\n+\t\tpThis->iStrLen = i;\n+\t\tpThis->pBuf[pThis->iStrLen] = '\\0'; /* we always have this space */\n+\t}\n \n done:\treturn RS_RET_OK;\n }\n", "changed_method_name": "cstrTrimTrailingWhiteSpace"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/b9dcd4e434265821695865e18e9ca14fdc51c3f1", "commit_message": "bugfix: imudp could do 0-size calloc if no listeners are active at late stage\n\nThis was found by clang static analyzer and is extremely unlikely to\nhappen in practice, due to checks in earlier stages. But we did not\ninvestigate that in detail but rather add checks to be on the safe\nside. Note that this is not performance critical as it happens just\non startup.", "code_diff": "@@ -4,7 +4,7 @@\n  * NOTE: read comments in module-template.h to understand how this file\n  *       works!\n  *\n- * Copyright 2007-2014 Rainer Gerhards and Adiscon GmbH.\n+ * Copyright 2007-2015 Rainer Gerhards and Adiscon GmbH.\n  *\n  * This file is part of rsyslog.\n  *\n@@ -747,6 +747,13 @@ rsRetVal rcvMainLoop(struct wrkrInfo_s *pWrkr)\n \tnLstn = 0;\n \tfor(lstn = lcnfRoot ; lstn != NULL ; lstn = lstn->next)\n \t\t++nLstn;\n+\n+\tif(nLstn == 0) {\n+\t\terrmsg.LogError(errno, RS_RET_ERR,\n+\t\t\t\"imudp error: we have 0 listeners, terminating\"\n+\t\t\t\"worker thread\");\n+\t\tABORT_FINALIZE(RS_RET_ERR);\n+\t}\n \tCHKmalloc(udpEPollEvt = calloc(nLstn, sizeof(struct epoll_event)));\n \n #if defined(EPOLL_CLOEXEC) && defined(HAVE_EPOLL_CREATE1)\n", "changed_method_name": "rcvMainLoop"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/69e1be41ac23b429d841f6b7de49c0de03e108e3", "commit_message": "improve json variable performance\n\nWe use libfastjson's alternative hash function, which has been\nproven to be much faster than the default one (which stems\nback to libjson-c). This should bring an overall performance\nimprovement for all operations involving variable processing.\n\ncloses https://github.com/rsyslog/rsyslog/issues/848", "code_diff": "@@ -1636,6 +1636,8 @@ deinitAll(void)\n int\n main(int argc, char **argv)\n {\n+\t/* use faster hash function inside json lib */\n+\tjson_global_set_string_hash(JSON_C_STR_HASH_PERLLIKE);\n \tdbgClassInit();\n \tinitAll(argc, argv);\n \tsd_notify(0, \"READY=1\");\n", "changed_method_name": "main"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/4af7e0616618118cc1ed7deba6a7fcefeb4b4c08", "commit_message": "core/stream.c: very, very slightly speed up multiline reads", "code_diff": "@@ -934,8 +934,10 @@ strmReadMultiLine(strm_t *pThis, cstr_t **ppCStr, regex_t *preg, const sbool bEs\n \t\t\t\t} else {\n \t\t\t\t\tcstrAppendChar(pThis->prevMsgSegment, '\\n');\n \t\t\t\t}\n-\t\t\t\tCHKiRet(cstrAppendCStr(pThis->prevMsgSegment, thisLine));\n-\t\t\t\t/* we could do this faster, but for now keep it simple */\n+\t\t\t\tif(thisLine->iStrLen > 0) {\n+\t\t\t\t\tCHKiRet(cstrAppendCStr(pThis->prevMsgSegment, thisLine));\n+\t\t\t\t\t/* we could do this faster, but for now keep it simple */\n+\t\t\t\t}\n \n \t\t\t}\n \t\t}\n", "changed_method_name": "strmReadMultiLine"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/edb81c0283bbef29f05817062478c0a9e769269c", "commit_message": "conf optimizer: small improvement\n\nnow that we have NOP-removal, we can restructre if compression a\nbit to make it more straightforward", "code_diff": "@@ -4452,12 +4452,21 @@ cnfstmtOptimizeIf(struct cnfstmt *stmt)\n \tstruct cnffunc *func;\n \tstruct funcData_prifilt *prifilt;\n \n+\tassert(stmt->nodetype == S_IF);\n \texpr = stmt->d.s_if.expr = cnfexprOptimize(stmt->d.s_if.expr);\n-\tstmt->d.s_if.t_then = removeNOPs(stmt->d.s_if.t_then);\n-\tstmt->d.s_if.t_else = removeNOPs(stmt->d.s_if.t_else);\n \tstmt->d.s_if.t_then = cnfstmtOptimize(stmt->d.s_if.t_then);\n \tstmt->d.s_if.t_else = cnfstmtOptimize(stmt->d.s_if.t_else);\n \n+\tif(stmt->d.s_if.t_then == NULL && stmt->d.s_if.t_else == NULL) {\n+\t\t/* pointless if, probably constructed by config mgmt system */\n+\t\tDBGPRINTF(\"optimizer: if with both empty then and else - remove\\n\");\n+\t\tcnfexprDestruct(stmt->d.s_if.expr);\n+\t\t/* set to NOP, this will be removed in later stage */\n+\t\tstmt->nodetype = S_NOP;\n+\t\tgoto done;\n+\t}\n+\n+\tassert(stmt->nodetype == S_IF);\n \tif(stmt->d.s_if.expr->nodetype == 'F') {\n \t\tfunc = (struct cnffunc*)expr;\n \t\t   if(func->fID == CNFFUNC_PRIFILT) {\n@@ -4477,17 +4486,8 @@ cnfstmtOptimizeIf(struct cnfstmt *stmt)\n \t\t\t\t\tes_str2cstr(((struct cnfstringval*)func->expr[0])->estr, NULL);\n \t\t\tcnfexprDestruct(expr);\n \t\t\tcnfstmtOptimizePRIFilt(stmt);\n-\t\t\tgoto done; /* no longer an if! */\n \t\t}\n \t}\n-\tassert(stmt->nodetype == S_IF);\n-\tif(stmt->d.s_if.t_then == NULL && stmt->d.s_if.t_else == NULL) {\n-\t\t/* pointless if, probably constructed by config mgmt system */\n-\t\tDBGPRINTF(\"optimizer: if with both empty then and else - remove\\n\");\n-\t\tcnfexprDestruct(stmt->d.s_if.expr);\n-\t\t/* for now, let's set it to NOP (and correct that later on) */\n-\t\tstmt->nodetype = S_NOP;\n-\t}\n done:\treturn;\n }\n \n", "changed_method_name": "cnfstmtOptimizeIf"}
{"commit_url": "https://github.com/rsyslog/rsyslog/commit/f3106c538f04ada7d1d0b1d1117d8930b0ce12d0", "commit_message": "Increase UNIX socket backlog for performance under heavy load", "code_diff": "@@ -441,7 +441,7 @@ static rsRetVal startupUXSrv(ptcpsrv_t *pSrv) {\n \t\tABORT_FINALIZE(RS_RET_ERR_CRE_AFUX);\n \t}\n \n-\tif (listen(sock, 5) < 0) {\n+\tif (listen(sock, 511) < 0) {\n \t\terrmsg.LogError(errno, RS_RET_ERR_CRE_AFUX, \"imptcp: unix socket listen error\");\n \t\tABORT_FINALIZE(RS_RET_ERR_CRE_AFUX);\n \t}\n", "changed_method_name": "startupUXSrv"}
{"commit_url": "https://github.com/lvmteam/lvm2/commit/0dc73f7dbd49308b1864444d1decfaf8e10d2d81", "commit_message": "dmeventd: time scaling for status retry\n\nIn normal case it's too slow to wait 1 second for default.\nSo rather start with short time and increase sleep between status\nretesting.", "code_diff": "@@ -1649,7 +1649,7 @@ int monitor_dev_for_events(struct cmd_context *cmd, const struct logical_volume\n \n \t\t/* Check [un]monitor results */\n \t\t/* Try a couple times if pending, but not forever... */\n-\t\tfor (i = 0; i < 10; i++) {\n+\t\tfor (i = 0; i < 40; i++) {\n \t\t\tpending = 0;\n \t\t\tmonitored = seg->segtype->ops->target_monitored(seg, &pending);\n \t\t\tif (pending ||\n@@ -1659,7 +1659,7 @@ int monitor_dev_for_events(struct cmd_context *cmd, const struct logical_volume\n \t\t\t\t\t\t lv->vg->name, lv->name, monitor ? \"\" : \"un\");\n \t\t\telse\n \t\t\t\tbreak;\n-\t\t\tsleep(1);\n+\t\t\tusleep(10000 * i);\n \t\t}\n \n \t\tif (r)\n", "changed_method_name": "monitor_dev_for_events"}
{"commit_url": "https://github.com/lvmteam/lvm2/commit/bfeabea631782b3f0b8ec6494c4490663c412774", "commit_message": "raid: preload splitted LV only when active\n\nCheck splitted leg is active before preload.\n(Since splitmirrors currently only does work active raid volumes\nit's not a change for current code flow).\n\nMinor optimization included - when already positively checked\nfor raid image don't check again for raid metadata.", "code_diff": "@@ -1760,18 +1760,15 @@ static int _preload_detached_lv(struct logical_volume *lv, void *data)\n \tstruct detached_lv_data *detached = data;\n \tstruct lv_list *lvl_pre;\n \n-        /* Check and preload removed raid image leg */\n+\t/* Check and preload removed raid image leg or metadata */\n \tif (lv_is_raid_image(lv)) {\n \t\tif ((lvl_pre = find_lv_in_vg_by_lvid(detached->lv_pre->vg, &lv->lvid)) &&\n-\t\t    !lv_is_raid_image(lvl_pre->lv) &&\n+\t\t    !lv_is_raid_image(lvl_pre->lv) && lv_is_active(lv) &&\n \t\t    !_lv_preload(lvl_pre->lv, detached->laopts, detached->flush_required))\n \t\t\treturn_0;\n-\t}\n-\n-        /* Check and preload removed of raid metadata */\n-\tif (lv_is_raid_metadata(lv)) {\n+\t} else if (lv_is_raid_metadata(lv)) {\n \t\tif ((lvl_pre = find_lv_in_vg_by_lvid(detached->lv_pre->vg, &lv->lvid)) &&\n-\t\t    !lv_is_raid_metadata(lvl_pre->lv) &&\n+\t\t    !lv_is_raid_metadata(lvl_pre->lv) && lv_is_active(lv) &&\n \t\t    !_lv_preload(lvl_pre->lv, detached->laopts, detached->flush_required))\n \t\t\treturn_0;\n \t}\n", "changed_method_name": "_preload_detached_lv"}
{"commit_url": "https://github.com/lvmteam/lvm2/commit/5577f2f4f0a5518662b9cedb6a373ccb67a71917", "commit_message": "cleanup: || instead of |\n\nMore efficient with same result here.", "code_diff": "@@ -502,13 +502,13 @@ static int _ignore_suspended_snapshot_component(struct device *dev)\n \t\t\t\tlog_error(\"Incorrect snapshot table found\");\n \t\t\t\tgoto_out;\n \t\t\t}\n-\t\t\tr = r | _device_is_suspended(major1, minor1) | _device_is_suspended(major2, minor2);\n+\t\t\tr = r || _device_is_suspended(major1, minor1) || _device_is_suspended(major2, minor2);\n \t\t} else if (!strcmp(target_type, \"snapshot-origin\")) {\n \t\t\tif (sscanf(params, \"%d:%d\", &major1, &minor1) != 2) {\n \t\t\t\tlog_error(\"Incorrect snapshot-origin table found\");\n \t\t\t\tgoto_out;\n \t\t\t}\n-\t\t\tr = r | _device_is_suspended(major1, minor1);\n+\t\t\tr = r || _device_is_suspended(major1, minor1);\n \t\t}\n \t} while (next);\n \n", "changed_method_name": "_ignore_suspended_snapshot_component"}
{"commit_url": "https://github.com/lvmteam/lvm2/commit/6dd0bd0255d585feca61000432d2de9552ede4e0", "commit_message": "libdm-stats: fix dm_stats_delete_region() performance\n\nFix a silly bug in dm_stats_delete_region() that hugely inflates\nruntimes when deleting a large number of regions.\n\nFor ~50,000 regions this change reduces the runtime from 98s to\n6s on my test systems (a ~93% reduction).\n\nThe bug exists because dm_stats_delete_region() applies a truth\ntest to the return value of dm_stats_get_nr_areas(); this is\nnever correct usage - it will walk the entire region table and\ncalculate area counts for each region (which is roughly O(n^2)\nin the number of regions, as dm_stats_delete_region() is being\ncalled inside a region walk).\n\nAlthough the individual area calculation is not that costly,\nuselessly running anything 2,500,000,000 times over gets a bit\nslow.\n\nA much cheaper test (which is always true if the areas check is\ntrue) is to just test dm_stats_get_nr_regions() or dms->regions;\nif either is true it implies at least one area exists.\n\nOld:\n\n Performance counter stats for 'dmstats delete --allregions --alldevices':\n\n      98117.791458      task-clock (msec)         #    1.000 CPUs utilized\n               127      context-switches          #    0.001 K/sec\n                 3      cpu-migrations            #    0.000 K/sec\n             6,631      page-faults               #    0.068 K/sec\n   307,711,724,562      cycles                    #    3.136 GHz\n   544,762,959,577      instructions              #    1.77  insn per cycle\n    84,287,824,115      branches                  #  859.047 M/sec\n         2,538,875      branch-misses             #    0.00% of all branches\n\n      98.119578733 seconds time elapsed\n\nNew:\n\n Performance counter stats for 'dmstats delete --allregions --alldevices':\n\n       6427.251074      task-clock (msec)         #    1.000 CPUs utilized\n                 6      context-switches          #    0.001 K/sec\n                 0      cpu-migrations            #    0.000 K/sec\n             6,634      page-faults               #    0.001 M/sec\n    21,613,018,724      cycles                    #    3.363 GHz\n     3,794,755,445      instructions              #    0.18  insn per cycle\n       852,974,026      branches                  #  132.712 M/sec\n           808,625      branch-misses             #    0.09% of all branches\n\n       6.428953647 seconds time elapsed", "code_diff": "@@ -2051,7 +2051,7 @@ int dm_stats_delete_region(struct dm_stats *dms, uint64_t region_id)\n \t\tgoto bad;\n \t}\n \n-\tif (!dm_stats_get_nr_areas(dms)) {\n+\tif (!dm_stats_get_nr_regions(dms)) {\n \t\tlog_error(\"Could not delete region ID \" FMTu64 \": \"\n \t\t\t  \"no regions found\", region_id);\n \t\tgoto bad;\n", "changed_method_name": "dm_stats_delete_region"}
{"commit_url": "https://github.com/lvmteam/lvm2/commit/772834e40aef44a8f7bc884050e1b88087073706", "commit_message": "commands: optimize binary search\n\nSince there is a lot of options and lot of searches,\nuse binary search to keep strcmp at minimum.\n\nThe interesting part is - alphabetically sorted array contains\nduplicates and some of them are not the 'right anwer', so\nafter we find matching string but not matching long_ARG,\nwe may need to check if the surrouding strings are the right matching\none.\n\nThe single loops is used also for strictly define --foo_long\n(i.e. --stripes)  and just differs at final part.\n\nTODO1: replace strstr call with some flag (just like short_opt).\nTODO2: drop '--' from being stored and tests by strcmp.", "code_diff": "@@ -359,46 +359,57 @@ static int opt_str_to_num(struct command *cmd, char *str)\n \tchar long_name[MAX_LONG_OPT_NAME_LEN];\n \tchar *p;\n \tint i;\n+\tint first = 0, last = ARG_COUNT - 1, middle;\n \n-\t/*\n-\t * --foo_long means there are two args entries\n-\t * for --foo, one with a short option and one\n-\t * without, and we want the one without the\n-\t * short option.\n-\t */\n-\tif (strstr(str, \"_long\")) {\n-\t\tmemset(long_name, 0, sizeof(long_name));\n-\t\tstrncpy(long_name, str, MAX_LONG_OPT_NAME_LEN-1);\n-\t\tif ((p = strstr(long_name, \"_long\")))\n-\t\t\t*p = '\\0';\n-\n-\t\tfor (i = 0; i < ARG_COUNT; i++) {\n-\t\t\tif (!opt_names[i].long_opt)\n-\t\t\t\tcontinue;\n-\t\t\t/* skip anything with a short opt */\n-\t\t\tif (opt_names[i].short_opt)\n-\t\t\t\tcontinue;\n-\t\t\tif (!strcmp(opt_names[i].long_opt, long_name))\n-\t\t\t\treturn opt_names[i].opt_enum;\n-\t\t}\n+\tdm_strncpy(long_name, str, sizeof(long_name));\n \n-\t\tlog_error(\"Parsing command defs: unknown opt str: %s %s\", str, long_name);\n-\t\tcmd->cmd_flags |= CMD_FLAG_PARSE_ERROR;\n-\t\treturn ARG_UNUSED;\n-\t}\n+\tif ((p = strstr(long_name, \"_long\")))\n+\t\t/*\n+\t\t * --foo_long means there are two args entries\n+\t\t * for --foo, one with a short option and one\n+\t\t * without, and we want the one without the\n+\t\t * short option (== 0).\n+\t\t */\n+\t\t*p = '\\0';\n \n-\tfor (i = 0; i < ARG_COUNT; i++) {\n-\t\tif (!opt_names[i].long_opt)\n-\t\t\tcontinue;\n-\t\t/* These are only selected using --foo_long */\n-\t\tif (strstr(opt_names[i].name, \"_long_ARG\"))\n-\t\t\tcontinue;\n-\t\tif (!strcmp(opt_names[i].long_opt, str))\n-\t\t\treturn opt_names[i].opt_enum;\n+\t/* Binary search in sorted array of long options (with duplicates) */\n+\twhile (first <= last) {\n+\t\tmiddle = first + (last - first) / 2;\n+\t\tif ((i = strcmp(opt_names_alpha[middle]->long_opt, long_name)) < 0)\n+\t\t\tfirst = middle + 1;\n+\t\telse if (i > 0)\n+\t\t\tlast = middle - 1;\n+\t\telse {\n+\t\t\t/* Matching long option string found.\n+\t\t\t * As sorted array contains duplicates, we need to also\n+\t\t\t * check left & right side for possible match\n+\t\t\t */\n+\t\t\tfor (i = middle;;) {\n+\t\t\t\tif ((!p && !strstr(opt_names_alpha[i]->name, \"_long_ARG\")) ||\n+\t\t\t\t    (p && !opt_names_alpha[i]->short_opt))\n+\t\t\t\t\treturn opt_names_alpha[i]->opt_enum; /* Found */\n+\t\t\t\t/* Check if there is something on the 'left-side' */\n+\t\t\t\tif ((i <= first) || strcmp(opt_names_alpha[--i]->long_opt, long_name))\n+\t\t\t\t\tbreak;\n+\t\t\t}\n+\n+\t\t\t/* Nothing on the left, so look on the 'right-side' */\n+\t\t\tfor (i = middle + 1; i <= last; ++i) {\n+\t\t\t\tif (strcmp(opt_names_alpha[i]->long_opt, long_name))\n+\t\t\t\t\tbreak;\n+\t\t\t\tif ((!p && !strstr(opt_names_alpha[i]->name, \"_long_ARG\")) ||\n+\t\t\t\t    (p && !opt_names_alpha[i]->short_opt))\n+\t\t\t\t\treturn opt_names_alpha[i]->opt_enum; /* Found */\n+\t\t\t}\n+\n+\t\t\tbreak; /* Nothing... */\n+\t\t}\n \t}\n \n-\tlog_error(\"Parsing command defs: unknown opt str: \\\"%s\\\"\", str);\n+\tlog_error(\"Parsing command defs: unknown opt str: \\\"%s\\\"%s%s.\",\n+\t\t  str, p ? \" \": \"\", p ? long_name : \"\");\n \tcmd->cmd_flags |= CMD_FLAG_PARSE_ERROR;\n+\n \treturn ARG_UNUSED;\n }\n \n", "changed_method_name": "opt_str_to_num"}
{"commit_url": "https://github.com/lvmteam/lvm2/commit/2c4e8254de59579a84b6c1f3dcc66868b3e9ef34", "commit_message": "man-generator: enhance performance\n\nSet block buffering on stdout to\nsave ~30% time generating manuals.", "code_diff": "@@ -3418,13 +3418,17 @@ static void _print_man_secondary(char *name)\n \t}\n }\n \n+#define\tSTDOUT_BUF_SIZE\t (MAX_MAN_DESC + 4 * 1024)\n+\n int main(int argc, char *argv[])\n {\n \tchar *cmdname = NULL;\n \tchar *desfile = NULL;\n+\tchar *stdout_buf;\n \tint primary = 0;\n \tint secondary = 0;\n-\tint r = 1;\n+\tint r = 0;\n+\tsize_t sz = STDOUT_BUF_SIZE;\n \n \tstatic struct option long_options[] = {\n \t\t{\"primary\", no_argument, 0, 'p' },\n@@ -3434,6 +3438,11 @@ int main(int argc, char *argv[])\n \n \tmemset(&commands, 0, sizeof(commands));\n \n+\tif (!(stdout_buf = dm_malloc(sz)))\n+\t\tlog_error(\"Failed to allocate stdout buffer; carrying on with default buffering.\");\n+\telse\n+\t\tsetbuffer(stdout, stdout_buf, sz);\n+\n \twhile (1) {\n \t\tint c;\n \t\tint option_index = 0;\n@@ -3456,14 +3465,14 @@ int main(int argc, char *argv[])\n \n \tif (!primary && !secondary) {\n \t\tlog_error(\"Usage: %s --primary|--secondary <command> [/path/to/description-file].\", argv[0]);\n-\t\tgoto out;\n+\t\tgoto out_free;\n \t}\n \n \tif (optind < argc)\n \t\tcmdname = strdup(argv[optind++]);\n \telse {\n \t\tlog_error(\"Missing command name.\");\n-\t\tgoto out;\n+\t\tgoto out_free;\n \t}\n \n \tif (optind < argc)\n@@ -3477,10 +3486,15 @@ int main(int argc, char *argv[])\n \n \tif (primary)\n \t\tr = _print_man(cmdname, desfile, secondary);\n-\telse if (secondary)\n+\telse if (secondary) {\n+\t\tr = 1;\n \t\t_print_man_secondary(cmdname);\n+\t}\n+\n+out_free:\n+\tif (stdout_buf)\n+\t\tfree(stdout_buf);\n \n-out:\n \texit(r ? EXIT_SUCCESS: EXIT_FAILURE);\n }\n \n", "changed_method_name": "main"}
{"commit_url": "https://github.com/lvmteam/lvm2/commit/4dc81848034f4f5edb02335af03e50f45c3977f0", "commit_message": "suspend: optimize generated list\n\nAvoid adding same LV multiple times into the list.\nJust saves couple extra calls and ioctls and makes log shorter.", "code_diff": "@@ -2089,7 +2089,7 @@ static int _lv_suspend(struct cmd_context *cmd, const char *lvid_s,\n \tconst struct logical_volume *pvmove_lv = NULL;\n \tconst struct logical_volume *lv_to_free = NULL;\n \tconst struct logical_volume *lv_pre_to_free = NULL;\n-\tstruct logical_volume *lv_pre_tmp;\n+\tstruct logical_volume *lv_pre_tmp, *lv_tmp;\n \tstruct seg_list *sl;\n \tstruct lv_segment *snap_seg;\n \tstruct lvinfo info;\n@@ -2098,6 +2098,7 @@ static int _lv_suspend(struct cmd_context *cmd, const char *lvid_s,\n \tstruct dm_pool *mem = NULL;\n \tstruct dm_list suspend_lvs;\n \tstruct lv_list *lvl;\n+\tint found;\n \n \tif (!activation())\n \t\treturn 1;\n@@ -2247,19 +2248,28 @@ static int _lv_suspend(struct cmd_context *cmd, const char *lvid_s,\n \t\t/* Prepare list of all LVs for suspend ahead */\n \t\tdm_list_init(&suspend_lvs);\n \t\tdm_list_iterate_items(sl, &pvmove_lv->segs_using_this_lv) {\n+\t\t\tlv_tmp = sl->seg->lv;\n+\t\t\tif (lv_is_cow(lv_tmp))\n+\t\t\t\t/* Never suspend COW, always has to be origin */\n+\t\t\t\tlv_tmp = origin_from_cow(lv_tmp);\n+\t\t\tfound = 0;\n+\t\t\tdm_list_iterate_items(lvl, &suspend_lvs)\n+\t\t\t\tif (strcmp(lvl->lv->name, lv_tmp->name) == 0) {\n+\t\t\t\t\tfound = 1;\n+\t\t\t\t\tbreak;\n+\t\t\t\t}\n+\t\t\tif (found)\n+\t\t\t\tcontinue; /* LV is already in the list */\n \t\t\tif (!(lvl = dm_pool_alloc(mem, sizeof(*lvl)))) {\n \t\t\t\tlog_error(\"lv_list alloc failed.\");\n \t\t\t\tgoto out;\n \t\t\t}\n \t\t\t/* Look for precommitted LV name in commmitted VG */\n-\t\t\tif (!(lvl->lv = find_lv(lv->vg, sl->seg->lv->name))) {\n+\t\t\tif (!(lvl->lv = find_lv(lv->vg, lv_tmp->name))) {\n \t\t\t\tlog_error(INTERNAL_ERROR \"LV %s missing from preload metadata.\",\n-\t\t\t\t\t  display_lvname(sl->seg->lv));\n+\t\t\t\t\t  display_lvname(lv_tmp));\n \t\t\t\tgoto out;\n \t\t\t}\n-\t\t\t/* Never suspend COW, always has to be origin */\n-\t\t\tif (lv_is_cow(lvl->lv))\n-\t\t\t\tlvl->lv = origin_from_cow(lvl->lv);\n \t\t\tdm_list_add(&suspend_lvs, &lvl->list);\n \t\t}\n \t\tdm_list_iterate_items(lvl, &suspend_lvs)\n", "changed_method_name": "_lv_suspend"}
{"commit_url": "https://github.com/llvm-mirror/llvm/commit/1610bcf8d92427d2c4cc34c632f3525a2b153e65", "commit_message": "[MemoryDepAnalysis] Fix compile time slowdown\n\n- Problem\nOne program takes ~3min to compile under -O2. This happens after a certain\nfunction A is inlined ~700 times in a function B, inserting thousands of new\nBBs. This leads to 80% of the compilation time spent in\nGVN::processNonLocalLoad and\nMemoryDependenceAnalysis::getNonLocalPointerDependency, while searching for\nnonlocal information for basic blocks.\n\nUsually, to avoid spending a long time to process nonlocal loads, GVN bails out\nif it gets more than 100 deps as a result from\nMD->getNonLocalPointerDependency.  However this only happens *after* all\nnonlocal information for BBs have been computed, which is the bottleneck in\nthis scenario. For instance, there are 8280 times where\ngetNonLocalPointerDependency returns deps with more than 100 bbs and from\nthose, 600 times it returns more than 1000 blocks.\n\n- Solution\nBail out early during the nonlocal info computation whenever we reach a\nspecified threshold.  This patch proposes a 100 BBs threshold, it also\nreduces the compile time from 3min to 23s.\n\n- Testing\nThe test-suite presented no compile nor execution time regressions.\n\nSome numbers from my machine (x86_64 darwin):\n - 17s under -Oz (which avoids inlining).\n - 1.3s under -O1.\n - 2m51s under -O2 ToT\n *** 23s under -O2 w/ Result.size() > 100\n - 1m54s under -O2 w/ Result.size() > 500\n\nWith NumResultsLimit = 100, GVN yields the same outcome as in the\nunlimited 3min version.\n\nhttp://reviews.llvm.org/D5532\nrdar://problem/18188041\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@218792 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -51,6 +51,9 @@ STATISTIC(NumCacheCompleteNonLocalPtr,\n // Limit for the number of instructions to scan in a block.\n static const int BlockScanLimit = 100;\n \n+// Limit on the number of memdep results to process.\n+static const int NumResultsLimit = 100;\n+\n char MemoryDependenceAnalysis::ID = 0;\n \n // Register this pass...\n@@ -1133,6 +1136,25 @@ getNonLocalPointerDepFromBB(const PHITransAddr &Pointer,\n   while (!Worklist.empty()) {\n     BasicBlock *BB = Worklist.pop_back_val();\n \n+    // If we do process a large number of blocks it becomes very expensive and\n+    // likely it isn't worth worrying about\n+    if (Result.size() > NumResultsLimit) {\n+      Worklist.clear();\n+      // Sort it now (if needed) so that recursive invocations of\n+      // getNonLocalPointerDepFromBB and other routines that could reuse the\n+      // cache value will only see properly sorted cache arrays.\n+      if (Cache && NumSortedEntries != Cache->size()) {\n+        SortNonLocalDepInfoCache(*Cache, NumSortedEntries);\n+        NumSortedEntries = Cache->size();\n+      }\n+      // Since we bail out, the \"Cache\" set won't contain all of the\n+      // results for the query.  This is ok (we can still use it to accelerate\n+      // specific block queries) but we can't do the fastpath \"return all\n+      // results from the set\".  Clear out the indicator for this.\n+      CacheInfo->Pair = BBSkipFirstBlockPair();\n+      return true;\n+    }\n+\n     // Skip the first block if we have it.\n     if (!SkipFirstBlock) {\n       // Analyze the dependency of *Pointer in FromBB.  See if we already have\n", "changed_method_name": "MemoryDependenceAnalysis::getNonLocalPointerDepFromBB"}
{"commit_url": "https://github.com/llvm-mirror/llvm/commit/ab1f4ef9a2b7200c20a98fe9882656752f4452d5", "commit_message": "Add some optional passes around the vectorizer to both better prepare\nthe IR going into it and to clean up the IR produced by the vectorizers.\n\nNote that these are *off by default* right now while folks collect data\non whether the performance tradeoff is reasonable.\n\nIn a build of the 'opt' binary, I see about 2% compile time regression\ndue to this change on average. This is in my mind essentially the worst\nexpected case: very little of the opt binary is going to *benefit* from\nthese extra passes.\n\nI've seen several benchmarks improve in performance my small amounts due\nto running these passes, and there are certain (rare) cases where these\npasses make a huge difference by either enabling the vectorizer at all\nor by hoisting runtime checks out of the outer loop. My primary\nmotivation is to prevent people from seeing runtime check overhead in\nbenchmarks where the existing passes and optimizers would be able to\neliminate that.\n\nI've chosen the sequence of passes based on the kinds of things that\nseem likely to be relevant for the code at each stage: rotaing loops for\nthe vectorizer, finding correlated values, loop invariants, and\nunswitching opportunities from any runtime checks, and cleaning up\ncommonalities exposed by the SLP vectorizer.\n\nI'll be pinging existing threads where some of these issues have come up\nand will start new threads to get folks to benchmark and collect data on\nwhether this is the right tradeoff or we should do something else.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@219644 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -48,6 +48,10 @@ UseGVNAfterVectorization(\"use-gvn-after-vectorization\",\n   cl::init(false), cl::Hidden,\n   cl::desc(\"Run GVN instead of Early CSE after vectorization passes\"));\n \n+static cl::opt<bool> ExtraVectorizerPasses(\n+    \"extra-vectorizer-passes\", cl::init(false), cl::Hidden,\n+    cl::desc(\"Run cleanup optimization passes after vectorization.\"));\n+\n static cl::opt<bool> UseNewSROA(\"use-new-sroa\",\n   cl::init(true), cl::Hidden,\n   cl::desc(\"Enable the new, experimental SROA pass\"));\n@@ -283,6 +287,13 @@ void PassManagerBuilder::populateModulePassManager(PassManagerBase &MPM) {\n   // pass manager that we are specifically trying to avoid. To prevent this\n   // we must insert a no-op module pass to reset the pass manager.\n   MPM.add(createBarrierNoopPass());\n+\n+  // Re-rotate loops in all our loop nests. These may have fallout out of\n+  // rotated form due to GVN or other transformations, and the vectorizer relies\n+  // on the rotated form.\n+  if (ExtraVectorizerPasses)\n+    MPM.add(createLoopRotatePass());\n+\n   MPM.add(createLoopVectorizePass(DisableUnrollLoops, LoopVectorize));\n   // FIXME: Because of #pragma vectorize enable, the passes below are always\n   // inserted in the pipeline, even when the vectorizer doesn't run (ex. when\n@@ -290,10 +301,29 @@ void PassManagerBuilder::populateModulePassManager(PassManagerBase &MPM) {\n   // as function calls, so that we can only pass them when the vectorizer\n   // changed the code.\n   MPM.add(createInstructionCombiningPass());\n+  if (OptLevel > 1 && ExtraVectorizerPasses) {\n+    // At higher optimization levels, try to clean up any runtime overlap and\n+    // alignment checks inserted by the vectorizer. We want to track correllated\n+    // runtime checks for two inner loops in the same outer loop, fold any\n+    // common computations, hoist loop-invariant aspects out of any outer loop,\n+    // and unswitch the runtime checks if possible. Once hoisted, we may have\n+    // dead (or speculatable) control flows or more combining opportunities.\n+    MPM.add(createEarlyCSEPass());\n+    MPM.add(createCorrelatedValuePropagationPass());\n+    MPM.add(createInstructionCombiningPass());\n+    MPM.add(createLICMPass());\n+    MPM.add(createLoopUnswitchPass(SizeLevel || OptLevel < 3));\n+    MPM.add(createCFGSimplificationPass());\n+    MPM.add(createInstructionCombiningPass());\n+  }\n \n   if (RunSLPAfterLoopVectorization) {\n-    if (SLPVectorize)\n+    if (SLPVectorize) {\n       MPM.add(createSLPVectorizerPass());   // Vectorize parallel scalar chains.\n+      if (OptLevel > 1 && ExtraVectorizerPasses) {\n+        MPM.add(createEarlyCSEPass());\n+      }\n+    }\n \n     if (BBVectorize) {\n       MPM.add(createBBVectorizePass());\n@@ -312,6 +342,7 @@ void PassManagerBuilder::populateModulePassManager(PassManagerBase &MPM) {\n \n   addExtensionsToPM(EP_Peephole, MPM);\n   MPM.add(createCFGSimplificationPass());\n+  MPM.add(createInstructionCombiningPass());\n \n   if (!DisableUnrollLoops)\n     MPM.add(createLoopUnrollPass());    // Unroll small loops\n", "changed_method_name": "PassManagerBuilder::populateModulePassManager"}
{"commit_url": "https://github.com/llvm-mirror/llvm/commit/a9fbbb48bcc56354681fc2ead593a9861bfec699", "commit_message": "Small optimization: once the size is know, we don't have to call fillCurWord.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@221891 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -227,8 +227,8 @@ public:\n   bool AtEndOfStream() {\n     if (BitsInCurWord != 0)\n       return false;\n-    if (Size != 0 && Size == NextChar)\n-      return true;\n+    if (Size != 0)\n+      return Size == NextChar;\n     fillCurWord();\n     return BitsInCurWord == 0;\n   }\n", "changed_method_name": "llvm::BitstreamCursor::AtEndOfStream"}
{"commit_url": "https://github.com/llvm-mirror/llvm/commit/f28cb39e4ca07c387dd270ce123753f898a75d5c", "commit_message": "[GMR] Switch to a DenseMap and clean up the iteration loop. NFC.\n\nSince we have to iterate this map not that infrequently, we should use\na map that is efficient for iteration. It is also almost certainly much\nfaster for lookups as well. There is more to do in terms of reducing the\nwasted overhead of GMR's runtime though. Not sure how much is worthwhile\nthough.\n\nThe loop improvements should hopefully address the code review that\nDuncan gave when he saw this code as I moved it around.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@242891 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -97,7 +97,7 @@ class GlobalsModRef : public ModulePass, public AliasAnalysis {\n \n   /// AllocsForIndirectGlobals - If an instruction allocates memory for an\n   /// indirect global, this map indicates which one.\n-  std::map<const Value *, const GlobalValue *> AllocsForIndirectGlobals;\n+  DenseMap<const Value *, const GlobalValue *> AllocsForIndirectGlobals;\n \n   /// FunctionInfo - For each function, keep track of what globals are\n   /// modified or read.\n@@ -120,16 +120,11 @@ class GlobalsModRef : public ModulePass, public AliasAnalysis {\n           // any AllocRelatedValues for it.\n           if (GMR.IndirectGlobals.erase(GV)) {\n             // Remove any entries in AllocsForIndirectGlobals for this global.\n-            for (std::map<const Value *, const GlobalValue *>::iterator\n-                     I = GMR.AllocsForIndirectGlobals.begin(),\n-                     E = GMR.AllocsForIndirectGlobals.end();\n-                 I != E;) {\n-              if (I->second == GV) {\n-                GMR.AllocsForIndirectGlobals.erase(I++);\n-              } else {\n-                ++I;\n-              }\n-            }\n+            for (auto I = GMR.AllocsForIndirectGlobals.begin(),\n+                      E = GMR.AllocsForIndirectGlobals.end();\n+                 I != E; ++I)\n+              if (I->second == GV)\n+                GMR.AllocsForIndirectGlobals.erase(I);\n           }\n         }\n       }\n", "changed_method_name": "GlobalsModRef::DeletionCallbackHandle::deleted"}
{"commit_url": "https://github.com/llvm-mirror/llvm/commit/c5374d2ba55eb0b28ae250d044a652c09b15d870", "commit_message": "[PM] Use PoisoningVH correctly when merely deleting entries in a map\nwith it.\n\nThis code was dereferencing the PoisoningVH which isn't allowed once it\nis poisoned. But the code itself really doesn't need to access the\npointer, it is just doing the safe stuff of clearing out data structures\nkeyed on the pointer value.\n\nChange the code to use iterators to erase directly from a DenseMap. This\nis also substantially more efficient as it avoids lots of hashing and\nlookups to do the erasure. DenseMap supports iterating behind the\niteration which is fairly easy to implement.\n\nSadly, I don't have a test case here. I'm not even close and I don't\nknow that I ever will be. The issue is that several of the tricky\naspects of fixing this only show up when you cause the stack's\nSmallVector to be in *EXACTLY* the right location. I only ever got\na reproduction for those with Clang, and only with *exactly* the right\ncommand line flags. Any adjustment, even to seemingly unrelated flags,\nwould make partial and half-way solutions magically start to \"work\". In\ngood news, all of this was caught with the LLVM test suite. Also, there\nis no *specific* code here that is untested, just that the old pattern\nof code won't immediately fail on any test case I've managed to\ncontrive.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@293160 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -459,15 +459,15 @@ namespace {\n }\n \n void LazyValueInfoCache::eraseValue(Value *V) {\n-  SmallVector<AssertingVH<BasicBlock>, 4> ToErase;\n-  for (auto &I : OverDefinedCache) {\n-    SmallPtrSetImpl<Value *> &ValueSet = I.second;\n+  for (auto I = OverDefinedCache.begin(), E = OverDefinedCache.end(); I != E;) {\n+    // Copy and increment the iterator immediately so we can erase behind\n+    // ourselves.\n+    auto Iter = I++;\n+    SmallPtrSetImpl<Value *> &ValueSet = Iter->second;\n     ValueSet.erase(V);\n     if (ValueSet.empty())\n-      ToErase.push_back(&*I.first);\n+      OverDefinedCache.erase(Iter);\n   }\n-  for (auto &BB : ToErase)\n-    OverDefinedCache.erase(&*BB);\n \n   ValueCache.erase(V);\n }\n", "changed_method_name": "LazyValueInfoCache::eraseValue"}
{"commit_url": "https://github.com/llvm-mirror/llvm/commit/1ecf0813db3b6e9a13d05fa891023ffef6b3abf9", "commit_message": "[DAGCombine] Use APInt::operator|(uint64_t) instead of creating a temporary APInt and calling APInt::Or. NFC\n\nThis is more efficient by itself. But this is prep for a future patch that may remove APInt::Or while making operator| support rvalue references similar to add/sub.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@296981 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -2529,12 +2529,12 @@ SDValue SelectionDAGLegalize::ExpandBITREVERSE(SDValue Op, const SDLoc &dl) {\n     APInt MaskHi4(Sz, 0), MaskHi2(Sz, 0), MaskHi1(Sz, 0);\n     APInt MaskLo4(Sz, 0), MaskLo2(Sz, 0), MaskLo1(Sz, 0);\n     for (unsigned J = 0; J != Sz; J += 8) {\n-      MaskHi4 = MaskHi4.Or(APInt(Sz, 0xF0ull << J));\n-      MaskLo4 = MaskLo4.Or(APInt(Sz, 0x0Full << J));\n-      MaskHi2 = MaskHi2.Or(APInt(Sz, 0xCCull << J));\n-      MaskLo2 = MaskLo2.Or(APInt(Sz, 0x33ull << J));\n-      MaskHi1 = MaskHi1.Or(APInt(Sz, 0xAAull << J));\n-      MaskLo1 = MaskLo1.Or(APInt(Sz, 0x55ull << J));\n+      MaskHi4 = MaskHi4 | (0xF0ull << J);\n+      MaskLo4 = MaskLo4 | (0x0Full << J);\n+      MaskHi2 = MaskHi2 | (0xCCull << J);\n+      MaskLo2 = MaskLo2 | (0x33ull << J);\n+      MaskHi1 = MaskHi1 | (0xAAull << J);\n+      MaskLo1 = MaskLo1 | (0x55ull << J);\n     }\n \n     // BSWAP if the type is wider than a single byte.\n", "changed_method_name": "SelectionDAGLegalize::ExpandBITREVERSE"}
{"commit_url": "https://github.com/llvm-mirror/llvm/commit/ffc893deb7106ee0c541b44ef41506a32e1e8350", "commit_message": "FunctionAttrs: Skip it if the effective SCC (ignoring optnone functions) is empty\n\nMinor optimization but mostly simplifies my debugging so I'm not dealing\nwith empty SCCNodeSets while investigating issues in this optimization.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@304597 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -1188,6 +1188,10 @@ static bool runImpl(CallGraphSCC &SCC, AARGetterT AARGetter) {\n     SCCNodes.insert(F);\n   }\n \n+  // Skip it if the SCC only contains optnone functions.\n+  if (SCCNodes.empty())\n+    return Changed;\n+\n   Changed |= addArgumentReturnedAttrs(SCCNodes);\n   Changed |= addReadAttrs(SCCNodes, AARGetter);\n   Changed |= addArgumentAttrs(SCCNodes);\n", "changed_method_name": "runImpl"}
{"commit_url": "https://github.com/llvm-mirror/llvm/commit/3d019d384a400c6ef66164dcb3abe4d8d846308f", "commit_message": "[Dominators] Use Semi-NCA instead of SLT to calculate dominators\n\nSummary:\nThis patch makes GenericDomTreeConstruction use the Semi-NCA algorithm instead of Simple Lengauer-Tarjan.\n\nAs described in `RFC: Dynamic dominators`, Semi-NCA offers slightly better performance than SLT. What's more important, it can be extended to perform incremental updates on already constructed dominator trees.\n\nThe patch passes check-all, llvm test suite and is able to boostrap clang. I also wasn't able to observe any compilation time regressions.\n\nReviewers: sanjoy, dberlin, chandlerc, grosser\n\nReviewed By: dberlin\n\nSubscribers: llvm-commits\n\nDifferential Revision: https://reviews.llvm.org/D34258\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@306437 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -10,10 +10,11 @@\n ///\n /// Generic dominator tree construction - This file provides routines to\n /// construct immediate dominator information for a flow-graph based on the\n-/// algorithm described in this document:\n+/// Semi-NCA algorithm described in this dissertation:\n ///\n-///   A Fast Algorithm for Finding Dominators in a Flowgraph\n-///   T. Lengauer & R. Tarjan, ACM TOPLAS July 1979, pgs 121-141.\n+///   Linear-Time Algorithms for Dominators and Related Problems\n+///   Loukas Georgiadis, Princeton University, November 2005, pp. 21-23:\n+///   ftp://ftp.cs.princeton.edu/reports/2005/737.pdf\n ///\n /// This implements the O(n*log(n)) versions of EVAL and LINK, because it turns\n /// out that the theoretically slower O(n*log(n)) implementation is actually\n@@ -169,39 +170,22 @@ void Calculate(DominatorTreeBaseByGraphTraits<GraphTraits<NodeT>> &DT,\n     N = DFSPass<GraphT>(DT, DT.Roots[0], N);\n   }\n \n-  // it might be that some blocks did not get a DFS number (e.g., blocks of\n+  // It might be that some blocks did not get a DFS number (e.g., blocks of\n   // infinite loops). In these cases an artificial exit node is required.\n   MultipleRoots |= (DT.isPostDominator() && N != GraphTraits<FuncT*>::size(&F));\n \n-  // When naively implemented, the Lengauer-Tarjan algorithm requires a separate\n-  // bucket for each vertex. However, this is unnecessary, because each vertex\n-  // is only placed into a single bucket (that of its semidominator), and each\n-  // vertex's bucket is processed before it is added to any bucket itself.\n-  //\n-  // Instead of using a bucket per vertex, we use a single array Buckets that\n-  // has two purposes. Before the vertex V with preorder number i is processed,\n-  // Buckets[i] stores the index of the first element in V's bucket. After V's\n-  // bucket is processed, Buckets[i] stores the index of the next element in the\n-  // bucket containing V, if any.\n-  SmallVector<unsigned, 32> Buckets;\n-  Buckets.resize(N + 1);\n-  for (unsigned i = 1; i <= N; ++i)\n-    Buckets[i] = i;\n+  // Initialize IDoms to spanning tree parents.\n+  for (unsigned i = 1; i <= N; ++i) {\n+    const NodePtr V = DT.Vertex[i];\n+    DT.IDoms[V] = DT.Vertex[DT.Info[V].Parent];\n+  }\n \n+  // Step #2: Calculate the semidominators of all vertices.\n   for (unsigned i = N; i >= 2; --i) {\n     NodePtr W = DT.Vertex[i];\n     auto &WInfo = DT.Info[W];\n \n-    // Step #2: Implicitly define the immediate dominator of vertices\n-    for (unsigned j = i; Buckets[j] != i; j = Buckets[j]) {\n-      NodePtr V = DT.Vertex[Buckets[j]];\n-      NodePtr U = Eval<GraphT>(DT, V, i + 1);\n-      DT.IDoms[V] = DT.Info[U].Semi < i ? U : W;\n-    }\n-\n-    // Step #3: Calculate the semidominators of all vertices\n-\n-    // initialize the semi dominator to point to the parent node\n+    // Initialize the semi dominator to point to the parent node.\n     WInfo.Semi = WInfo.Parent;\n     for (const auto &N : inverse_children<NodeT>(W))\n       if (DT.Info.count(N)) { // Only if this predecessor is reachable!\n@@ -209,32 +193,22 @@ void Calculate(DominatorTreeBaseByGraphTraits<GraphTraits<NodeT>> &DT,\n         if (SemiU < WInfo.Semi)\n           WInfo.Semi = SemiU;\n       }\n-\n-    // If V is a non-root vertex and sdom(V) = parent(V), then idom(V) is\n-    // necessarily parent(V). In this case, set idom(V) here and avoid placing\n-    // V into a bucket.\n-    if (WInfo.Semi == WInfo.Parent) {\n-      DT.IDoms[W] = DT.Vertex[WInfo.Parent];\n-    } else {\n-      Buckets[i] = Buckets[WInfo.Semi];\n-      Buckets[WInfo.Semi] = i;\n-    }\n   }\n \n-  if (N >= 1) {\n-    NodePtr Root = DT.Vertex[1];\n-    for (unsigned j = 1; Buckets[j] != 1; j = Buckets[j]) {\n-      NodePtr V = DT.Vertex[Buckets[j]];\n-      DT.IDoms[V] = Root;\n-    }\n-  }\n \n-  // Step #4: Explicitly define the immediate dominator of each vertex\n+  // Step #3: Explicitly define the immediate dominator of each vertex.\n+  //          IDom[i] = NCA(SDom[i], SpanningTreeParent(i)).\n+  // Note that the parents were stored in IDoms and later got invalidated during\n+  // path compression in Eval.\n   for (unsigned i = 2; i <= N; ++i) {\n-    NodePtr W = DT.Vertex[i];\n-    NodePtr &WIDom = DT.IDoms[W];\n-    if (WIDom != DT.Vertex[DT.Info[W].Semi])\n-      WIDom = DT.IDoms[WIDom];\n+    const NodePtr W = DT.Vertex[i];\n+    const auto &WInfo = DT.Info[W];\n+    const unsigned SDomNum = DT.Info[DT.Vertex[WInfo.Semi]].DFSNum;\n+    NodePtr WIDomCandidate = DT.IDoms[W];\n+    while (DT.Info[WIDomCandidate].DFSNum > SDomNum)\n+      WIDomCandidate = DT.IDoms[WIDomCandidate];\n+\n+    DT.IDoms[W] = WIDomCandidate;\n   }\n \n   if (DT.Roots.empty()) return;\n", "changed_method_name": "llvm::Calculate"}
{"commit_url": "https://github.com/llvm-mirror/llvm/commit/549896a7368869a9f93b59071a5bcf11b2383a88", "commit_message": "[ADT] Add a much simpler loop to DenseMap::clear when the types are\nPOD-like and we can just splat the empty key across memory.\n\nSadly we can't optimize the normal loop well enough because we can't\nturn the conditional store into an unconditional store according to the\nmemory model.\n\nThis loop actually showed up in a profile of code that was calling clear\nas a serious source of time. =[\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@310189 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -107,17 +107,23 @@ public:\n     }\n \n     const KeyT EmptyKey = getEmptyKey(), TombstoneKey = getTombstoneKey();\n-    unsigned NumEntries = getNumEntries();\n-    for (BucketT *P = getBuckets(), *E = getBucketsEnd(); P != E; ++P) {\n-      if (!KeyInfoT::isEqual(P->getFirst(), EmptyKey)) {\n-        if (!KeyInfoT::isEqual(P->getFirst(), TombstoneKey)) {\n-          P->getSecond().~ValueT();\n-          --NumEntries;\n-        }\n+    if (isPodLike<KeyT>::value && isPodLike<ValueT>::value) {\n+      // Use a simpler loop when these are trivial types.\n+      for (BucketT *P = getBuckets(), *E = getBucketsEnd(); P != E; ++P)\n         P->getFirst() = EmptyKey;\n+    } else {\n+      unsigned NumEntries = getNumEntries();\n+      for (BucketT *P = getBuckets(), *E = getBucketsEnd(); P != E; ++P) {\n+        if (!KeyInfoT::isEqual(P->getFirst(), EmptyKey)) {\n+          if (!KeyInfoT::isEqual(P->getFirst(), TombstoneKey)) {\n+            P->getSecond().~ValueT();\n+            --NumEntries;\n+          }\n+          P->getFirst() = EmptyKey;\n+        }\n       }\n+      assert(NumEntries == 0 && \"Node count imbalance!\");\n     }\n-    assert(NumEntries == 0 && \"Node count imbalance!\");\n     setNumEntries(0);\n     setNumTombstones(0);\n   }\n", "changed_method_name": "llvm::DenseMapBase::clear"}
{"commit_url": "https://github.com/llvm-mirror/llvm/commit/b0edfb8160e3c836faccae1945e2c49db3701683", "commit_message": "AMDGPU: Don't look for DS merge candidates with one use address\n\nThe merge is only possible if the base address register is the\nsame for the two instructions. If there is only the one use,\nthere's no point in doing an expensive forward scan checking\nfor memory interference looking for a merge candidate.\n\nThis gives a signficant improvement in one extreme testcase.\nThe code to do the scan is still algorithmically terrible,\nso this is still the slowest pass in that example.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@312096 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -251,6 +251,16 @@ bool SILoadStoreOptimizer::offsetsCanBeCombined(CombineInfo &CI) {\n bool SILoadStoreOptimizer::findMatchingDSInst(CombineInfo &CI) {\n   MachineBasicBlock::iterator E = CI.I->getParent()->end();\n   MachineBasicBlock::iterator MBBI = CI.I;\n+\n+  int AddrIdx = AMDGPU::getNamedOperandIdx(CI.I->getOpcode(),\n+                                           AMDGPU::OpName::addr);\n+  const MachineOperand &AddrReg0 = CI.I->getOperand(AddrIdx);\n+\n+  // We only ever merge operations with the same base address register, so don't\n+  // bother scanning forward if there are no other uses.\n+  if (MRI->hasOneNonDBGUse(AddrReg0.getReg()))\n+    return false;\n+\n   ++MBBI;\n \n   SmallVector<const MachineOperand *, 8> DefsToMove;\n@@ -300,9 +310,6 @@ bool SILoadStoreOptimizer::findMatchingDSInst(CombineInfo &CI) {\n     if (addToListsIfDependent(*MBBI, DefsToMove, CI.InstsToMove))\n       continue;\n \n-    int AddrIdx = AMDGPU::getNamedOperandIdx(CI.I->getOpcode(),\n-                                             AMDGPU::OpName::addr);\n-    const MachineOperand &AddrReg0 = CI.I->getOperand(AddrIdx);\n     const MachineOperand &AddrReg1 = MBBI->getOperand(AddrIdx);\n \n     // Check same base pointer. Be careful of subregisters, which can occur with\n", "changed_method_name": "SILoadStoreOptimizer::findMatchingDSInst"}
{"commit_url": "https://github.com/llvm-mirror/llvm/commit/b6f73f8f0beec41e5d2a29034b028bab3f22080f", "commit_message": "[TableGen] Use SmallMapVector to simplify some code that was trying to keep a vector unique\n\nSummary:\nThis code previously had a SmallVector of std::pairs containing an unsigned and another SmallVector. The outer vector was using the unsigned effectively as a key to decide which SmallVector to add into. So each time something new needed to be added the out vector needed to be scanned. If it wasn't found a new entry needed to be added to be added. This sounds very much like a map, but the next loop iterates over the outer vector to get a deterministic order.\n\nWe can simplify this code greatly if use SmallMapVector instead. This uses more stack space since we now have a vector and a map, but the searching and creating new entries all happens behind the scenes. It should also make the search more efficient though usually there are only a few entries so that doesn't matter much.\n\nWe could probably get determinism by just using std::map which would iterate over the unsigned key, but that would generate different output from what we get with the current implementation.\n\nReviewers: RKSimon, dblaikie\n\nReviewed By: dblaikie\n\nSubscribers: llvm-commits\n\nDifferential Revision: https://reviews.llvm.org/D44711\n\ngit-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@328070 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -15,6 +15,7 @@\n #include \"CodeGenSchedule.h\"\n #include \"CodeGenInstruction.h\"\n #include \"CodeGenTarget.h\"\n+#include \"llvm/ADT/MapVector.h\"\n #include \"llvm/ADT/STLExtras.h\"\n #include \"llvm/ADT/SmallPtrSet.h\"\n #include \"llvm/ADT/SmallSet.h\"\n@@ -743,7 +744,7 @@ void CodeGenSchedModels::createInstRWClass(Record *InstRWDef) {\n   // intersects with an existing class via a previous InstRWDef. Instrs that do\n   // not intersect with an existing class refer back to their former class as\n   // determined from ItinDef or SchedRW.\n-  SmallVector<std::pair<unsigned, SmallVector<Record *, 8>>, 4> ClassInstrs;\n+  SmallMapVector<unsigned, SmallVector<Record *, 8>, 4> ClassInstrs;\n   // Sort Instrs into sets.\n   const RecVec *InstDefs = Sets.expand(InstRWDef);\n   if (InstDefs->empty())\n@@ -754,22 +755,13 @@ void CodeGenSchedModels::createInstRWClass(Record *InstRWDef) {\n     if (Pos == InstrClassMap.end())\n       PrintFatalError(InstDef->getLoc(), \"No sched class for instruction.\");\n     unsigned SCIdx = Pos->second;\n-    unsigned CIdx = 0, CEnd = ClassInstrs.size();\n-    for (; CIdx != CEnd; ++CIdx) {\n-      if (ClassInstrs[CIdx].first == SCIdx)\n-        break;\n-    }\n-    if (CIdx == CEnd) {\n-      ClassInstrs.resize(CEnd + 1);\n-      ClassInstrs[CIdx].first = SCIdx;\n-    }\n-    ClassInstrs[CIdx].second.push_back(InstDef);\n+    ClassInstrs[SCIdx].push_back(InstDef);\n   }\n   // For each set of Instrs, create a new class if necessary, and map or remap\n   // the Instrs to it.\n-  for (unsigned CIdx = 0, CEnd = ClassInstrs.size(); CIdx != CEnd; ++CIdx) {\n-    unsigned OldSCIdx = ClassInstrs[CIdx].first;\n-    ArrayRef<Record*> InstDefs = ClassInstrs[CIdx].second;\n+  for (auto &Entry : ClassInstrs) {\n+    unsigned OldSCIdx = Entry.first;\n+    ArrayRef<Record*> InstDefs = Entry.second;\n     // If the all instrs in the current class are accounted for, then leave\n     // them mapped to their old class.\n     if (OldSCIdx) {\n", "changed_method_name": "CodeGenSchedModels::createInstRWClass"}
{"commit_url": "https://github.com/git/git/commit/a6eec1263883ce9787a354e1635b7b732e72c3c9", "commit_message": "upload-pack: drop lookup-before-parse optimization\n\nWhen we receive a \"have\" line from the client, we want to\nload the object pointed to by the sha1. However, we are\ncareful to do:\n\n  o = lookup_object(sha1);\n  if (!o || !o->parsed)\n\t  o = parse_object(sha1);\n\nto avoid loading the object from disk if we have already\nseen it.  However, since ccdc603 (parse_object: try internal\ncache before reading object db), parse_object already does\nthis optimization internally. We can just call parse_object\ndirectly.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -327,9 +327,7 @@ static int got_sha1(char *hex, unsigned char *sha1)\n \tif (!has_sha1_file(sha1))\n \t\treturn -1;\n \n-\to = lookup_object(sha1);\n-\tif (!(o && o->parsed))\n-\t\to = parse_object(sha1);\n+\to = parse_object(sha1);\n \tif (!o)\n \t\tdie(\"oops (%s)\", sha1_to_hex(sha1));\n \tif (o->type == OBJ_COMMIT) {\n", "changed_method_name": "got_sha1"}
{"commit_url": "https://github.com/git/git/commit/9a414486d9f0325c3663210471e4673ed0cd862c", "commit_message": "lookup_object: prioritize recently found objects\n\nThe lookup_object function is backed by a hash table of all\nobjects we have seen in the program. We manage collisions\nwith a linear walk over the colliding entries, checking each\nwith hashcmp(). The main cost of lookup is in these\nhashcmp() calls; finding our item in the first slot is\ncheaper than finding it in the second slot, which is cheaper\nthan the third, and so on.\n\nIf we assume that there is some locality to the object\nlookups (e.g., if X and Y collide, and we have just looked\nup X, the next lookup is more likely to be for X than for\nY), then we can improve our average lookup speed by checking\nX before Y.\n\nThis patch does so by swapping a found item to the front of\nthe collision chain. The p0001 perf test reveals that this\ndoes indeed exploit locality in the case of \"rev-list --all\n--objects\":\n\nTest                               origin          this tree\n-------------------------------------------------------------------------\n0001.1: rev-list --all             0.40(0.38+0.02) 0.40(0.36+0.03) +0.0%\n0001.2: rev-list --all --objects   2.24(2.17+0.05) 1.86(1.79+0.05) -17.0%\n\nThis is not surprising, as the full object traversal will\nhit the same tree entries over and over (e.g., for every\ncommit that doesn't change \"Documentation/\", we will have to\nlook up the same sha1 just to find out that we already\nprocessed it).\n\nThe reason why this technique works (and does not violate\nany properties of the hash table) is subtle and bears some\nexplanation. Let's imagine we get a lookup for sha1 `X`, and\nit hashes to bucket `i` in our table. That stretch of the\ntable may look like:\n\nindex       | i-1 |  i  | i+1 | i+2 |\n       -----------------------------------\nentry   ... |  A  |  B  |  C  |  X  | ...\n       -----------------------------------\n\nWe start our probe at i, see that B does not match, nor does\nC, and finally find X. There may be multiple C's in the\nmiddle, but we know that there are no empty slots (or else\nwe would not find X at all).\n\nWe do not know the original index of B; it may be `i`, or it\nmay be less than i (e.g., if it were `i-1`, it would collide\nwith A and spill over into the `i` bucket). So it is\nacceptable for us to move it to the right of a contiguous\nstretch of entries (because we will find it from a linear\nwalk starting anywhere at `i` or before), but never to the\nleft (if we moved it to `i-1`, we would miss it when\nstarting our walk at `i`).\n\nWe do know the original index of X; it is `i`, so it is safe\nto place it anywhere in the contiguous stretch between `i`\nand where we found it (`i+2` in the this case).\n\nThis patch does a pure swap; after finding X in the\nsituation above, we would end with:\n\nindex       | i-1 |  i  | i+1 | i+2 |\n       -----------------------------------\nentry   ... |  A  |  X  |  C  |  B  | ...\n       -----------------------------------\n\nWe could instead bump X into the `i` slot, and then shift\nthe whole contiguous chain down by one, resulting in:\n\nindex       | i-1 |  i  | i+1 | i+2 |\n       -----------------------------------\nentry   ... |  A  |  X  |  B  |  C  | ...\n       -----------------------------------\n\nThat puts our chain in true most-recently-used order.\nHowever, experiments show that it is not any faster (and in\nfact, is slightly slower due to the extra manipulation).\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -71,13 +71,13 @@ static unsigned int hashtable_index(const unsigned char *sha1)\n \n struct object *lookup_object(const unsigned char *sha1)\n {\n-\tunsigned int i;\n+\tunsigned int i, first;\n \tstruct object *obj;\n \n \tif (!obj_hash)\n \t\treturn NULL;\n \n-\ti = hashtable_index(sha1);\n+\tfirst = i = hashtable_index(sha1);\n \twhile ((obj = obj_hash[i]) != NULL) {\n \t\tif (!hashcmp(sha1, obj->sha1))\n \t\t\tbreak;\n@@ -85,6 +85,16 @@ struct object *lookup_object(const unsigned char *sha1)\n \t\tif (i == obj_hash_size)\n \t\t\ti = 0;\n \t}\n+\tif (obj && i != first) {\n+\t\t/*\n+\t\t * Move object to where we started to look for it so\n+\t\t * that we do not need to walk the hash table the next\n+\t\t * time we look for it.\n+\t\t */\n+\t\tstruct object *tmp = obj_hash[i];\n+\t\tobj_hash[i] = obj_hash[first];\n+\t\tobj_hash[first] = tmp;\n+\t}\n \treturn obj;\n }\n \n", "changed_method_name": "lookup_object"}
{"commit_url": "https://github.com/git/git/commit/4c30d50402c17d2569151820b92cea110ad1d240", "commit_message": "rev-list: disable object/refname ambiguity check with --stdin\n\nThis is the \"rev-list\" analogue to 25fba78 (cat-file:\ndisable object/refname ambiguity check for batch mode,\n2013-07-12).  Like cat-file, \"rev-list --stdin\" may read a\nlarge number of sha1 object names, and the warning check\nintroduces a significant slow-down.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -1541,6 +1541,10 @@ static void read_revisions_from_stdin(struct rev_info *revs,\n {\n \tstruct strbuf sb;\n \tint seen_dashdash = 0;\n+\tint save_warning;\n+\n+\tsave_warning = warn_on_object_refname_ambiguity;\n+\twarn_on_object_refname_ambiguity = 0;\n \n \tstrbuf_init(&sb, 1000);\n \twhile (strbuf_getwholeline(&sb, stdin, '\\n') != EOF) {\n@@ -1562,7 +1566,9 @@ static void read_revisions_from_stdin(struct rev_info *revs,\n \t}\n \tif (seen_dashdash)\n \t\tread_pathspec_from_stdin(revs, &sb, prune);\n+\n \tstrbuf_release(&sb);\n+\twarn_on_object_refname_ambiguity = save_warning;\n }\n \n static void add_grep(struct rev_info *revs, const char *ptn, enum grep_pat_token what)\n", "changed_method_name": "read_revisions_from_stdin"}
{"commit_url": "https://github.com/git/git/commit/3446a59b3950d57960e27f8a2c7e41462bd2bcf4", "commit_message": "strbuf_getwholeline: use getc macro\n\nstrbuf_getwholeline calls fgetc in a tight loop. Using the\ngetc form, which can be implemented as a macro, should be\nfaster (and we do not care about it evaluating our argument\ntwice, as we just have a plain variable).\n\nOn my glibc system, running \"git rev-parse\nrefs/heads/does-not-exist\" on a file with an extremely large\n(1.6GB) packed-refs file went from (best of 3 runs):\n\n  real    0m19.383s\n  user    0m18.876s\n  sys     0m0.528s\n\nto:\n\n  real    0m18.900s\n  user    0m18.472s\n  sys     0m0.448s\n\nfor a wall-clock speedup of 2.5%.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -443,7 +443,7 @@ int strbuf_getwholeline(struct strbuf *sb, FILE *fp, int term)\n \t\treturn EOF;\n \n \tstrbuf_reset(sb);\n-\twhile ((ch = fgetc(fp)) != EOF) {\n+\twhile ((ch = getc(fp)) != EOF) {\n \t\tstrbuf_grow(sb, 1);\n \t\tsb->buf[sb->len++] = ch;\n \t\tif (ch == term)\n", "changed_method_name": "strbuf_getwholeline"}
{"commit_url": "https://github.com/git/git/commit/f5b2dec1657e09a22f8b2aefa25d022988e3e467", "commit_message": "refs.c: remove extra git_path calls from read_loose_refs\n\nIn iterating over the loose refs in \"refs/foo/\", we keep a\nrunning strbuf with \"refs/foo/one\", \"refs/foo/two\", etc. But\nwe also need to access these files in the filesystem, as\n\".git/refs/foo/one\", etc. For this latter purpose, we make a\nseries of independent calls to git_path(). These are safe\n(we only use the result to call stat()), but assigning the\nresult of git_path is a suspicious pattern that we'd rather\navoid.\n\nThis patch keeps a running buffer with \".git/refs/foo/\", and\nwe can just append/reset each directory element as we loop.\nThis matches how we handle the refnames. It should also be\nmore efficient, as we do not keep formatting the same\n\".git/refs/foo\" prefix (which can be arbitrarily deep).\n\nTechnically we are dropping a call to strbuf_cleanup() on\neach generated filename, but that's OK; it wasn't doing\nanything, as we are putting in single-level names we read\nfrom the filesystem (so it could not possibly be cleaning up\ncruft like \"./\" in this instance).\n\nA clever reader may also note that the running refname\nbuffer (\"refs/foo/\") is actually a subset of the filesystem\npath buffer (\".git/refs/foo/\"). We could get by with one\nbuffer, indexing the length of $GIT_DIR when we want the\nrefname. However, having tried this, the resulting code\nactually ends up a little more confusing, and the efficiency\nimprovement is tiny (and almost certainly dwarfed by the\nsystem calls we are making).\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -1352,19 +1352,23 @@ static void read_loose_refs(const char *dirname, struct ref_dir *dir)\n {\n \tstruct ref_cache *refs = dir->ref_cache;\n \tDIR *d;\n-\tconst char *path;\n \tstruct dirent *de;\n \tint dirnamelen = strlen(dirname);\n \tstruct strbuf refname;\n+\tstruct strbuf path = STRBUF_INIT;\n+\tsize_t path_baselen;\n \n \tif (*refs->name)\n-\t\tpath = git_path_submodule(refs->name, \"%s\", dirname);\n+\t\tstrbuf_git_path_submodule(&path, refs->name, \"%s\", dirname);\n \telse\n-\t\tpath = git_path(\"%s\", dirname);\n+\t\tstrbuf_git_path(&path, \"%s\", dirname);\n+\tpath_baselen = path.len;\n \n-\td = opendir(path);\n-\tif (!d)\n+\td = opendir(path.buf);\n+\tif (!d) {\n+\t\tstrbuf_release(&path);\n \t\treturn;\n+\t}\n \n \tstrbuf_init(&refname, dirnamelen + 257);\n \tstrbuf_add(&refname, dirname, dirnamelen);\n@@ -1373,17 +1377,14 @@ static void read_loose_refs(const char *dirname, struct ref_dir *dir)\n \t\tunsigned char sha1[20];\n \t\tstruct stat st;\n \t\tint flag;\n-\t\tconst char *refdir;\n \n \t\tif (de->d_name[0] == '.')\n \t\t\tcontinue;\n \t\tif (ends_with(de->d_name, \".lock\"))\n \t\t\tcontinue;\n \t\tstrbuf_addstr(&refname, de->d_name);\n-\t\trefdir = *refs->name\n-\t\t\t? git_path_submodule(refs->name, \"%s\", refname.buf)\n-\t\t\t: git_path(\"%s\", refname.buf);\n-\t\tif (stat(refdir, &st) < 0) {\n+\t\tstrbuf_addstr(&path, de->d_name);\n+\t\tif (stat(path.buf, &st) < 0) {\n \t\t\t; /* silently ignore */\n \t\t} else if (S_ISDIR(st.st_mode)) {\n \t\t\tstrbuf_addch(&refname, '/');\n@@ -1430,8 +1431,10 @@ static void read_loose_refs(const char *dirname, struct ref_dir *dir)\n \t\t\t\t\t create_ref_entry(refname.buf, sha1, flag, 0));\n \t\t}\n \t\tstrbuf_setlen(&refname, dirnamelen);\n+\t\tstrbuf_setlen(&path, path_baselen);\n \t}\n \tstrbuf_release(&refname);\n+\tstrbuf_release(&path);\n \tclosedir(d);\n }\n \n", "changed_method_name": "read_loose_refs"}
{"commit_url": "https://github.com/git/git/commit/4e1d1a2eea25878a2128e376bff8b4a1b2216b15", "commit_message": "shortlog: optimize \"--summary\" mode\n\nIf the user asked us only to show counts for each author,\nrather than the individual summary lines, then there is no\npoint in us generating the summaries only to throw them\naway. With this patch, I measured the following speedup for\n\"git shortlog -ns HEAD\" on linux.git (best-of-five):\n\n  [before]\n  real    0m5.644s\n  user    0m5.472s\n  sys     0m0.176s\n\n  [after]\n  real    0m5.257s\n  user    0m5.104s\n  sys     0m0.156s\n\nThat's only ~7%, but it's so easy to do, there's no good\nreason not to. We don't have to touch any downstream code,\nsince we already fill in the magic string \"<none>\" to handle\ncommits without a message.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -132,10 +132,12 @@ void shortlog_add_commit(struct shortlog *log, struct commit *commit)\n \t\tgoto out;\n \t}\n \n-\tif (log->user_format)\n-\t\tpretty_print_commit(&ctx, commit, &oneline);\n-\telse\n-\t\tformat_commit_message(commit, \"%s\", &oneline, &ctx);\n+\tif (!log->summary) {\n+\t\tif (log->user_format)\n+\t\t\tpretty_print_commit(&ctx, commit, &oneline);\n+\t\telse\n+\t\t\tformat_commit_message(commit, \"%s\", &oneline, &ctx);\n+\t}\n \n \tinsert_one_record(log, author.buf, oneline.len ? oneline.buf : \"<none>\");\n \n", "changed_method_name": "shortlog_add_commit"}
{"commit_url": "https://github.com/git/git/commit/6a36e1e7bb64726cc712259aff57179d81361b5d", "commit_message": "cat-file: default to --buffer when --batch-all-objects is used\n\nTraditionally cat-file's batch-mode does not do any output\nbuffering. The reason is that a caller may have pipes\nconnected to its input and output, and would want to use\ncat-file interactively, getting output immediately for each\ninput it sends.\n\nThis may involve a lot of small write() calls, which can be\nslow. So we introduced --buffer to improve this, but we\ncan't turn it on by default, as it would break the\ninteractive case above.\n\nHowever, when --batch-all-objects is used, we do not read\nstdin at all. We generate the output ourselves as quickly as\npossible, and then exit. In this case buffering is a strict\nwin, and it is simply a hassle for the user to have to\nremember to specify --buffer.\n\nThis patch makes --buffer the default when --batch-all-objects\nis used. Specifying \"--buffer\" manually is still OK, and you\ncan even override it with \"--no-buffer\" if you're a\nmasochist (or debugging).\n\nFor some real numbers, running:\n\n  git cat-file --batch-all-objects --batch-check='%(objectname)'\n\non torvalds/linux goes from:\n\n  real    0m1.464s\n  user    0m1.208s\n  sys     0m0.252s\n\nto:\n\n  real    0m1.230s\n  user    0m1.172s\n  sys     0m0.056s\n\nfor a 16% speedup.\n\nSuggested-by: Charles Bailey <charles@hashpling.org>\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -504,6 +504,7 @@ int cmd_cat_file(int argc, const char **argv, const char *prefix)\n \n \tgit_config(git_cat_file_config, NULL);\n \n+\tbatch.buffer_output = -1;\n \targc = parse_options(argc, argv, prefix, options, cat_file_usage, 0);\n \n \tif (opt) {\n@@ -527,6 +528,9 @@ int cmd_cat_file(int argc, const char **argv, const char *prefix)\n \t\tusage_with_options(cat_file_usage, options);\n \t}\n \n+\tif (batch.buffer_output < 0)\n+\t\tbatch.buffer_output = batch.all_objects;\n+\n \tif (batch.enabled)\n \t\treturn batch_objects(&batch);\n \n", "changed_method_name": "cmd_cat_file"}
{"commit_url": "https://github.com/git/git/commit/7eb6e10c9d7f43913615667740d1b22055cfba1f", "commit_message": "branch: use write_file_buf instead of write_file\n\nIf we already have a strbuf, then using write_file_buf is a\nlittle nicer to read (no wondering whether \"%s\" will eat\nyour NULs), and it's more efficient (no extra formatting\nstep).\n\nWe don't care about the newline magic of write_file(), as we\nhave our own multi-line content.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -618,7 +618,7 @@ static int edit_branch_description(const char *branch_name)\n \t\t    \"  %s\\n\"\n \t\t    \"Lines starting with '%c' will be stripped.\\n\",\n \t\t    branch_name, comment_line_char);\n-\twrite_file(git_path(edit_description), \"%s\", buf.buf);\n+\twrite_file_buf(git_path(edit_description), buf.buf, buf.len);\n \tstrbuf_reset(&buf);\n \tif (launch_editor(git_path(edit_description), &buf, NULL)) {\n \t\tstrbuf_release(&buf);\n", "changed_method_name": "edit_branch_description"}
{"commit_url": "https://github.com/git/git/commit/da470981defcace6e909b74ebc4ab5a40a702728", "commit_message": "fetch-pack: grow stateless RPC windows exponentially\n\nWhen updating large repositories, the LARGE_FLUSH limit (that is, the\nlimit at which the window growth strategy switches from exponential to\nlinear) is reached quite quickly. Use a conservative exponential growth\nstrategy when that limit is reached instead (and increase LARGE_FLUSH so\nthat there is no regression in window size).\n\nThis optimization is only applied during stateless RPCs to avoid the\nissue raised and fixed in commit 44d8dc54 (Fix potential local\ndeadlock during fetch-pack, 2011-03-29).\n\nSigned-off-by: Jonathan Tan <jonathantanmy@google.com>\nReviewed-by: Jonathan Nieder <jrnieder@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -243,16 +243,21 @@ static void insert_one_alternate_ref(const struct ref *ref, void *unused)\n \n #define INITIAL_FLUSH 16\n #define PIPESAFE_FLUSH 32\n-#define LARGE_FLUSH 1024\n+#define LARGE_FLUSH 16384\n \n static int next_flush(struct fetch_pack_args *args, int count)\n {\n-\tint flush_limit = args->stateless_rpc ? LARGE_FLUSH : PIPESAFE_FLUSH;\n-\n-\tif (count < flush_limit)\n-\t\tcount <<= 1;\n-\telse\n-\t\tcount += flush_limit;\n+\tif (args->stateless_rpc) {\n+\t\tif (count < LARGE_FLUSH)\n+\t\t\tcount <<= 1;\n+\t\telse\n+\t\t\tcount = count * 11 / 10;\n+\t} else {\n+\t\tif (count < PIPESAFE_FLUSH)\n+\t\t\tcount <<= 1;\n+\t\telse\n+\t\t\tcount += PIPESAFE_FLUSH;\n+\t}\n \treturn count;\n }\n \n", "changed_method_name": "next_flush"}
{"commit_url": "https://github.com/git/git/commit/e5494631ed94017da862d55eb6393a0d01d8b91d", "commit_message": "read-cache: speed up add_index_entry during checkout\n\nTeach add_index_entry_with_check() to see if the path\nof the new item is greater than the last path in the\nindex array before attempting to search for it.\n\nDuring checkout, merge_working_tree() populates the new\nindex in sorted order, so this change will save a binary\nlookups per file.  This preserves the original behavior\nbut simply checks the last element before starting the\nsearch.\n\nThis helps performance on very large repositories.\n\nSigned-off-by: Jeff Hostetler <jeffhost@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -1021,7 +1021,16 @@ static int add_index_entry_with_check(struct index_state *istate, struct cache_e\n \n \tif (!(option & ADD_CACHE_KEEP_CACHE_TREE))\n \t\tcache_tree_invalidate_path(istate, ce->name);\n-\tpos = index_name_stage_pos(istate, ce->name, ce_namelen(ce), ce_stage(ce));\n+\n+\t/*\n+\t * If this entry's path sorts after the last entry in the index,\n+\t * we can avoid searching for it.\n+\t */\n+\tif (istate->cache_nr > 0 &&\n+\t\tstrcmp(ce->name, istate->cache[istate->cache_nr - 1]->name) > 0)\n+\t\tpos = -istate->cache_nr - 1;\n+\telse\n+\t\tpos = index_name_stage_pos(istate, ce->name, ce_namelen(ce), ce_stage(ce));\n \n \t/* existing match? Just replace it. */\n \tif (pos >= 0) {\n", "changed_method_name": "add_index_entry_with_check"}
{"commit_url": "https://github.com/git/git/commit/9ec726a4120bb219530faf988198a704ec7dd1f1", "commit_message": "grep: skip pthreads overhead when using one thread\n\nSkip the administrative overhead of using pthreads when only using one\nthread. Instead take the non-threaded path which would be taken under\nNO_PTHREADS.\n\nThe threading support was initially added in commit\n5b594f457a (\"Threaded grep\", 2010-01-25) with a hardcoded compile-time\nnumber of 8 threads. Later the number of threads was made configurable\nin commit 89f09dd34e (\"grep: add --threads=<num> option and\ngrep.threads configuration\", 2015-12-15).\n\nThat change did not add any special handling for --threads=1. Now we\ntake a slightly faster path by skipping thread handling entirely when\n1 thread is requested.\n\nSigned-off-by: \u00c6var Arnfj\u00f6r\u00f0 Bjarmason <avarab@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -1238,6 +1238,8 @@ int cmd_grep(int argc, const char **argv, const char *prefix)\n \t\tnum_threads = GREP_NUM_THREADS_DEFAULT;\n \telse if (num_threads < 0)\n \t\tdie(_(\"invalid number of threads specified (%d)\"), num_threads);\n+\tif (num_threads == 1)\n+\t\tnum_threads = 0;\n #else\n \tif (num_threads)\n \t\twarning(_(\"no threads support, ignoring --threads\"));\n", "changed_method_name": "cmd_grep"}
{"commit_url": "https://github.com/git/git/commit/f35650dff6a4500e317803165b13cc087f48ee85", "commit_message": "log: do not free parents when walking reflog\n\nWhen we're doing a reflog walk (instead of walking the\nactual parent pointers), we may see commits multiple times.\nFor this reason, we hold on to the commit buffer for each\ncommit rather than freeing it after we've showed the commit.\n\nWe should do the same for the parent list. Right now this is\njust a minor optimization. But once we refactor how reflog\nwalks are performed, keeping the parents will avoid\nconfusing us the second time we see the commit.\n\nSigned-off-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -377,9 +377,9 @@ static int cmd_log_walk(struct rev_info *rev)\n \t\t\t * walking the reflogs.\n \t\t\t */\n \t\t\tfree_commit_buffer(commit);\n+\t\t\tfree_commit_list(commit->parents);\n+\t\t\tcommit->parents = NULL;\n \t\t}\n-\t\tfree_commit_list(commit->parents);\n-\t\tcommit->parents = NULL;\n \t\tif (saved_nrl < rev->diffopt.needed_rename_limit)\n \t\t\tsaved_nrl = rev->diffopt.needed_rename_limit;\n \t\tif (rev->diffopt.degraded_cc_to_c)\n", "changed_method_name": "cmd_log_walk"}
{"commit_url": "https://github.com/git/git/commit/7a40a95eb4f79517750eb2bcd81342c25c6db406", "commit_message": "refs: use skip_prefix() in ref_is_hidden()\n\nThis is shorter, makes the logic a bit easier to follow, and is\nperhaps a bit faster too.\n\nThe logic is to make the final decision only when \"subject\" is there,\nits early part matches \"match\", and the match is at the slash\nboundary (or the whole thing).\n\nSigned-off-by: Christian Couder <chriscool@tuxfamily.org>\nReviewed-by: Jeff King <peff@peff.net>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -1066,7 +1066,7 @@ int ref_is_hidden(const char *refname, const char *refname_full)\n \t\tconst char *match = hide_refs->items[i].string;\n \t\tconst char *subject;\n \t\tint neg = 0;\n-\t\tint len;\n+\t\tconst char *p;\n \n \t\tif (*match == '!') {\n \t\t\tneg = 1;\n@@ -1081,10 +1081,9 @@ int ref_is_hidden(const char *refname, const char *refname_full)\n \t\t}\n \n \t\t/* refname can be NULL when namespaces are used. */\n-\t\tif (!subject || !starts_with(subject, match))\n-\t\t\tcontinue;\n-\t\tlen = strlen(match);\n-\t\tif (!subject[len] || subject[len] == '/')\n+\t\tif (subject &&\n+\t\t    skip_prefix(subject, match, &p) &&\n+\t\t    (!*p || *p == '/'))\n \t\t\treturn !neg;\n \t}\n \treturn 0;\n", "changed_method_name": "ref_is_hidden"}
{"commit_url": "https://github.com/git/git/commit/2523c4be855af84460e70ab5c8375534f8cefed5", "commit_message": "dir.c: avoid stat() in valid_cached_dir()\n\nstat() may follow a symlink and return stat data of the link's target\ninstead of the link itself. We are concerned about the link itself.\n\nIt's kind of hard to demonstrate the bug. I think when path->buf is a\nsymlink, we most likely find that its target's stat data does not\nmatch our cached one, which means we ignore the cache and fall back to\nslow path.\n\nThis is performance issue, not correctness (though we could still\ncatch it by verifying test-dump-untracked-cache. The less unlikely\ncase is, link target stat data matches the cached version and we\nincorrectly go fast path, ignoring real data on disk. A test for this\nmay involve manipulating stat data, which may be not portable.\n\nSigned-off-by: Nguy\u1ec5n Th\u00e1i Ng\u1ecdc Duy <pclouds@gmail.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -1739,7 +1739,7 @@ static int valid_cached_dir(struct dir_struct *dir,\n \t */\n \trefresh_fsmonitor(istate);\n \tif (!(dir->untracked->use_fsmonitor && untracked->valid)) {\n-\t\tif (stat(path->len ? path->buf : \".\", &st)) {\n+\t\tif (lstat(path->len ? path->buf : \".\", &st)) {\n \t\t\tinvalidate_directory(dir->untracked, untracked);\n \t\t\tmemset(&untracked->stat_data, 0, sizeof(untracked->stat_data));\n \t\t\treturn 0;\n", "changed_method_name": "valid_cached_dir"}
{"commit_url": "https://github.com/git/git/commit/ca598d5f2ab988935a5b882b44122cbfa5fd99f5", "commit_message": "fsmonitor: force index write after full scan\n\nfsmonitor currently only flags the index as dirty if the extension is being\nadded or removed. This is a performance optimization that recognizes you can\nstat() a lot of files in less time than it takes to write out an updated index.\n\nThis patch makes a small enhancement and flags the index dirty if we end up\nhaving to stat() all files and scan the entire working directory.  The assumption\nbeing that must be expensive or you would not have turned on the feature.\n\nSigned-off-by: Ben Peart <benpeart@microsoft.com>\nSigned-off-by: Junio C Hamano <gitster@pobox.com>", "code_diff": "@@ -185,6 +185,9 @@ void refresh_fsmonitor(struct index_state *istate)\n \t\tfor (i = 0; i < istate->cache_nr; i++)\n \t\t\tistate->cache[i]->ce_flags &= ~CE_FSMONITOR_VALID;\n \n+\t\t/* If we're going to check every file, ensure we save the results */\n+\t\tistate->cache_changed |= FSMONITOR_CHANGED;\n+\n \t\tif (istate->untracked)\n \t\t\tistate->untracked->use_fsmonitor = 0;\n \t}\n", "changed_method_name": "refresh_fsmonitor"}
{"commit_url": "https://github.com/llvm-mirror/clang/commit/41748f7d3ae36db1b1c52eaaf76631ed60c79c53", "commit_message": "[analyzer] Bump down the max size of functions being analyzed.\n\nWith the new setting, we are not going to inline any functions that are\nmore than 50 basic blocks. (The analyzer is 20% faster on several\nespecially bad benchmarks with the new default.)\n\ngit-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@171891 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -304,7 +304,7 @@ public:\n     NoRetryExhausted = 0;\n     // Cap the stack depth at 4 calls (5 stack frames, base + 4 calls).\n     InlineMaxStackDepth = 5;\n-    InlineMaxFunctionSize = 200;\n+    InlineMaxFunctionSize = 50;\n     InliningMode = NoRedundancy;\n   }\n };\n", "changed_method_name": "clang::AnalyzerOptions::AnalyzerOptions"}
{"commit_url": "https://github.com/llvm-mirror/clang/commit/7cea1487602536e91a2c36511f5ad56ff1b2dc68", "commit_message": "Test for virtual instead of pure here. It has the exact same effect, and John\nclaims it will improve performance.\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@174341 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -11192,7 +11192,7 @@ void Sema::MarkDeclRefReferenced(DeclRefExpr *E) {\n   // if it's a qualified reference.\n   bool OdrUse = true;\n   if (CXXMethodDecl *Method = dyn_cast<CXXMethodDecl>(E->getDecl()))\n-    if (Method->isPure())\n+    if (Method->isVirtual())\n       OdrUse = false;\n   MarkExprReferenced(*this, E->getLocation(), E->getDecl(), E, OdrUse);\n }\n", "changed_method_name": "Sema::MarkDeclRefReferenced"}
{"commit_url": "https://github.com/llvm-mirror/clang/commit/2f13eb116e62161c5e4d198f7831f226e5cea9da", "commit_message": "[analyzer] Make GRBugReporter::generatePathDiagnostic iterative, not recursive.\n\nThe previous generatePathDiagnostic() was intended to be tail-recursive,\nrestarting and trying again if a report was marked invalid. However:\n (1) this leaked all the cloned visitors, which weren't being deleted, and\n (2) this wasn't actually tail-recursive because some local variables had\n     non-trivial destructors.\n\nThis was causing us to overflow the stack on inputs with large numbers of\nreports in the same equivalence class, such as sqlite3.c. Being iterative\nat least prevents us from blowing out the stack, but doesn't solve the\nperformance issue: suppressing thousands (yes, thousands) of paths in the\nsame equivalence class is expensive. I'm looking into that now.\n\n<rdar://problem/13423498>\n\ngit-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@177189 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -2114,134 +2114,125 @@ bool GRBugReporter::generatePathDiagnostic(PathDiagnostic& PD,\n                                            ArrayRef<BugReport *> &bugReports) {\n   assert(!bugReports.empty());\n \n-  bool HasValid = false;\n-  SmallVector<const ExplodedNode *, 10> errorNodes;\n+  SmallVector<const ExplodedNode *, 32> errorNodes;\n   for (ArrayRef<BugReport*>::iterator I = bugReports.begin(),\n-                                      E = bugReports.end(); I != E; ++I) {\n-    if ((*I)->isValid()) {\n-      HasValid = true;\n-      errorNodes.push_back((*I)->getErrorNode());\n-    } else {\n-      errorNodes.push_back(0);\n-    }\n+                                      E = bugReports.end();\n+       I != E; ++I) {\n+    errorNodes.push_back((*I)->getErrorNode());\n   }\n \n-  // If all the reports have been marked invalid, we're done.\n-  if (!HasValid)\n-    return false;\n-\n-  // Construct a new graph that contains only a single path from the error\n-  // node to a root.\n-  const std::pair<std::pair<ExplodedGraph*, NodeBackMap*>,\n-  std::pair<ExplodedNode*, unsigned> >&\n-    GPair = MakeReportGraph(&getGraph(), errorNodes);\n-\n-  // Find the BugReport with the original location.\n-  assert(GPair.second.second < bugReports.size());\n-  BugReport *R = bugReports[GPair.second.second];\n-  assert(R && \"No original report found for sliced graph.\");\n-  assert(R->isValid() && \"Report selected from trimmed graph marked invalid.\");\n-\n-  OwningPtr<ExplodedGraph> ReportGraph(GPair.first.first);\n-  OwningPtr<NodeBackMap> BackMap(GPair.first.second);\n-  const ExplodedNode *N = GPair.second.first;\n-\n-  // Start building the path diagnostic...\n-  PathDiagnosticBuilder PDB(*this, R, BackMap.get(), &PC);\n-\n-  // Register additional node visitors.\n-  R->addVisitor(new NilReceiverBRVisitor());\n-  R->addVisitor(new ConditionBRVisitor());\n-  R->addVisitor(new LikelyFalsePositiveSuppressionBRVisitor());\n-\n-  BugReport::VisitorList visitors;\n-  unsigned originalReportConfigToken, finalReportConfigToken;\n-\n-  // While generating diagnostics, it's possible the visitors will decide\n-  // new symbols and regions are interesting, or add other visitors based on\n-  // the information they find. If they do, we need to regenerate the path\n-  // based on our new report configuration.\n-  do {\n-    // Get a clean copy of all the visitors.\n-    for (BugReport::visitor_iterator I = R->visitor_begin(),\n-                                     E = R->visitor_end(); I != E; ++I)\n-       visitors.push_back((*I)->clone());\n-\n-    // Clear out the active path from any previous work.\n-    PD.resetPath();\n-    originalReportConfigToken = R->getConfigurationChangeToken();\n-\n-    // Generate the very last diagnostic piece - the piece is visible before \n-    // the trace is expanded.\n-    PathDiagnosticPiece *LastPiece = 0;\n-    for (BugReport::visitor_iterator I = visitors.begin(), E = visitors.end();\n-        I != E; ++I) {\n-      if (PathDiagnosticPiece *Piece = (*I)->getEndPath(PDB, N, *R)) {\n-        assert (!LastPiece &&\n-            \"There can only be one final piece in a diagnostic.\");\n-        LastPiece = Piece;\n+  typedef PathDiagnosticConsumer::PathGenerationScheme PathGenerationScheme;\n+  PathGenerationScheme ActiveScheme = PC.getGenerationScheme();\n+\n+  for (size_t Remaining = bugReports.size(); Remaining > 0; --Remaining) {\n+    // Construct a new graph that contains only a single path from the error\n+    // node to a root.\n+    // FIXME: It might be possible to reuse some of this work instead of\n+    // redoing it every time we mark a report invalid.\n+    const std::pair<std::pair<ExplodedGraph*, NodeBackMap*>,\n+                    std::pair<ExplodedNode*, unsigned> >&\n+      GPair = MakeReportGraph(&getGraph(), errorNodes);\n+\n+    // Find the BugReport with the original location.\n+    assert(GPair.second.second < bugReports.size());\n+    BugReport *R = bugReports[GPair.second.second];\n+    assert(R && \"No original report found for sliced graph.\");\n+    assert(R->isValid() && \"Report selected by trimmed graph marked invalid.\");\n+\n+    // Don't try to reuse this report if it ends up being suppressed.\n+    errorNodes[GPair.second.second] = 0;\n+\n+    OwningPtr<ExplodedGraph> ReportGraph(GPair.first.first);\n+    OwningPtr<NodeBackMap> BackMap(GPair.first.second);\n+    const ExplodedNode *N = GPair.second.first;\n+\n+    // Start building the path diagnostic...\n+    PathDiagnosticBuilder PDB(*this, R, BackMap.get(), &PC);\n+\n+    // Register additional node visitors.\n+    R->addVisitor(new NilReceiverBRVisitor());\n+    R->addVisitor(new ConditionBRVisitor());\n+    R->addVisitor(new LikelyFalsePositiveSuppressionBRVisitor());\n+\n+    BugReport::VisitorList visitors;\n+    unsigned origReportConfigToken, finalReportConfigToken;\n+\n+    // While generating diagnostics, it's possible the visitors will decide\n+    // new symbols and regions are interesting, or add other visitors based on\n+    // the information they find. If they do, we need to regenerate the path\n+    // based on our new report configuration.\n+    do {\n+      // Get a clean copy of all the visitors.\n+      for (BugReport::visitor_iterator I = R->visitor_begin(),\n+                                       E = R->visitor_end(); I != E; ++I)\n+        visitors.push_back((*I)->clone());\n+\n+      // Clear out the active path from any previous work.\n+      PD.resetPath();\n+      origReportConfigToken = R->getConfigurationChangeToken();\n+\n+      // Generate the very last diagnostic piece - the piece is visible before \n+      // the trace is expanded.\n+      PathDiagnosticPiece *LastPiece = 0;\n+      for (BugReport::visitor_iterator I = visitors.begin(), E = visitors.end();\n+          I != E; ++I) {\n+        if (PathDiagnosticPiece *Piece = (*I)->getEndPath(PDB, N, *R)) {\n+          assert (!LastPiece &&\n+              \"There can only be one final piece in a diagnostic.\");\n+          LastPiece = Piece;\n+        }\n       }\n-    }\n \n-    if (PDB.getGenerationScheme() != PathDiagnosticConsumer::None) {\n-      if (!LastPiece)\n-        LastPiece = BugReporterVisitor::getDefaultEndPath(PDB, N, *R);\n-      if (LastPiece)\n+      if (ActiveScheme != PathDiagnosticConsumer::None) {\n+        if (!LastPiece)\n+          LastPiece = BugReporterVisitor::getDefaultEndPath(PDB, N, *R);\n+        assert(LastPiece);\n         PD.setEndOfPath(LastPiece);\n-      else\n-        return false;\n-    }\n-\n-    switch (PDB.getGenerationScheme()) {\n-    case PathDiagnosticConsumer::Extensive:\n-      if (!GenerateExtensivePathDiagnostic(PD, PDB, N, visitors)) {\n-        assert(!R->isValid() && \"Failed on valid report\");\n-        // Try again. We'll filter out the bad report when we trim the graph.\n-        // FIXME: It would be more efficient to use the same intermediate\n-        // trimmed graph, and just repeat the shortest-path search.\n-        return generatePathDiagnostic(PD, PC, bugReports);\n       }\n-      break;\n-    case PathDiagnosticConsumer::Minimal:\n-      if (!GenerateMinimalPathDiagnostic(PD, PDB, N, visitors)) {\n-        assert(!R->isValid() && \"Failed on valid report\");\n-        // Try again. We'll filter out the bad report when we trim the graph.\n-        return generatePathDiagnostic(PD, PC, bugReports);\n-      }\n-      break;\n-    case PathDiagnosticConsumer::None:\n-      if (!GenerateVisitorsOnlyPathDiagnostic(PD, PDB, N, visitors)) {\n-        assert(!R->isValid() && \"Failed on valid report\");\n-        // Try again. We'll filter out the bad report when we trim the graph.\n-        return generatePathDiagnostic(PD, PC, bugReports);\n+\n+      switch (ActiveScheme) {\n+      case PathDiagnosticConsumer::Extensive:\n+        GenerateExtensivePathDiagnostic(PD, PDB, N, visitors);\n+        break;\n+      case PathDiagnosticConsumer::Minimal:\n+        GenerateMinimalPathDiagnostic(PD, PDB, N, visitors);\n+        break;\n+      case PathDiagnosticConsumer::None:\n+        GenerateVisitorsOnlyPathDiagnostic(PD, PDB, N, visitors);\n+        break;\n       }\n-      break;\n-    }\n \n-    // Clean up the visitors we used.\n-    llvm::DeleteContainerPointers(visitors);\n+      // Clean up the visitors we used.\n+      llvm::DeleteContainerPointers(visitors);\n \n-    // Did anything change while generating this path?\n-    finalReportConfigToken = R->getConfigurationChangeToken();\n-  } while(finalReportConfigToken != originalReportConfigToken);\n+      // Did anything change while generating this path?\n+      finalReportConfigToken = R->getConfigurationChangeToken();\n+    } while (finalReportConfigToken != origReportConfigToken);\n \n-  // Finally, prune the diagnostic path of uninteresting stuff.\n-  if (!PD.path.empty()) {\n-    // Remove messages that are basically the same.\n-    removeRedundantMsgs(PD.getMutablePieces());\n+    if (!R->isValid())\n+      continue;\n \n-    if (R->shouldPrunePath() &&\n-        getEngine().getAnalysisManager().options.shouldPrunePaths()) {\n-      bool hasSomethingInteresting = RemoveUnneededCalls(PD.getMutablePieces(),\n-                                                         R);\n-      assert(hasSomethingInteresting);\n-      (void) hasSomethingInteresting;\n+    // Finally, prune the diagnostic path of uninteresting stuff.\n+    if (!PD.path.empty()) {\n+      // Remove messages that are basically the same.\n+      removeRedundantMsgs(PD.getMutablePieces());\n+\n+      if (R->shouldPrunePath() &&\n+          getEngine().getAnalysisManager().options.shouldPrunePaths()) {\n+        bool stillHasNotes = RemoveUnneededCalls(PD.getMutablePieces(), R);\n+        assert(stillHasNotes);\n+        (void)stillHasNotes;\n+      }\n+\n+      adjustCallLocations(PD.getMutablePieces());\n     }\n \n-    adjustCallLocations(PD.getMutablePieces());\n+    // We found a report and didn't suppress it.\n+    return true;\n   }\n \n-  return true;\n+  // We suppressed all the reports in this equivalence class.\n+  return false;\n }\n \n void BugReporter::Register(BugType *BT) {\n", "changed_method_name": "GRBugReporter::generatePathDiagnostic"}
{"commit_url": "https://github.com/llvm-mirror/clang/commit/ac39f135ea0d45bc37d1154fa8380d46aac0547d", "commit_message": "Minor optimization to r177367 to treat a module with missing dependencies as out-of-date rather than missing.\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@177369 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -1789,7 +1789,7 @@ ASTReader::ReadControlBlock(ModuleFile &F,\n                            ClientLoadCapabilities)) {\n         case Failure: return Failure;\n           // If we have to ignore the dependency, we'll have to ignore this too.\n-        case Missing: return Missing;\n+        case Missing:\n         case OutOfDate: return OutOfDate;\n         case VersionMismatch: return VersionMismatch;\n         case ConfigurationMismatch: return ConfigurationMismatch;\n", "changed_method_name": "ASTReader::ReadControlBlock"}
{"commit_url": "https://github.com/llvm-mirror/clang/commit/df5f80f8a34e26a4fb77f48f858c7838426a0785", "commit_message": "[analyzer] micro optimization as per Jordan\u2019s feedback on r177905.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@178062 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -833,13 +833,13 @@ RegionStoreManager::removeSubRegionBindings(RegionBindingsConstRef B,\n                                             const SubRegion *Top) {\n   BindingKey TopKey = BindingKey::Make(Top, BindingKey::Default);\n   const MemRegion *ClusterHead = TopKey.getBaseRegion();\n-  const ClusterBindings *Cluster = B.lookup(ClusterHead);\n \n   if (Top == ClusterHead) {\n     // We can remove an entire cluster's bindings all in one go.\n     return B.remove(Top);\n   }\n \n+  const ClusterBindings *Cluster = B.lookup(ClusterHead);\n   if (!Cluster) {\n     // If we're invalidating a region with a symbolic offset, we need to make\n     // sure we don't treat the base region as uninitialized anymore.\n", "changed_method_name": "RegionStoreManager::removeSubRegionBindings"}
{"commit_url": "https://github.com/llvm-mirror/clang/commit/90cdec1762c2a72b7c63f67c025597ab9ac8cae0", "commit_message": "AST: Simplify CharUnits::alignmentAtOffset\n\nCharUnits::alignmentAtOffset is equivalent to llvm::MinAlign but\nslightly less efficient.  Use it's implementation instead.\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@202099 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -173,12 +173,7 @@ namespace clang {\n       /// Given that this is a non-zero alignment value, what is the\n       /// alignment at the given offset?\n       CharUnits alignmentAtOffset(CharUnits offset) {\n-        // alignment: 0010000\n-        // offset:    1011100\n-        // lowBits:   0001011\n-        // result:    0000100\n-        QuantityType lowBits = (Quantity-1) & (offset.Quantity-1);\n-        return CharUnits((lowBits + 1) & ~lowBits);\n+        return CharUnits(llvm::MinAlign(Quantity, offset.Quantity));\n       }\n \n \n", "changed_method_name": "clang::CharUnits::alignmentAtOffset"}
{"commit_url": "https://github.com/llvm-mirror/clang/commit/575c8ea65c2a5212d95e9881f8a2aac27315dd53", "commit_message": "[AST] hasAttr followed by getAttr isn't efficient\n\nJust use getAttr because we are interested in the attribute's contents.\n\ngit-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@237336 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -1915,10 +1915,13 @@ VarDecl::isThisDeclarationADefinition(ASTContext &C) const {\n   if (hasInit())\n     return Definition;\n \n-  if (hasAttr<AliasAttr>() ||\n-      (hasAttr<SelectAnyAttr>() && !getAttr<SelectAnyAttr>()->isInherited()))\n+  if (hasAttr<AliasAttr>())\n     return Definition;\n \n+  if (const auto *SAA = getAttr<SelectAnyAttr>())\n+    if (!SAA->isInherited())\n+      return Definition;\n+\n   // A variable template specialization (other than a static data member\n   // template or an explicit specialization) is a declaration until we\n   // instantiate its initializer.\n", "changed_method_name": "VarDecl::isThisDeclarationADefinition"}
{"commit_url": "https://github.com/llvm-mirror/clang/commit/f78232dcbf734a1c7e42ae60b58c9bbe14b64516", "commit_message": "Replace use of SmallVector::back + pop_back with pop_back_val\n\nI ran across an instance where the value was being loaded\nout via back, then immediately popped.  Since pop_back_val\nis more efficient at this (it moves out), replace this \ninstance.\n\n\ngit-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@316015 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -361,8 +361,7 @@ static bool hasThrowOutNonThrowingFunc(SourceLocation &OpLoc, CFG *BodyCFG) {\n   SmallVector<CFGBlock *, 16> Stack;\n   Stack.push_back(&BodyCFG->getEntry());\n   while (!Stack.empty()) {\n-    CFGBlock *CurBlock = Stack.back();\n-    Stack.pop_back();\n+    CFGBlock *CurBlock = Stack.pop_back_val();\n \n     unsigned ID = CurBlock->getBlockID();\n     ThrowState CurState = States[ID];\n", "changed_method_name": "hasThrowOutNonThrowingFunc"}
{"commit_url": "https://github.com/llvm-mirror/clang/commit/007983114f448135906abddea70250d463fcd13a", "commit_message": "[objc-gnustep2] Use isalnum instead of a less efficient and nonportable equivalent.\n\nPatch by Hans Wennborg!\n\ngit-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@332964 91177308-0d34-0410-b5e6-96231b3b80d8", "code_diff": "@@ -1054,7 +1054,7 @@ class CGObjCGNUstep2 : public CGObjCGNUstep {\n       StringName = \".objc_str_\";\n       for (int i=0,e=Str.size() ; i<e ; ++i) {\n         char c = Str[i];\n-        if (isalpha(c) || isnumber(c))\n+        if (isalnum(c))\n           StringName += c;\n         else if (c == ' ')\n           StringName += '_';\n", "changed_method_name": "CGObjCGNUstep2::GenerateConstantString"}
{"commit_url": "https://github.com/mozilla/gecko-dev/commit/783e661627ee82083e5f2a71668ade7633dfb897", "commit_message": "Bug 925088 - SpiderMonkey: Micro-optimize x64's testStringTruthy. r=mjrosen", "code_diff": "@@ -1057,14 +1057,11 @@ class MacroAssemblerX64 : public MacroAssemblerX86Shared\n         testl(operand.valueReg(), operand.valueReg());\n         j(truthy ? NonZero : Zero, label);\n     }\n-    // This returns the tag in ScratchReg.\n     Condition testStringTruthy(bool truthy, const ValueOperand &value) {\n         unboxString(value, ScratchReg);\n \n         Operand lengthAndFlags(ScratchReg, JSString::offsetOfLengthAndFlags());\n-        movq(lengthAndFlags, ScratchReg);\n-        shrq(Imm32(JSString::LENGTH_SHIFT), ScratchReg);\n-        testq(ScratchReg, ScratchReg);\n+        testq(lengthAndFlags, Imm32(-1 << JSString::LENGTH_SHIFT));\n         return truthy ? Assembler::NonZero : Assembler::Zero;\n     }\n \n", "changed_method_name": "js::jit::MacroAssemblerX64::testStringTruthy"}
{"commit_url": "https://github.com/mozilla/gecko-dev/commit/b6275dd517c124256c1f1002a7260171cff54e90", "commit_message": "bug 625383 - optimize http chunked decoder memmoves r=hurley", "code_diff": "@@ -676,6 +676,28 @@ nsHttpTransaction::WritePipeSegment(nsIOutputStream *stream,\n     //\n     // OK, now let the caller fill this segment with data.\n     //\n+    if (!trans->mHaveAllHeaders) {\n+        // Reading too far ahead on a chunked encoding is expensive (see below)\n+        // so limit header reads to 1KB to minimize any potential damage while\n+        // we figure out the message delimiter.\n+        count = std::min(count, 1024U);\n+    } else if (trans->mChunkedDecoder) {\n+        // The API in use requires us to return entity data in 1 contiguous\n+        // buffer supplied by the caller. That means\n+        // all entity data needs to be moved up to cover gaps created by\n+        // stripping the chunk length. We can mitigate this problem by\n+        // doing short reads when we are parsing chunk lengths and limiting\n+        // reads in the middle of chunks to the remaining chunk size to\n+        // increase the frequency of chunk markers naturally aligning\n+        // at the start.\n+        if (!trans->mChunkedDecoder->GetChunkRemaining()) {\n+            count = std::min(count, 6U); // 6 is 4 hex chars + CRLF\n+        } else {\n+            // extra 2 bytes is for CRLF that terminates the chunk\n+            count = std::min(count,\n+                             trans->mChunkedDecoder->GetChunkRemaining() + 2);\n+        }\n+    }\n     rv = trans->mWriter->OnWriteSegment(buf, count, countWritten);\n     if (NS_FAILED(rv)) return rv; // caller didn't want to write anything\n \n", "changed_method_name": "mozilla::net::nsHttpTransaction::WritePipeSegment"}
{"commit_url": "https://github.com/mozilla/gecko-dev/commit/3a3d9ab7f782990d2cde6876fe1d1c1ae6378e66", "commit_message": "Bug 1119089. Switch from the ineffecient x = x.sub(x, y) to x.subout(y);\n\nThe recently added move assignment operators make the existing pattern more\nefficient, but using SubOut() is cleaner and even more efficient.\n\n--HG--\nextra : rebase_source : 14ba52bfde0a4a591ca39b92d86632206bbe13eb", "code_diff": "@@ -1282,8 +1282,8 @@ ClientTiledLayerBuffer::ValidateTile(TileClient aTile,\n     nsIntRect(aTileOrigin.x, aTileOrigin.y,\n               GetScaledTileSize().width, GetScaledTileSize().height);\n   // Intersect this area with the portion that's invalid.\n-  tileRegion = tileRegion.Sub(tileRegion, GetValidRegion());\n-  tileRegion = tileRegion.Sub(tileRegion, aDirtyRegion); // Has now been validated\n+  tileRegion.SubOut(GetValidRegion());\n+  tileRegion.SubOut(aDirtyRegion); // Has now been validated\n \n   backBuffer->SetWaste(tileRegion.Area() * mResolution * mResolution);\n   backBuffer->Unlock();\n", "changed_method_name": "mozilla::ClientTiledLayerBuffer::ValidateTile"}
{"commit_url": "https://github.com/mozilla/gecko-dev/commit/6adaf4dfcb7fae5b8d39536f54503f21681d91f4", "commit_message": "Bug 1121871 - Properly compute the invalid region when painting using the tiling fast path. r=nical", "code_diff": "@@ -418,20 +418,36 @@ ClientTiledPaintedLayer::RenderLayer()\n       ToClientLayer(GetMaskLayer())->RenderLayer();\n     }\n \n+    // For more complex cases we need to calculate a bunch of metrics before we\n+    // can do the paint.\n+    BeginPaint();\n+    if (mPaintData.mPaintFinished) {\n+      return;\n+    }\n+\n     // In some cases we can take a fast path and just be done with it.\n     if (UseFastPath()) {\n       TILING_LOG(\"TILING %p: Taking fast-path\\n\", this);\n       mValidRegion = neededRegion;\n+\n+      // Make sure that tiles that fall outside of the visible region or outside of the\n+      // critical displayport are discarded on the first update. Also make sure that we\n+      // only draw stuff inside the critical displayport on the first update.\n+      if (!mPaintData.mCriticalDisplayPort.IsEmpty()) {\n+        mValidRegion.And(mValidRegion, LayerIntRect::ToUntyped(mPaintData.mCriticalDisplayPort));\n+        invalidRegion.And(invalidRegion, LayerIntRect::ToUntyped(mPaintData.mCriticalDisplayPort));\n+      }\n+\n+      if (invalidRegion.IsEmpty()) {\n+        EndPaint();\n+        return;\n+      }\n+\n+      mContentClient->mTiledBuffer.SetFrameResolution(mPaintData.mResolution);\n       mContentClient->mTiledBuffer.PaintThebes(mValidRegion, invalidRegion, callback, data);\n       ClientManager()->Hold(this);\n       mContentClient->UseTiledLayerBuffer(TiledContentClient::TILED_BUFFER);\n-      return;\n-    }\n-\n-    // For more complex cases we need to calculate a bunch of metrics before we\n-    // can do the paint.\n-    BeginPaint();\n-    if (mPaintData.mPaintFinished) {\n+      EndPaint();\n       return;\n     }\n \n", "changed_method_name": "mozilla::layers::ClientTiledPaintedLayer::RenderLayer"}
{"commit_url": "https://github.com/mozilla/gecko-dev/commit/19d13525ebc7839243866b0252b51d57088fa174", "commit_message": "Bug 1237714.  Make nsContentUtils::IsCustomElementName faster in the common case of a non-custom-element name.  r=smaug", "code_diff": "@@ -2773,11 +2773,14 @@ nsContentUtils::IsCustomElementName(nsIAtom* aName)\n {\n   // The custom element name identifies a custom element and is a sequence of\n   // alphanumeric ASCII characters that must match the NCName production and\n-  // contain a U+002D HYPHEN-MINUS character.\n+  // contain a U+002D HYPHEN-MINUS character.  We check for the HYPHEN-MINUS\n+  // first, since that will typically not be present, which will allow us to\n+  // return before doing the more expensive (and generally passing) CheckQName\n+  // check.\n   nsDependentAtomString str(aName);\n   const char16_t* colon;\n-  if (NS_FAILED(nsContentUtils::CheckQName(str, false, &colon)) || colon ||\n-      str.FindChar('-') == -1) {\n+  if (str.FindChar('-') == -1 ||\n+      NS_FAILED(nsContentUtils::CheckQName(str, false, &colon)) || colon) {\n     return false;\n   }\n \n", "changed_method_name": "nsContentUtils::IsCustomElementName"}
{"commit_url": "https://github.com/mozilla/gecko-dev/commit/0391a5005094db4ee2e4c9fcd2529528ce428389", "commit_message": "Bug 1289165 - Apply the optimizations in moveDenseElements to unboxed objects; r=sfink", "code_diff": "@@ -568,10 +568,12 @@ MoveBoxedOrUnboxedDenseElements(JSContext* cx, JSObject* obj, uint32_t dstStart,\n         uint8_t* data = obj->as<UnboxedArrayObject>().elements();\n         size_t elementSize = UnboxedTypeSize(Type);\n \n-        if (UnboxedTypeNeedsPreBarrier(Type)) {\n+        if (UnboxedTypeNeedsPreBarrier(Type) &&\n+            JS::shadow::Zone::asShadowZone(obj->zone())->needsIncrementalBarrier())\n+        {\n             // Trigger pre barriers on any elements we are overwriting. See\n-            // moveDenseElements::moveDenseElements. No post barrier is needed\n-            // as only whole cell post barriers are used with unboxed objects.\n+            // NativeObject::moveDenseElements. No post barrier is needed as\n+            // only whole cell post barriers are used with unboxed objects.\n             for (size_t i = 0; i < length; i++)\n                 obj->as<UnboxedArrayObject>().triggerPreBarrier<Type>(dstStart + i);\n         }\n", "changed_method_name": "js::MoveBoxedOrUnboxedDenseElements"}
{"commit_url": "https://github.com/mozilla/gecko-dev/commit/7fccf77722188b706082866fcd60311a476e0c8a", "commit_message": "Bug 1373063 - Make nsFormFillController::HandleEvent() a bit faster by avoiding some string comparisons; r=MattN", "code_diff": "@@ -904,64 +904,65 @@ nsFormFillController::OnSearchCompletion(nsIAutoCompleteResult *aResult)\n NS_IMETHODIMP\n nsFormFillController::HandleEvent(nsIDOMEvent* aEvent)\n {\n-  nsAutoString type;\n-  aEvent->GetType(type);\n+  WidgetEvent* internalEvent = aEvent->WidgetEventPtr();\n+  NS_ENSURE_STATE(internalEvent);\n \n-  if (type.EqualsLiteral(\"focus\")) {\n+  switch (internalEvent->mMessage) {\n+  case eFocus:\n     return Focus(aEvent);\n-  }\n-  if (type.EqualsLiteral(\"mousedown\")) {\n+  case eMouseDown:\n     return MouseDown(aEvent);\n-  }\n-  if (type.EqualsLiteral(\"keypress\")) {\n+  case eKeyPress:\n     return KeyPress(aEvent);\n-  }\n-  if (type.EqualsLiteral(\"input\")) {\n-    bool unused = false;\n-    return (!mSuppressOnInput && mController && mFocusedInput) ?\n-           mController->HandleText(&unused) : NS_OK;\n-  }\n-  if (type.EqualsLiteral(\"blur\")) {\n+  case eEditorInput:\n+    {\n+      bool unused = false;\n+      return (!mSuppressOnInput && mController && mFocusedInput) ?\n+             mController->HandleText(&unused) : NS_OK;\n+    }\n+  case eBlur:\n     if (mFocusedInput) {\n       StopControllingInput();\n     }\n     return NS_OK;\n-  }\n-  if (type.EqualsLiteral(\"compositionstart\")) {\n+  case eCompositionStart:\n     NS_ASSERTION(mController, \"should have a controller!\");\n     if (mController && mFocusedInput) {\n       mController->HandleStartComposition();\n     }\n     return NS_OK;\n-  }\n-  if (type.EqualsLiteral(\"compositionend\")) {\n+  case eCompositionEnd:\n     NS_ASSERTION(mController, \"should have a controller!\");\n     if (mController && mFocusedInput) {\n       mController->HandleEndComposition();\n     }\n     return NS_OK;\n-  }\n-  if (type.EqualsLiteral(\"contextmenu\")) {\n+  case eContextMenu:\n     if (mFocusedPopup) {\n       mFocusedPopup->ClosePopup();\n     }\n     return NS_OK;\n-  }\n-  if (type.EqualsLiteral(\"pagehide\")) {\n-\n-    nsCOMPtr<nsIDocument> doc = do_QueryInterface(\n-      aEvent->InternalDOMEvent()->GetTarget());\n-    if (!doc) {\n-      return NS_OK;\n-    }\n+  case ePageHide:\n+    {\n+      nsCOMPtr<nsIDocument> doc = do_QueryInterface(\n+        aEvent->InternalDOMEvent()->GetTarget());\n+      if (!doc) {\n+        return NS_OK;\n+      }\n \n-    if (mFocusedInput) {\n-      if (doc == mFocusedInputNode->OwnerDoc()) {\n-        StopControllingInput();\n+      if (mFocusedInput) {\n+        if (doc == mFocusedInputNode->OwnerDoc()) {\n+          StopControllingInput();\n+        }\n       }\n-    }\n \n-    RemoveForDocument(doc);\n+      RemoveForDocument(doc);\n+    }\n+    break;\n+  default:\n+    // Handling the default case to shut up stupid -Wswitch warnings.\n+    // One day compilers will be smarter...\n+    break;\n   }\n \n   return NS_OK;\n", "changed_method_name": "nsFormFillController::HandleEvent"}
{"commit_url": "https://github.com/openssl/openssl/commit/c10e3f0cffb3820da64a3f822cca96239efe4369", "commit_message": "PBKDF2 should be efficient. Contributed by Christian Heimes\n<christian@python.org>.", "code_diff": "@@ -85,7 +85,7 @@ int PKCS5_PBKDF2_HMAC(const char *pass, int passlen,\n \tunsigned char digtmp[EVP_MAX_MD_SIZE], *p, itmp[4];\n \tint cplen, j, k, tkeylen, mdlen;\n \tunsigned long i = 1;\n-\tHMAC_CTX hctx;\n+\tHMAC_CTX hctx_tpl, hctx;\n \n \tmdlen = EVP_MD_size(digest);\n \tif (mdlen < 0)\n@@ -98,6 +98,11 @@ int PKCS5_PBKDF2_HMAC(const char *pass, int passlen,\n \t\tpasslen = 0;\n \telse if(passlen == -1)\n \t\tpasslen = strlen(pass);\n+\tif (!HMAC_Init_ex(&hctx_tpl, pass, passlen, digest, NULL))\n+\t\t{\n+\t\tHMAC_CTX_cleanup(&hctx_tpl);\n+\t\treturn 0;\n+\t\t}\n \twhile(tkeylen)\n \t\t{\n \t\tif(tkeylen > mdlen)\n@@ -111,19 +116,35 @@ int PKCS5_PBKDF2_HMAC(const char *pass, int passlen,\n \t\titmp[1] = (unsigned char)((i >> 16) & 0xff);\n \t\titmp[2] = (unsigned char)((i >> 8) & 0xff);\n \t\titmp[3] = (unsigned char)(i & 0xff);\n-\t\tif (!HMAC_Init_ex(&hctx, pass, passlen, digest, NULL)\n-\t\t\t|| !HMAC_Update(&hctx, salt, saltlen)\n-\t\t\t|| !HMAC_Update(&hctx, itmp, 4)\n-\t\t\t|| !HMAC_Final(&hctx, digtmp, NULL))\n+\t\tif (!HMAC_CTX_copy(&hctx, &hctx_tpl))\n \t\t\t{\n+\t\t\tHMAC_CTX_cleanup(&hctx_tpl);\n+\t\t\treturn 0;\n+\t\t\t}\n+\t\tif (!HMAC_Update(&hctx, salt, saltlen)\n+\t\t    || !HMAC_Update(&hctx, itmp, 4)\n+\t\t    || !HMAC_Final(&hctx, digtmp, NULL))\n+\t\t\t{\n+\t\t\tHMAC_CTX_cleanup(&hctx_tpl);\n \t\t\tHMAC_CTX_cleanup(&hctx);\n \t\t\treturn 0;\n \t\t\t}\n \t\tmemcpy(p, digtmp, cplen);\n \t\tfor(j = 1; j < iter; j++)\n \t\t\t{\n-\t\t\tHMAC(digest, pass, passlen,\n-\t\t\t\t digtmp, mdlen, digtmp, NULL);\n+\t\t\tif (!HMAC_CTX_copy(&hctx, &hctx_tpl))\n+\t\t\t\t{\n+\t\t\t\tHMAC_CTX_cleanup(&hctx_tpl);\n+\t\t\t\treturn 0;\n+\t\t\t\t}\n+\t\t\tif (!HMAC_Update(&hctx, digtmp, mdlen)\n+\t\t\t    || !HMAC_Final(&hctx, digtmp, NULL))\n+\t\t\t\t{\n+\t\t\t\tHMAC_CTX_cleanup(&hctx_tpl);\n+\t\t\t\tHMAC_CTX_cleanup(&hctx);\n+\t\t\t\treturn 0;\n+\t\t\t\t}\n+\t\t\tHMAC_CTX_cleanup(&hctx);\n \t\t\tfor(k = 0; k < cplen; k++)\n \t\t\t\tp[k] ^= digtmp[k];\n \t\t\t}\n@@ -131,7 +152,7 @@ int PKCS5_PBKDF2_HMAC(const char *pass, int passlen,\n \t\ti++;\n \t\tp+= cplen;\n \t\t}\n-\tHMAC_CTX_cleanup(&hctx);\n+\tHMAC_CTX_cleanup(&hctx_tpl);\n #ifdef DEBUG_PKCS5V2\n \tfprintf(stderr, \"Password:\\n\");\n \th__dump (pass, passlen);\n", "changed_method_name": "PKCS5_PBKDF2_HMAC"}
{"commit_url": "https://github.com/openssl/openssl/commit/e8b0dd57c0e9c53fd0708f0f458a7a2fd7a95c91", "commit_message": "ssl/t1_enc.c: optimize PRF (suggested by Intel).", "code_diff": "@@ -160,7 +160,7 @@ static int tls1_P_hash(const EVP_MD *md, const unsigned char *sec,\n \t{\n \tint chunk;\n \tsize_t j;\n-\tEVP_MD_CTX ctx, ctx_tmp;\n+\tEVP_MD_CTX ctx, ctx_tmp, ctx_init;\n \tEVP_PKEY *mac_key;\n \tunsigned char A1[EVP_MAX_MD_SIZE];\n \tsize_t A1_len;\n@@ -171,14 +171,14 @@ static int tls1_P_hash(const EVP_MD *md, const unsigned char *sec,\n \n \tEVP_MD_CTX_init(&ctx);\n \tEVP_MD_CTX_init(&ctx_tmp);\n-\tEVP_MD_CTX_set_flags(&ctx, EVP_MD_CTX_FLAG_NON_FIPS_ALLOW);\n-\tEVP_MD_CTX_set_flags(&ctx_tmp, EVP_MD_CTX_FLAG_NON_FIPS_ALLOW);\n+\tEVP_MD_CTX_init(&ctx_init);\n+\tEVP_MD_CTX_set_flags(&ctx_init, EVP_MD_CTX_FLAG_NON_FIPS_ALLOW);\n \tmac_key = EVP_PKEY_new_mac_key(EVP_PKEY_HMAC, NULL, sec, sec_len);\n \tif (!mac_key)\n \t\tgoto err;\n-\tif (!EVP_DigestSignInit(&ctx,NULL,md, NULL, mac_key))\n+\tif (!EVP_DigestSignInit(&ctx_init,NULL,md, NULL, mac_key))\n \t\tgoto err;\n-\tif (!EVP_DigestSignInit(&ctx_tmp,NULL,md, NULL, mac_key))\n+\tif (!EVP_MD_CTX_copy_ex(&ctx,&ctx_init))\n \t\tgoto err;\n \tif (seed1 && !EVP_DigestSignUpdate(&ctx,seed1,seed1_len))\n \t\tgoto err;\n@@ -196,13 +196,11 @@ static int tls1_P_hash(const EVP_MD *md, const unsigned char *sec,\n \tfor (;;)\n \t\t{\n \t\t/* Reinit mac contexts */\n-\t\tif (!EVP_DigestSignInit(&ctx,NULL,md, NULL, mac_key))\n-\t\t\tgoto err;\n-\t\tif (!EVP_DigestSignInit(&ctx_tmp,NULL,md, NULL, mac_key))\n+\t\tif (!EVP_MD_CTX_copy_ex(&ctx,&ctx_init))\n \t\t\tgoto err;\n \t\tif (!EVP_DigestSignUpdate(&ctx,A1,A1_len))\n \t\t\tgoto err;\n-\t\tif (!EVP_DigestSignUpdate(&ctx_tmp,A1,A1_len))\n+\t\tif (olen>chunk && !EVP_MD_CTX_copy_ex(&ctx_tmp,&ctx))\n \t\t\tgoto err;\n \t\tif (seed1 && !EVP_DigestSignUpdate(&ctx,seed1,seed1_len))\n \t\t\tgoto err;\n@@ -238,6 +236,7 @@ err:\n \tEVP_PKEY_free(mac_key);\n \tEVP_MD_CTX_cleanup(&ctx);\n \tEVP_MD_CTX_cleanup(&ctx_tmp);\n+\tEVP_MD_CTX_cleanup(&ctx_init);\n \tOPENSSL_cleanse(A1,sizeof(A1));\n \treturn ret;\n \t}\n", "changed_method_name": "tls1_P_hash"}
{"commit_url": "https://github.com/openssl/openssl/commit/be2c4d9bd9e81030c547a34216ae2d8e5c888190", "commit_message": "Add support for aes-128/192/256-ctr to the cryptodev engine.\nThis can be used to speed up SRTP with libsrtp, e.g. on TI omap/sitara based devices.", "code_diff": "@@ -147,6 +147,9 @@ static struct {\n \t{ CRYPTO_AES_CBC,\t\tNID_aes_128_cbc,\t16,\t16, },\n \t{ CRYPTO_AES_CBC,\t\tNID_aes_192_cbc,\t16,\t24, },\n \t{ CRYPTO_AES_CBC,\t\tNID_aes_256_cbc,\t16,\t32, },\n+\t{ CRYPTO_AES_CTR,\t\tNID_aes_128_ctr,\t14,\t16, },\n+\t{ CRYPTO_AES_CTR,\t\tNID_aes_192_ctr,\t14,\t24, },\n+\t{ CRYPTO_AES_CTR,\t\tNID_aes_256_ctr,\t14,\t32, },\n \t{ CRYPTO_BLF_CBC,\t\tNID_bf_cbc,\t\t8,\t16, },\n \t{ CRYPTO_CAST_CBC,\t\tNID_cast5_cbc,\t\t8,\t16, },\n \t{ CRYPTO_SKIPJACK_CBC,\t\tNID_undef,\t\t0,\t 0, },\n@@ -600,6 +603,45 @@ const EVP_CIPHER cryptodev_aes_256_cbc = {\n \tNULL\n };\n \n+const EVP_CIPHER cryptodev_aes_ctr = {\n+\tNID_aes_128_ctr,\n+\t16, 16, 14,\n+\tEVP_CIPH_CTR_MODE,\n+\tcryptodev_init_key,\n+\tcryptodev_cipher,\n+\tcryptodev_cleanup,\n+\tsizeof(struct dev_crypto_state),\n+\tEVP_CIPHER_set_asn1_iv,\n+\tEVP_CIPHER_get_asn1_iv,\n+\tNULL\n+};\n+\n+const EVP_CIPHER cryptodev_aes_ctr_192 = {\n+\tNID_aes_192_ctr,\n+\t16, 24, 14,\n+\tEVP_CIPH_CTR_MODE,\n+\tcryptodev_init_key,\n+\tcryptodev_cipher,\n+\tcryptodev_cleanup,\n+\tsizeof(struct dev_crypto_state),\n+\tEVP_CIPHER_set_asn1_iv,\n+\tEVP_CIPHER_get_asn1_iv,\n+\tNULL\n+};\n+\n+const EVP_CIPHER cryptodev_aes_ctr_256 = {\n+\tNID_aes_256_ctr,\n+\t16, 32, 14,\n+\tEVP_CIPH_CTR_MODE,\n+\tcryptodev_init_key,\n+\tcryptodev_cipher,\n+\tcryptodev_cleanup,\n+\tsizeof(struct dev_crypto_state),\n+\tEVP_CIPHER_set_asn1_iv,\n+\tEVP_CIPHER_get_asn1_iv,\n+\tNULL\n+};\n+\n /*\n  * Registered by the ENGINE when used to find out how to deal with\n  * a particular NID in the ENGINE. this says what we'll do at the\n@@ -637,6 +679,15 @@ cryptodev_engine_ciphers(ENGINE *e, const EVP_CIPHER **cipher,\n \tcase NID_aes_256_cbc:\n \t\t*cipher = &cryptodev_aes_256_cbc;\n \t\tbreak;\n+\tcase NID_aes_128_ctr:\n+\t\t*cipher = &cryptodev_aes_ctr;\n+\t\tbreak;\n+\tcase NID_aes_192_ctr:\n+\t\t*cipher = &cryptodev_aes_ctr_192;\n+\t\tbreak;\n+\tcase NID_aes_256_ctr:\n+\t\t*cipher = &cryptodev_aes_ctr_256;\n+\t\tbreak;\n \tdefault:\n \t\t*cipher = NULL;\n \t\tbreak;\n", "changed_method_name": "cryptodev_engine_ciphers"}
{"commit_url": "https://github.com/openssl/openssl/commit/1d2a18dc5a3b3363e17db5af8b6b0273856ac077", "commit_message": "Multiblock corrupted pointer fix\n\nOpenSSL 1.0.2 introduced the \"multiblock\" performance improvement. This\nfeature only applies on 64 bit x86 architecture platforms that support AES\nNI instructions. A defect in the implementation of \"multiblock\" can cause\nOpenSSL's internal write buffer to become incorrectly set to NULL when\nusing non-blocking IO. Typically, when the user application is using a\nsocket BIO for writing, this will only result in a failed connection.\nHowever if some other BIO is used then it is likely that a segmentation\nfault will be triggered, thus enabling a potential DoS attack.\n\nCVE-2015-0290\n\nReviewed-by: Richard Levitte <levitte@openssl.org>\nReviewed-by: Andy Polyakov <appro@openssl.org>", "code_diff": "@@ -804,7 +804,7 @@ int ssl3_write_bytes(SSL *s, int type, const void *buf_, int len)\n \n             i = ssl3_write_pending(s, type, &buf[tot], nw);\n             if (i <= 0) {\n-                if (i < 0) {\n+                if (i < 0 && (!s->wbio || !BIO_should_retry(s->wbio))) {\n                     OPENSSL_free(wb->buf);\n                     wb->buf = NULL;\n                 }\n", "changed_method_name": "ssl3_write_bytes"}
{"commit_url": "https://github.com/openssl/openssl/commit/06b9ff06cc7fdd8f51abb92aaac39d3988a7090e", "commit_message": "Swap to using _longjmp/_setjmp instead of longjmp/setjmp\n\n_longjmp/_setjmp do not manipulate the signal mask whilst\nlongjmp/setjmp may do. Online sources suggest this could result\nin a significant speed up in the context switching.\n\nReviewed-by: Rich Salz <rsalz@openssl.org>", "code_diff": "@@ -80,9 +80,9 @@ static inline int async_fibre_swapcontext(async_fibre *o, async_fibre *n, int r)\n {\n     o->env_init = 1;\n \n-    if (!r || !setjmp(o->env)) {\n+    if (!r || !_setjmp(o->env)) {\n         if (n->env_init)\n-            longjmp(n->env, 1);\n+            _longjmp(n->env, 1);\n         else\n             setcontext(&n->fibre);\n     }\n", "changed_method_name": "async_fibre_swapcontext"}
{"commit_url": "https://github.com/openssl/openssl/commit/5fc2c6896d5050735c7d99dc80275c72fc58c49c", "commit_message": "VSI submission: make the VMS version of RAND_poll() faster and more secure\n\nReviewed-by: Rich Salz <rsalz@openssl.org>", "code_diff": "@@ -7,15 +7,21 @@\n  * https://www.openssl.org/source/license.html\n  */\n \n+/*\n+ * Modified by VMS Software, Inc (2016)\n+ *    Eliminate looping through all processes (performance)\n+ *    Add additional randomizations using rand() function\n+ */\n+\n #include <openssl/rand.h>\n #include \"rand_lcl.h\"\n \n #if defined(OPENSSL_SYS_VMS)\n-\n # include <descrip.h>\n # include <jpidef.h>\n # include <ssdef.h>\n # include <starlet.h>\n+# include <efndef>\n # ifdef __DECC\n #  pragma message disable DOLLARID\n # endif\n@@ -33,76 +39,94 @@\n # endif                         /* __INITIAL_POINTER_SIZE == 64 [else] */\n \n static struct items_data_st {\n-    short length, code;         /* length is amount of bytes */\n+    short length, code;         /* length is number of bytes */\n } items_data[] = {\n-    {\n-        4, JPI$_BUFIO\n-    },\n-    {\n-        4, JPI$_CPUTIM\n-    },\n-    {\n-        4, JPI$_DIRIO\n-    },\n-    {\n-        8, JPI$_LOGINTIM\n-    },\n-    {\n-        4, JPI$_PAGEFLTS\n-    },\n-    {\n-        4, JPI$_PID\n-    },\n-    {\n-        4, JPI$_WSSIZE\n-    },\n-    {\n-        0, 0\n-    }\n+    {4, JPI$_BUFIO},\n+    {4, JPI$_CPUTIM},\n+    {4, JPI$_DIRIO},\n+    {4, JPI$_IMAGECOUNT},\n+    {8, JPI$_LAST_LOGIN_I},\n+    {8, JPI$_LOGINTIM},\n+    {4, JPI$_PAGEFLTS},\n+    {4, JPI$_PID},\n+    {4, JPI$_PPGCNT},\n+    {4, JPI$_WSPEAK},\n+    {4, JPI$_FINALEXC},\n+    {0, 0}                      /* zero terminated */\n };\n \n int RAND_poll(void)\n {\n-    long pid, iosb[2];\n-    int status = 0;\n+\n+    /* determine the number of items in the JPI array */\n+\n+    struct items_data_st item_entry;\n+    int item_entry_count = sizeof(items_data)/sizeof(item_entry);\n+\n+    /* Create the JPI itemlist array to hold item_data content */\n+\n     struct {\n         short length, code;\n-        long *buffer;\n+        int *buffer;\n         int *retlen;\n-    } item[32], *pitem;\n-    unsigned char data_buffer[256];\n-    short total_length = 0;\n+    } item[item_entry_count], *pitem; /* number of entries in items_data */\n+\n     struct items_data_st *pitems_data;\n+    int data_buffer[(item_entry_count*2)+4]; /* 8 bytes per entry max */\n+    int iosb[2];\n+    int sys_time[2];\n+    int *ptr;\n+    int i, j ;\n+    int tmp_length   = 0;\n+    int total_length = 0;\n \n     pitems_data = items_data;\n     pitem = item;\n \n-    /* Setup */\n-    while (pitems_data->length && (total_length + pitems_data->length <= 256)) {\n+\n+    /* Setup itemlist for GETJPI */\n+    while (pitems_data->length) {\n         pitem->length = pitems_data->length;\n-        pitem->code = pitems_data->code;\n-        pitem->buffer = (long *)&data_buffer[total_length];\n+        pitem->code   = pitems_data->code;\n+        pitem->buffer = &data_buffer[total_length];\n         pitem->retlen = 0;\n-        total_length += pitems_data->length;\n+        /* total_length is in longwords */\n+        total_length += pitems_data->length/4;\n         pitems_data++;\n         pitem ++;\n     }\n     pitem->length = pitem->code = 0;\n \n-    /*\n-     * Scan through all the processes in the system and add entropy with\n-     * results from the processes that were possible to look at.\n-     * However, view the information as only half trustable.\n-     */\n-    pid = -1;                   /* search context */\n-    while ((status = sys$getjpiw(0, &pid, 0, item, iosb, 0, 0))\n-           != SS$_NOMOREPROC) {\n-        if (status == SS$_NORMAL) {\n-            RAND_add((PTR_T) data_buffer, total_length, total_length / 2);\n+    /* Fill data_buffer with various info bits from this process */\n+    /* and twist that data to seed the SSL random number init    */\n+\n+    if (sys$getjpiw(EFN$C_ENF, NULL, NULL, item, &iosb, 0, 0) == SS$_NORMAL) {\n+        for (i = 0; i < total_length; i++) {\n+            sys$gettim((struct _generic_64 *)&sys_time[0]);\n+            srand(sys_time[0] * data_buffer[0] * data_buffer[1] + i);\n+\n+            if (i == (total_length - 1)) { /* for JPI$_FINALEXC */\n+                ptr = &data_buffer[i];\n+                for (j = 0; j < 4; j++) {\n+                    data_buffer[i + j] = ptr[j];\n+                    /* OK to use rand() just to scramble the seed */\n+                    data_buffer[i + j] ^= (sys_time[0] ^ rand());\n+                    tmp_length++;\n+                }\n+            } else {\n+                /* OK to use rand() just to scramble the seed */\n+                data_buffer[i] ^= (sys_time[0] ^ rand());\n+            }\n         }\n+\n+        total_length += (tmp_length - 1);\n+\n+        /* size of seed is total_length*4 bytes (64bytes) */\n+        RAND_add((PTR_T) data_buffer, total_length*4, total_length * 2);\n+    } else {\n+        return 0;\n     }\n-    sys$gettim(iosb);\n-    RAND_add((PTR_T) iosb, sizeof(iosb), sizeof(iosb) / 2);\n+\n     return 1;\n }\n \n", "changed_method_name": "RAND_poll"}
{"commit_url": "https://github.com/openssl/openssl/commit/65d62488b8c808350f440d2276034f5223b391ad", "commit_message": "openssl enc: Don't unbuffer stdin\n\n - unbuffer causes single-byte reads from stdin and poor performance\n\nFixes #3281\nCLA: trivial\n\nReviewed-by: Rich Salz <rsalz@openssl.org>\nReviewed-by: Richard Levitte <levitte@openssl.org>\n(Merged from https://github.com/openssl/openssl/pull/3299)", "code_diff": "@@ -291,7 +291,6 @@ int enc_main(int argc, char **argv)\n     buff = app_malloc(EVP_ENCODE_LENGTH(bsize), \"evp buffer\");\n \n     if (infile == NULL) {\n-        unbuffer(stdin);\n         in = dup_bio_in(informat);\n     } else\n         in = bio_open_default(infile, 'r', informat);\n", "changed_method_name": "enc_main"}
{"commit_url": "https://github.com/openssl/openssl/commit/848113a30b431c2fe21ae8de2a366b9b6146fb92", "commit_message": "bn/bn_exp.c: mitigation of the One-and-Done side-channel attack.\n\nThe One&Done attack, which is described in a paper to appear in the\nUSENIX Security'18 conference, uses EM emanations to recover the values\nof the bits that are obtained using BN_is_bit_set while constructing\nthe value of the window in BN_mod_exp_consttime. The EM signal changes\nslightly depending on the value of the bit, and since the lookup of a\nbit is surrounded by highly regular execution (constant-time Montgomery\nmultiplications) the attack is able to isolate the (very brief) part of\nthe signal that changes depending on the bit. Although the change is\nslight, the attack recovers it successfully >90% of the time on several\nphones and IoT devices (all with ARM processors with clock rates around\n1GHz), so after only one RSA decryption more than 90% of the bits in\nd_p and d_q are recovered correctly, which enables rapid recovery of\nthe full RSA key using an algorithm (also described in the paper) that\nmodifies the branch-and-prune approach for a situation in which the\nexponents' bits are recovered with errors, i.e. where we do not know\na priori which bits are correctly recovered.\n\nThe mitigation for the attack is relatively simple - all the bits of\nthe window are obtained at once, along with other bits so that an\nentire integer's worth of bits are obtained together using masking and\nshifts, without unnecessarily considering each bit in isolation. This\nimproves performance somewhat (one call to bn_get_bits is faster than\nseveral calls to BN_is_bit_set), so the attacker now gets one signal\nsnippet per window (rather than one per bit) in which the signal is\naffected by all bits in the integer (rather than just the one bit).\n\nReviewed-by: Andy Polyakov <appro@openssl.org>\nReviewed-by: Rich Salz <rsalz@openssl.org>\n(Merged from https://github.com/openssl/openssl/pull/6276)", "code_diff": "@@ -473,7 +473,6 @@ int BN_mod_exp_mont(BIGNUM *rr, const BIGNUM *a, const BIGNUM *p,\n     return ret;\n }\n \n-#if defined(SPARC_T4_MONT)\n static BN_ULONG bn_get_bits(const BIGNUM *a, int bitpos)\n {\n     BN_ULONG ret = 0;\n@@ -492,7 +491,6 @@ static BN_ULONG bn_get_bits(const BIGNUM *a, int bitpos)\n \n     return ret & BN_MASK2;\n }\n-#endif\n \n /*\n  * BN_mod_exp_mont_consttime() stores the precomputed powers in a specific\n@@ -599,7 +597,7 @@ int BN_mod_exp_mont_consttime(BIGNUM *rr, const BIGNUM *a, const BIGNUM *p,\n                               const BIGNUM *m, BN_CTX *ctx,\n                               BN_MONT_CTX *in_mont)\n {\n-    int i, bits, ret = 0, window, wvalue;\n+    int i, bits, ret = 0, window, wvalue, wmask, window0;\n     int top;\n     BN_MONT_CTX *mont = NULL;\n \n@@ -1040,27 +1038,44 @@ int BN_mod_exp_mont_consttime(BIGNUM *rr, const BIGNUM *a, const BIGNUM *p,\n             }\n         }\n \n-        bits--;\n-        for (wvalue = 0, i = bits % window; i >= 0; i--, bits--)\n-            wvalue = (wvalue << 1) + BN_is_bit_set(p, bits);\n+        /* \n+         * The exponent may not have a whole number of fixed-size windows.\n+         * To simplify the main loop, the initial window has between 1 and\n+         * full-window-size bits such that what remains is always a whole\n+         * number of windows\n+         */ \n+        window0 = (bits - 1) % window + 1;\n+        wmask = (1 << window0) - 1;\n+        bits -= window0;\n+        wvalue = bn_get_bits(p, bits) & wmask;\n         if (!MOD_EXP_CTIME_COPY_FROM_PREBUF(&tmp, top, powerbuf, wvalue,\n                                             window))\n             goto err;\n \n+        wmask = (1 << window) - 1;\n         /*\n          * Scan the exponent one window at a time starting from the most\n          * significant bits.\n          */\n-        while (bits >= 0) {\n-            wvalue = 0;         /* The 'value' of the window */\n+        while (bits > 0) {\n \n-            /* Scan the window, squaring the result as we go */\n-            for (i = 0; i < window; i++, bits--) {\n+            /* Square the result window-size times */\n+            for (i = 0; i < window; i++)\n                 if (!BN_mod_mul_montgomery(&tmp, &tmp, &tmp, mont, ctx))\n                     goto err;\n-                wvalue = (wvalue << 1) + BN_is_bit_set(p, bits);\n-            }\n \n+            /* \n+             * Get a window's worth of bits from the exponent\n+             * This avoids calling BN_is_bit_set for each bit, which\n+             * is not only slower but also makes each bit vulnerable to\n+             * EM (and likely other) side-channel attacks like One&Done\n+             * (for details see \"One&Done: A Single-Decryption EM-Based\n+             *  Attack on OpenSSL\u2019s Constant-Time Blinded RSA\" by M. Alam,\n+             *  H. Khan, M. Dey, N. Sinha, R. Callan, A. Zajic, and\n+             *  M. Prvulovic, in USENIX Security'18)\n+             */\n+            bits -= window;\n+            wvalue = bn_get_bits(p, bits) & wmask;\n             /*\n              * Fetch the appropriate pre-computed value from the pre-buf\n              */\n", "changed_method_name": "BN_mod_exp_mont_consttime"}
{"commit_url": "https://github.com/openssl/openssl/commit/cb8164b05e3bad5586c2a109bbdbab1ad65a1a6f", "commit_message": "Fix tls_cbc_digest_record is slow using SHA-384 and short messages\n\nThe formula used for this is now\n\nkVarianceBlocks = ((255 + 1 + md_size + md_block_size - 1) / md_block_size) + 1\n\nNotice that md_block_size=64 for SHA256, which results on the\nmagic constant kVarianceBlocks = 6.\nHowever, md_block_size=128 for SHA384 leading to kVarianceBlocks = 4.\n\nCLA:trivial\n\nReviewed-by: Matt Caswell <matt@openssl.org>\nReviewed-by: Paul Dale <paul.dale@oracle.com>\n(Merged from https://github.com/openssl/openssl/pull/7342)", "code_diff": "@@ -256,12 +256,13 @@ int ssl3_cbc_digest_record(const EVP_MD_CTX *ctx,\n      * of hash termination (0x80 + 64-bit length) don't fit in the final\n      * block, we say that the final two blocks can vary based on the padding.\n      * TLSv1 has MACs up to 48 bytes long (SHA-384) and the padding is not\n-     * required to be minimal. Therefore we say that the final six blocks can\n+     * required to be minimal. Therefore we say that the final |variance_blocks|\n+     * blocks can\n      * vary based on the padding. Later in the function, if the message is\n      * short and there obviously cannot be this many blocks then\n      * variance_blocks can be reduced.\n      */\n-    variance_blocks = is_sslv3 ? 2 : 6;\n+    variance_blocks = is_sslv3 ? 2 : ( ((255 + 1 + md_size + md_block_size - 1) / md_block_size) + 1);\n     /*\n      * From now on we're dealing with the MAC, which conceptually has 13\n      * bytes of `header' before the start of the data (TLS) or 71/75 bytes\n", "changed_method_name": "ssl3_cbc_digest_record"}
{"commit_url": "https://github.com/systemd/systemd/commit/66a67effcc5beaf8a61e1c1147c3114b02a96439", "commit_message": "sd-dhcp-client: --omg-optimized\n\nPassing the protocol to socket() is redundant as it will be specified again in\nbind(). Dropping the redundancy reduces the cost of bind() from ~30ms to ~0ms.\nFor details see [0].\n\nnetworkd in a container (i.e., with next to no network latency) can now\nnegotiate a DHCP lease in 0.7 - 5 ms.\n\nThanks to Kay for help with debugging and to Daniel Borkmann for the pointer\nto fix the problem.\n\n[0]: <https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=902fefb82ef72a50c78cb4a20cc954b037a98d1c>", "code_diff": "@@ -37,8 +37,7 @@ int dhcp_network_bind_raw_socket(int index, union sockaddr_union *link)\n         assert(index > 0);\n         assert(link);\n \n-        s = socket(AF_PACKET, SOCK_DGRAM | SOCK_CLOEXEC | SOCK_NONBLOCK,\n-                   htons(ETH_P_IP));\n+        s = socket(AF_PACKET, SOCK_DGRAM | SOCK_CLOEXEC | SOCK_NONBLOCK, 0);\n         if (s < 0)\n                 return -errno;\n \n", "changed_method_name": "dhcp_network_bind_raw_socket"}
{"commit_url": "https://github.com/systemd/systemd/commit/bcf3ce7b39529eb5421aa45d6336c9b12f8594c0", "commit_message": "sd-ipv4ll: speed up bind() in the same way as for dhcp", "code_diff": "@@ -38,7 +38,7 @@ int arp_network_bind_raw_socket(int index, union sockaddr_union *link) {\n         assert(index > 0);\n         assert(link);\n \n-        s = socket(PF_PACKET, SOCK_DGRAM | SOCK_CLOEXEC | SOCK_NONBLOCK, htons(ETH_P_ARP));\n+        s = socket(PF_PACKET, SOCK_DGRAM | SOCK_CLOEXEC | SOCK_NONBLOCK, 0);\n         if (s < 0)\n                 return -errno;\n \n", "changed_method_name": "arp_network_bind_raw_socket"}
{"commit_url": "https://github.com/systemd/systemd/commit/1930eed2a7855d2df06ccf51f9e394428bf547e2", "commit_message": "journal/compress: improve xz compression performance\n\nThe new lzma2 compression options at the top of compress_blob_xz are\nequivalent to using preset \"0\", exept for using a 1 MiB dictionary\n(the same as preset \"1\"). This makes the memory usage at most 7.5 MiB\nin the compressor, and 1 MiB in the decompressor, instead of the\nprevious 92 MiB in the compressor and 8 MiB in the decompressor.\n\nAccording to test-compress-benchmark this commit makes XZ compression\n20 times faster, with no increase in compressed data size.\nUsing more realistic test data (an ELF binary rather than repeating\nASCII letters 'a' through 'z' in order) it only provides a factor 10\nspeedup, and at a cost if a 10% increase in compressed data size.\nBut that is still a worthwhile trade-off.\n\nAccording to test-compress-benchmark XZ compression is still 25 times\nslower than LZ4, but the compressed data is one eighth the size.\nUsing more realistic test data XZ compression is only 18 times slower\nthan LZ4, and the compressed data is only one quarter the size.\n\n$ ./test-compress-benchmark\nXZ: compressed & decompressed 2535300963 bytes in 42.30s (57.15MiB/s), mean compresion 99.95%, skipped 3570 bytes\nLZ4: compressed & decompressed 2535303543 bytes in 1.60s (1510.60MiB/s), mean compresion 99.60%, skipped 990 bytes", "code_diff": "@@ -49,6 +49,13 @@ DEFINE_STRING_TABLE_LOOKUP(object_compressed, int);\n \n int compress_blob_xz(const void *src, uint64_t src_size, void *dst, uint64_t *dst_size) {\n #ifdef HAVE_XZ\n+        static const lzma_options_lzma opt = {\n+                1u << 20u, NULL, 0, LZMA_LC_DEFAULT, LZMA_LP_DEFAULT,\n+                LZMA_PB_DEFAULT, LZMA_MODE_FAST, 128, LZMA_MF_HC3, 4};\n+        static const lzma_filter filters[2] = {\n+                {LZMA_FILTER_LZMA2, (lzma_options_lzma*) &opt},\n+                {LZMA_VLI_UNKNOWN, NULL}\n+        };\n         lzma_ret ret;\n         size_t out_pos = 0;\n \n@@ -60,8 +67,11 @@ int compress_blob_xz(const void *src, uint64_t src_size, void *dst, uint64_t *ds\n         /* Returns < 0 if we couldn't compress the data or the\n          * compressed result is longer than the original */\n \n-        ret = lzma_easy_buffer_encode(LZMA_PRESET_DEFAULT, LZMA_CHECK_NONE, NULL,\n-                                      src, src_size, dst, &out_pos, src_size - 1);\n+        if (src_size < 80)\n+                return -ENOBUFS;\n+\n+        ret = lzma_stream_buffer_encode((lzma_filter*) filters, LZMA_CHECK_NONE, NULL,\n+                                        src, src_size, dst, &out_pos, src_size - 1);\n         if (ret != LZMA_OK)\n                 return -ENOBUFS;\n \n", "changed_method_name": "compress_blob_xz"}
{"commit_url": "https://github.com/systemd/systemd/commit/7943f42275025e1b6642b580b19b24dfab8dee61", "commit_message": "journal: optimize iteration by returning previously found candidate entry\n\nIn next_beyond_location() when the JournalFile's location type is\nLOCATION_SEEK, it means there's nothing to do, because we already have\nthe location of the candidate entry. Do an early return. Note that now\nnext_beyond_location() does not anymore guarantee on return that the\nentry is mapped, but previous patches made sure the caller does not\ncare.\n\nThis optimization is at least as good as \"journal: optimize iteration:\nskip files that cannot improve current candidate entry\" was.\n\nTiming results on my workstation, using:\n$ time ./journalctl -q --since=2014-06-01 --until=2014-07-01 > /dev/null\n\nBefore \"Revert \"journal: optimize iteration: skip files that cannot\nimprove current candidate entry\":\n\nreal    0m5.349s\nuser    0m5.166s\nsys     0m0.181s\n\nNow:\n\nreal    0m3.901s\nuser    0m3.724s\nsys     0m0.176s", "code_diff": "@@ -742,6 +742,12 @@ static int next_beyond_location(sd_journal *j, JournalFile *f, direction_t direc\n         f->last_n_entries = n_entries;\n \n         if (f->last_direction == direction && f->current_offset > 0) {\n+                /* LOCATION_SEEK here means we did the work in a previous\n+                 * iteration and the current location already points to a\n+                 * candidate entry. */\n+                if (f->location_type == LOCATION_SEEK)\n+                        return 1;\n+\n                 cp = f->current_offset;\n \n                 r = journal_file_move_to_object(f, OBJECT_ENTRY, cp, &c);\n", "changed_method_name": "next_beyond_location"}
{"commit_url": "https://github.com/systemd/systemd/commit/426bb5ddb8ff122d3e08b0480466718b68485e70", "commit_message": "bus-proxyd: optimize replies if they're not requested\n\nIf a caller does not request a reply, dont send it. This skips message\ncreation and speeds up NO_REPLY_EXPECTED cases. Note that sd-bus still\nhandles this case internally, but if we handle it in bus-proxyd, we can\nskip the whole message creation step.", "code_diff": "@@ -405,6 +405,9 @@ static int synthetic_reply_return_strv(sd_bus_message *call, char **l) {\n \n         assert(call);\n \n+        if (call->header->flags & BUS_MESSAGE_NO_REPLY_EXPECTED)\n+                return 0;\n+\n         r = sd_bus_message_new_method_return(call, &m);\n         if (r < 0)\n                 return synthetic_reply_method_errno(call, r, NULL);\n", "changed_method_name": "synthetic_reply_return_strv"}
{"commit_url": "https://github.com/systemd/systemd/commit/4b64536ee7fd0438c93d1784824098f826cd642c", "commit_message": "util: optimize free_and_strdup() if NOP\n\nUnder the assumption that strcmp() is cheaper than memory allocation,\nlet's avoid the allocation, if the new value is identical to the old.", "code_diff": "@@ -5682,6 +5682,9 @@ int free_and_strdup(char **p, const char *s) {\n         /* Replaces a string pointer with an strdup()ed new string,\n          * possibly freeing the old one. */\n \n+        if (streq_ptr(*p, s))\n+                return 0;\n+\n         if (s) {\n                 t = strdup(s);\n                 if (!t)\n@@ -5692,7 +5695,7 @@ int free_and_strdup(char **p, const char *s) {\n         free(*p);\n         *p = t;\n \n-        return 0;\n+        return 1;\n }\n \n int sethostname_idempotent(const char *s) {\n", "changed_method_name": "free_and_strdup"}
{"commit_url": "https://github.com/systemd/systemd/commit/a6149b93afeb4e7b37e1313920ac2e0a91ff1c08", "commit_message": "process-util: trivial optimization", "code_diff": "@@ -181,10 +181,10 @@ int is_kernel_thread(pid_t pid) {\n         bool eof;\n         FILE *f;\n \n-        if (pid == 0)\n+        if (pid == 0 || pid == 1) /* pid 1, and we ourselves certainly aren't a kernel thread */\n                 return 0;\n \n-        assert(pid > 0);\n+        assert(pid > 1);\n \n         p = procfs_file_alloca(pid, \"cmdline\");\n         f = fopen(p, \"re\");\n", "changed_method_name": "is_kernel_thread"}
{"commit_url": "https://github.com/systemd/systemd/commit/8372da448f3c738e0154d988538d497f7e2e1f83", "commit_message": "extract-word: Check for early bail out before inspecting separators\n\nIt's a pretty small optimization but doesn't hurt...\n\nTested with test-extract-word.", "code_diff": "@@ -39,13 +39,13 @@ int extract_first_word(const char **p, char **ret, const char *separators, Extra\n         assert(p);\n         assert(ret);\n \n-        if (!separators)\n-                separators = WHITESPACE;\n-\n         /* Bail early if called after last value or with no input */\n         if (!*p)\n                 goto finish_force_terminate;\n \n+        if (!separators)\n+                separators = WHITESPACE;\n+\n         /* Parses the first word of a string, and returns it in\n          * *ret. Removes all quotes in the process. When parsing fails\n          * (because of an uneven number of quotes or similar), leaves\n", "changed_method_name": "extract_first_word"}
{"commit_url": "https://github.com/systemd/systemd/commit/ef9a3e3c28095e52f8ffe96acf3c70b2babfacb5", "commit_message": "resolve: optimize dns_cache_flush() a bit\n\nLet's use dns_cache_remove() rather than\ndns_cache_item_remove_and_free() to destroy the cache, since the former\nrequires far fewer hash table lookups.", "code_diff": "@@ -85,21 +85,6 @@ static void dns_cache_item_remove_and_free(DnsCache *c, DnsCacheItem *i) {\n         dns_cache_item_free(i);\n }\n \n-void dns_cache_flush(DnsCache *c) {\n-        DnsCacheItem *i;\n-\n-        assert(c);\n-\n-        while ((i = hashmap_first(c->by_key)))\n-                dns_cache_item_remove_and_free(c, i);\n-\n-        assert(hashmap_size(c->by_key) == 0);\n-        assert(prioq_size(c->by_expiry) == 0);\n-\n-        c->by_key = hashmap_free(c->by_key);\n-        c->by_expiry = prioq_free(c->by_expiry);\n-}\n-\n static bool dns_cache_remove_by_rr(DnsCache *c, DnsResourceRecord *rr) {\n         DnsCacheItem *first, *i;\n         int r;\n@@ -136,6 +121,21 @@ static bool dns_cache_remove(DnsCache *c, DnsResourceKey *key) {\n         return true;\n }\n \n+void dns_cache_flush(DnsCache *c) {\n+        DnsResourceKey *key;\n+\n+        assert(c);\n+\n+        while ((key = hashmap_first_key(c->by_key)))\n+                dns_cache_remove(c, key);\n+\n+        assert(hashmap_size(c->by_key) == 0);\n+        assert(prioq_size(c->by_expiry) == 0);\n+\n+        c->by_key = hashmap_free(c->by_key);\n+        c->by_expiry = prioq_free(c->by_expiry);\n+}\n+\n static void dns_cache_make_space(DnsCache *c, unsigned add) {\n         assert(c);\n \n", "changed_method_name": "dns_cache_flush"}
{"commit_url": "https://github.com/systemd/systemd/commit/fdb90ac6a6f3320a33104951e0c8505df901cc4f", "commit_message": "networkd: optimize link_node_enumerator() a bit\n\nstrv_consume() is pretty expensive when invoked piecemeal, hence optimize it a bit by pre-allocating a properly sized\narray.", "code_diff": "@@ -59,15 +59,19 @@ static char *link_bus_path(Link *link) {\n int link_node_enumerator(sd_bus *bus, const char *path, void *userdata, char ***nodes, sd_bus_error *error) {\n         _cleanup_strv_free_ char **l = NULL;\n         Manager *m = userdata;\n+        unsigned c = 0;\n         Link *link;\n         Iterator i;\n-        int r;\n \n         assert(bus);\n         assert(path);\n         assert(m);\n         assert(nodes);\n \n+        l = new0(char*, hashmap_size(m->links) + 1);\n+        if (!l)\n+                return -ENOMEM;\n+\n         HASHMAP_FOREACH(link, m->links, i) {\n                 char *p;\n \n@@ -75,11 +79,10 @@ int link_node_enumerator(sd_bus *bus, const char *path, void *userdata, char ***\n                 if (!p)\n                         return -ENOMEM;\n \n-                r = strv_consume(&l, p);\n-                if (r < 0)\n-                        return r;\n+                l[c++] = p;\n         }\n \n+        l[c] = NULL;\n         *nodes = l;\n         l = NULL;\n \n", "changed_method_name": "link_node_enumerator"}
{"commit_url": "https://github.com/systemd/systemd/commit/ed71f95662af903f0c5eba32c439e77c5cec4e7b", "commit_message": "sd-journal: minor optimization\n\nNo need to store the object and offset data if we don't actually need it ever.", "code_diff": "@@ -2520,24 +2520,20 @@ _public_ int sd_journal_enumerate_unique(sd_journal *j, const void **data, size_\n                  * traversed files. */\n                 found = false;\n                 ORDERED_HASHMAP_FOREACH(of, j->files, i) {\n-                        Object *oo;\n-                        uint64_t op;\n-\n                         if (of == j->unique_file)\n                                 break;\n \n-                        /* Skip this file it didn't have any fields\n-                         * indexed */\n-                        if (JOURNAL_HEADER_CONTAINS(of->header, n_fields) &&\n-                            le64toh(of->header->n_fields) <= 0)\n+                        /* Skip this file it didn't have any fields indexed */\n+                        if (JOURNAL_HEADER_CONTAINS(of->header, n_fields) && le64toh(of->header->n_fields) <= 0)\n                                 continue;\n \n-                        r = journal_file_find_data_object_with_hash(of, odata, ol, le64toh(o->data.hash), &oo, &op);\n+                        r = journal_file_find_data_object_with_hash(of, odata, ol, le64toh(o->data.hash), NULL, NULL);\n                         if (r < 0)\n                                 return r;\n-\n-                        if (r > 0)\n+                        if (r > 0) {\n                                 found = true;\n+                                break;\n+                        }\n                 }\n \n                 if (found)\n", "changed_method_name": "sd_journal_enumerate_unique"}
{"commit_url": "https://github.com/systemd/systemd/commit/00a8cf7763ec5e132efd4c974fbc6530c82240d0", "commit_message": "basic/copy: use sendfile smarter\n\nWe called sendfile with 16kb (a.k.a. COPY_BUFFER_SIZE) as the maximum\nnumber of bytes to copy. This seems rather inefficient, especially with\nlarge files. Instead, call sendfile with a \"large\" maximum.\n\nWhat \"large\" max means is a bit tricky: current file offset + max\nmust fit in loff_t. This means that as we call sendfile more than once,\nwe have to lower the max size.\n\nWith this patch, test-copy calls sendfile twice, e.g.:\nsendfile(4, 3, NULL, 9223372036854775807) = 738760\nsendfile(4, 3, NULL, 9223372036854037047) = 0\nThe second call is necessary to determine EOF.", "code_diff": "@@ -46,11 +46,12 @@\n #include \"umask-util.h\"\n #include \"xattr-util.h\"\n \n-#define COPY_BUFFER_SIZE (16*1024)\n+#define COPY_BUFFER_SIZE (16*1024u)\n \n int copy_bytes(int fdf, int fdt, uint64_t max_bytes, bool try_reflink) {\n         bool try_sendfile = true, try_splice = true;\n         int r;\n+        size_t m = SSIZE_MAX; /* that the maximum that sendfile accepts */\n \n         assert(fdf >= 0);\n         assert(fdt >= 0);\n@@ -67,11 +68,9 @@ int copy_bytes(int fdf, int fdt, uint64_t max_bytes, bool try_reflink) {\n         }\n \n         for (;;) {\n-                size_t m = COPY_BUFFER_SIZE;\n                 ssize_t n;\n \n                 if (max_bytes != (uint64_t) -1) {\n-\n                         if (max_bytes <= 0)\n                                 return 1; /* return > 0 if we hit the max_bytes limit */\n \n@@ -81,42 +80,41 @@ int copy_bytes(int fdf, int fdt, uint64_t max_bytes, bool try_reflink) {\n \n                 /* First try sendfile(), unless we already tried */\n                 if (try_sendfile) {\n-\n                         n = sendfile(fdt, fdf, NULL, m);\n                         if (n < 0) {\n-                                if (errno != EINVAL && errno != ENOSYS)\n+                                if (!IN_SET(errno, EINVAL, ENOSYS))\n                                         return -errno;\n \n                                 try_sendfile = false;\n                                 /* use fallback below */\n                         } else if (n == 0) /* EOF */\n                                 break;\n-                        else if (n > 0)\n+                        else\n                                 /* Success! */\n                                 goto next;\n                 }\n \n-                /* The try splice, unless we already tried */\n+                /* Then try splice, unless we already tried */\n                 if (try_splice) {\n                         n = splice(fdf, NULL, fdt, NULL, m, 0);\n                         if (n < 0) {\n-                                if (errno != EINVAL && errno != ENOSYS)\n+                                if (!IN_SET(errno, EINVAL, ENOSYS))\n                                         return -errno;\n \n                                 try_splice = false;\n                                 /* use fallback below */\n                         } else if (n == 0) /* EOF */\n                                 break;\n-                        else if (n > 0)\n+                        else\n                                 /* Success! */\n                                 goto next;\n                 }\n \n                 /* As a fallback just copy bits by hand */\n                 {\n-                        uint8_t buf[m];\n+                        uint8_t buf[MIN(m, COPY_BUFFER_SIZE)];\n \n-                        n = read(fdf, buf, m);\n+                        n = read(fdf, buf, sizeof buf);\n                         if (n < 0)\n                                 return -errno;\n                         if (n == 0) /* EOF */\n@@ -132,6 +130,11 @@ int copy_bytes(int fdf, int fdt, uint64_t max_bytes, bool try_reflink) {\n                         assert(max_bytes >= (uint64_t) n);\n                         max_bytes -= n;\n                 }\n+                /* sendfile accepts at most SSIZE_MAX-offset bytes to copy,\n+                 * so reduce our maximum by the amount we already copied,\n+                 * but don't go below our copy buffer size, unless we are\n+                 * close the the limit of bytes we are allowed to copy. */\n+                m = MAX(MIN(COPY_BUFFER_SIZE, max_bytes), m - n);\n         }\n \n         return 0; /* return 0 if we hit EOF earlier than the size limit */\n", "changed_method_name": "copy_bytes"}
{"commit_url": "https://github.com/systemd/systemd/commit/815b09d39b74a9ece31b7d7ef45f8f00784b8d8b", "commit_message": "core: optimize unit_write_drop_in a bit\n\nThere's no point in first determining the drop-in file name path, then\nforgetting it again, and then determining it again. Instead, just generated it\nonce, and then write to ti directly.", "code_diff": "@@ -3379,17 +3379,19 @@ int unit_write_drop_in(Unit *u, UnitSetPropertiesMode mode, const char *name, co\n         prefixed = strjoina(\"# This is a drop-in unit file extension, created via \\\"systemctl set-property\\\" or an equivalent operation. Do not edit.\\n\",\n                             data);\n \n-        r = write_drop_in(dir, u->id, 50, name, prefixed);\n+        r = drop_in_file(dir, u->id, 50, name, &p, &q);\n         if (r < 0)\n                 return r;\n \n-        r = drop_in_file(dir, u->id, 50, name, &p, &q);\n+        (void) mkdir_p(p, 0755);\n+        r = write_string_file_atomic_label(q, prefixed);\n         if (r < 0)\n                 return r;\n \n-        r = strv_extend(&u->dropin_paths, q);\n+        r = strv_push(&u->dropin_paths, q);\n         if (r < 0)\n                 return r;\n+        q = NULL;\n \n         strv_uniq(u->dropin_paths);\n \n", "changed_method_name": "unit_write_drop_in"}
{"commit_url": "https://github.com/systemd/systemd/commit/ae5b39588734aacef5b6b411cf2053fdcef4764a", "commit_message": "basic/terminal-util: cache value for colors_enabled\n\nAfter all it's something that we query over and over.\nFor example, systemctl calls colors_enabled() four times for each failing\nservice. The compiler is unable to optimize those calls away because they\n(potentially) accesses external and global state through on_tty() and\ngetenv().", "code_diff": "@@ -1135,14 +1135,19 @@ int open_terminal_in_namespace(pid_t pid, const char *name, int mode) {\n }\n \n bool colors_enabled(void) {\n-        const char *colors;\n+        static int enabled = -1;\n \n-        colors = getenv(\"SYSTEMD_COLORS\");\n-        if (!colors) {\n-                if (streq_ptr(getenv(\"TERM\"), \"dumb\"))\n-                        return false;\n-                return on_tty();\n+        if (_unlikely_(enabled < 0)) {\n+                const char *colors;\n+\n+                colors = getenv(\"SYSTEMD_COLORS\");\n+                if (colors)\n+                        enabled = parse_boolean(colors) != 0;\n+                else if (streq_ptr(getenv(\"TERM\"), \"dumb\"))\n+                        enabled = false;\n+                else\n+                        enabled = on_tty();\n         }\n \n-        return parse_boolean(colors) != 0;\n+        return enabled;\n }\n", "changed_method_name": "colors_enabled"}
{"commit_url": "https://github.com/systemd/systemd/commit/8f1e0ad415dab8f3e5d301129fe2bb25c420e66f", "commit_message": "path-lookup: optimize a common strv copy operation away\n\nFollow-up for:\n\nhttps://github.com/systemd/systemd/pull/3033#discussion_r59689398", "code_diff": "@@ -586,9 +586,16 @@ int lookup_paths_init(\n                 if (!add)\n                         return -ENOMEM;\n \n-                r = strv_extend_strv(&paths, add, true);\n-                if (r < 0)\n+                if (paths) {\n+                        r = strv_extend_strv(&paths, add, true);\n+                        if (r < 0)\n                                 return r;\n+                } else {\n+                        /* Small optimization: if paths is NULL (and it usually is), we can simply assign 'add' to it,\n+                         * and don't have to copy anything */\n+                        paths = add;\n+                        add = NULL;\n+                }\n         }\n \n         r = patch_root_prefix(&persistent_config, root);\n", "changed_method_name": "lookup_paths_init"}
{"commit_url": "https://github.com/systemd/systemd/commit/454f0f8680ebbded135e8575b4d9615b427fdf76", "commit_message": "hashmap: optimize set_put_strdup() a bit\n\nHashing should be quicker than allocating, hence let's first check if the\nstring already exists and only then allocate a new copy for it.", "code_diff": "@@ -1773,20 +1773,18 @@ int set_consume(Set *s, void *value) {\n \n int set_put_strdup(Set *s, const char *p) {\n         char *c;\n-        int r;\n \n         assert(s);\n         assert(p);\n \n+        if (set_contains(s, (char*) p))\n+                return 0;\n+\n         c = strdup(p);\n         if (!c)\n                 return -ENOMEM;\n \n-        r = set_consume(s, c);\n-        if (r == -EEXIST)\n-                return 0;\n-\n-        return r;\n+        return set_consume(s, c);\n }\n \n int set_put_strdupv(Set *s, char **l) {\n", "changed_method_name": "set_put_strdup"}
{"commit_url": "https://github.com/systemd/systemd/commit/fc9ae7178e1462377b272a14b1a763d480ab0980", "commit_message": "cgroup-util: check unified_cache before invoking streq()\n\nJust a minor optimization.", "code_diff": "@@ -2340,10 +2340,13 @@ bool cg_unified(const char *controller) {\n \n         assert(cg_update_unified() >= 0);\n \n-        if (streq_ptr(controller, SYSTEMD_CGROUP_CONTROLLER))\n-                return unified_cache >= CGROUP_UNIFIED_SYSTEMD;\n-        else\n-                return unified_cache >= CGROUP_UNIFIED_ALL;\n+        if (unified_cache == CGROUP_UNIFIED_NONE)\n+                return false;\n+\n+        if (unified_cache >= CGROUP_UNIFIED_ALL)\n+                return true;\n+\n+        return streq_ptr(controller, SYSTEMD_CGROUP_CONTROLLER);\n }\n \n bool cg_all_unified(void) {\n", "changed_method_name": "cg_unified"}
{"commit_url": "https://github.com/systemd/systemd/commit/496ae8c84b2d3622bc767a727e3582e2b6bcffcd", "commit_message": "resolved: Recover from slow DNS responses\n\nWhen DNS is unreliable temporarily, the current implementation will\nnever improve resend behavior again and switch DNS servers only late\n(current maximum timeout is 5 seconds).\n\nWe can improve this by biasing the resend_timeout back to the current\nRTT when a successful response was received. Next time, a timeout is hit\non this server, it will switch to the next server faster.\n\nFixes: #5953", "code_diff": "@@ -304,7 +304,10 @@ void dns_server_packet_received(DnsServer *s, int protocol, DnsServerFeatureLeve\n         if (s->max_rtt < rtt) {\n                 s->max_rtt = rtt;\n                 s->resend_timeout = CLAMP(s->max_rtt * 2, DNS_TIMEOUT_MIN_USEC, DNS_TIMEOUT_MAX_USEC);\n-        }\n+        } else if (s->resend_timeout > rtt)\n+                /* If we received the packet faster than the resend_timeout, bias\n+                 * the resend_timeout back to the rtt. */\n+                s->resend_timeout = CLAMP((2 * s->resend_timeout + rtt) / 3, DNS_TIMEOUT_MIN_USEC, DNS_TIMEOUT_MAX_USEC);\n }\n \n void dns_server_packet_lost(DnsServer *s, int protocol, DnsServerFeatureLevel level, usec_t usec) {\n", "changed_method_name": "dns_server_packet_received"}
{"commit_url": "https://github.com/systemd/systemd/commit/47b33c7d5284492e5679ccfabafe8c9738de8cb3", "commit_message": "string-util: optimize strshorten() a bit\n\nThere's no reason to determine the full length of the string, it's\nsufficient to know whether it is larger than the intended size...", "code_diff": "@@ -558,7 +558,7 @@ bool nulstr_contains(const char *nulstr, const char *needle) {\n char* strshorten(char *s, size_t l) {\n         assert(s);\n \n-        if (l < strlen(s))\n+        if (strnlen(s, l+1) > l)\n                 s[l] = 0;\n \n         return s;\n", "changed_method_name": "strshorten"}
{"commit_url": "https://github.com/systemd/systemd/commit/ff0e7e05c9904b4120868e96216b123c1b798aa4", "commit_message": "fileio: try to read one byte too much in read_full_stream()\n\nLet's read one byte more than the file size we read from stat() on the\nfirst fread() invocation. That way, the first read() will already be\nshort and indicate eof to fread().\n\nThis is a minor optimization, and replaces #3908.", "code_diff": "@@ -270,11 +270,11 @@ int read_full_stream(FILE *f, char **contents, size_t *size) {\n                 if (st.st_size > READ_FULL_BYTES_MAX)\n                         return -E2BIG;\n \n-                /* Start with the right file size, but be prepared for\n-                 * files from /proc which generally report a file size\n-                 * of 0 */\n+                /* Start with the right file size, but be prepared for files from /proc which generally report a file\n+                 * size of 0. Note that we increase the size to read here by one, so that the first read attempt\n+                 * already makes us notice the EOF. */\n                 if (st.st_size > 0)\n-                        n = st.st_size;\n+                        n = st.st_size + 1;\n         }\n \n         l = 0;\n", "changed_method_name": "read_full_stream"}
{"commit_url": "https://github.com/systemd/systemd/commit/bf516294c89d8db9769d90b4f90c177adafa038c", "commit_message": "nspawn: minor optimization\n\nno need to prepare the target path if we quite the loop anyway one step\nlater.", "code_diff": "@@ -1038,13 +1038,13 @@ static int mount_legacy_cgns_supported(\n                         if (r == 0)\n                                 break;\n \n-                        target = prefix_root(\"/sys/fs/cgroup\", tok);\n-                        if (!target)\n-                                return log_oom();\n-\n                         if (streq(controller, tok))\n                                 break;\n \n+                        target = prefix_root(\"/sys/fs/cgroup/\", tok);\n+                        if (!target)\n+                                return log_oom();\n+\n                         r = symlink_idempotent(controller, target);\n                         if (r == -EINVAL)\n                                 return log_error_errno(r, \"Invalid existing symlink for combined hierarchy: %m\");\n", "changed_method_name": "mount_legacy_cgns_supported"}
{"commit_url": "https://github.com/systemd/systemd/commit/77fa610b22f343671945501905e8079d68807ddb", "commit_message": "cgroup-util: optimization \u2014 open subtree_control file only once for all controllers", "code_diff": "@@ -2541,6 +2541,7 @@ int cg_unified_flush(void) {\n }\n \n int cg_enable_everywhere(CGroupMask supported, CGroupMask mask, const char *p) {\n+        _cleanup_fclose_ FILE *f = NULL;\n         _cleanup_free_ char *fs = NULL;\n         CGroupController c;\n         int r;\n@@ -2574,7 +2575,15 @@ int cg_enable_everywhere(CGroupMask supported, CGroupMask mask, const char *p) {\n                         s[0] = mask & bit ? '+' : '-';\n                         strcpy(s + 1, n);\n \n-                        r = write_string_file(fs, s, 0);\n+                        if (!f) {\n+                                f = fopen(fs, \"we\");\n+                                if (!f) {\n+                                        log_debug_errno(errno, \"Failed to open cgroup.subtree_control file of %s: %m\", p);\n+                                        break;\n+                                }\n+                        }\n+\n+                        r = write_string_stream(f, s, 0);\n                         if (r < 0)\n                                 log_debug_errno(r, \"Failed to enable controller %s for %s (%s): %m\", n, p, fs);\n                 }\n", "changed_method_name": "cg_enable_everywhere"}
{"commit_url": "https://github.com/systemd/systemd/commit/4dc63c4bc7850bc570fcf33800a444e09dec81d5", "commit_message": "main: minor optimization\n\nLet's remove one memory allocation in the common path.", "code_diff": "@@ -1413,6 +1413,7 @@ static int bump_unix_max_dgram_qlen(void) {\n \n static int fixup_environment(void) {\n         _cleanup_free_ char *term = NULL;\n+        const char *t;\n         int r;\n \n         /* We expect the environment to be set correctly\n@@ -1432,13 +1433,10 @@ static int fixup_environment(void) {\n         r = proc_cmdline_get_key(\"TERM\", 0, &term);\n         if (r < 0)\n                 return r;\n-        if (r == 0) {\n-                term = strdup(default_term_for_tty(\"/dev/console\"));\n-                if (!term)\n-                        return -ENOMEM;\n-        }\n \n-        if (setenv(\"TERM\", term, 1) < 0)\n+        t = term ?: default_term_for_tty(\"/dev/console\");\n+\n+        if (setenv(\"TERM\", t, 1) < 0)\n                 return -errno;\n \n         return 0;\n", "changed_method_name": "fixup_environment"}
{"commit_url": "https://github.com/systemd/systemd/commit/244d2f07b49e3470d679fdd0f6ebd24fac8d5dc7", "commit_message": "fs-util: add shortcut for chase_symlinks() when it is called like open(O_PATH)\n\nLet's optimize things, and let the kernel chase the paths if none of the\nfeatures chase_symlinks() offers are actually used.", "code_diff": "@@ -634,6 +634,16 @@ int chase_symlinks(const char *path, const char *original_root, unsigned flags,\n         if (noop_root(original_root))\n                 original_root = NULL;\n \n+        if (!original_root && !ret && (flags & (CHASE_NONEXISTENT|CHASE_NO_AUTOFS|CHASE_SAFE|CHASE_OPEN)) == CHASE_OPEN) {\n+                /* Shortcut the CHASE_OPEN case if the caller isn't interested in the actual path and has no root set\n+                 * and doesn't care about any of the other special features we provide either. */\n+                r = open(path, O_PATH|O_CLOEXEC);\n+                if (r < 0)\n+                        return -errno;\n+\n+                return r;\n+        }\n+\n         if (original_root) {\n                 r = path_make_absolute_cwd(original_root, &root);\n                 if (r < 0)\n", "changed_method_name": "chase_symlinks"}
{"commit_url": "https://github.com/systemd/systemd/commit/6dbef3053dcb11a58ead99bee0790ad1f4c40522", "commit_message": "fuzz-journal-remote: write to /dev/null not stdout\n\nThis makes the fuzzing much more efficient. Optionally provide output is\n$SYSTEMD_FUZZ_OUTPUT is set, which makes debugging of any failures much easier.\n\nThe case from 056129deb73df17ece4212db39d2ca0842d9a49c is still detected properly.", "code_diff": "@@ -6,6 +6,7 @@\n \n #include \"sd-journal.h\"\n \n+#include \"env-util.h\"\n #include \"fd-util.h\"\n #include \"fileio.h\"\n #include \"fs-util.h\"\n@@ -15,6 +16,7 @@\n #include \"strv.h\"\n \n int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n+        _cleanup_fclose_ FILE *dev_null = NULL;\n         RemoteServer s = {};\n         char name[] = \"/tmp/fuzz-journal-remote.XXXXXX.journal\";\n         void *mem;\n@@ -53,8 +55,13 @@ int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n         r = sd_journal_open_files(&j, (const char**) STRV_MAKE(name), 0);\n         assert_se(r >= 0);\n \n+        if (getenv_bool(\"SYSTEMD_FUZZ_OUTPUT\") <= 0)\n+                assert_se(dev_null = fopen(\"/dev/null\", \"we\"));\n+\n         for (mode = 0; mode < _OUTPUT_MODE_MAX; mode++) {\n-                r = show_journal(stdout, j, mode, 0, 0, -1, 0, NULL);\n+                if (!dev_null)\n+                        log_info(\"/* %s */\", output_mode_to_string(mode));\n+                r = show_journal(dev_null ?: stdout, j, mode, 0, 0, -1, 0, NULL);\n                 assert_se(r >= 0);\n \n                 r = sd_journal_seek_head(j);\n", "changed_method_name": "LLVMFuzzerTestOneInput"}
{"commit_url": "https://github.com/systemd/systemd/commit/3c72b6ed4252e7ff5f7704bfe44557ec197b47fa", "commit_message": "sd-dhcp6: make dhcp6_option_parse_domainname() not store empty domain\n\nThis improves performance of fuzzer.\nC.f. oss-fuzz#11019.", "code_diff": "@@ -553,6 +553,7 @@ int dhcp6_option_parse_domainname(const uint8_t *optval, uint16_t optlen, char *\n                 bool first = true;\n \n                 for (;;) {\n+                        const char *label;\n                         uint8_t c;\n \n                         c = optval[pos++];\n@@ -560,47 +561,41 @@ int dhcp6_option_parse_domainname(const uint8_t *optval, uint16_t optlen, char *\n                         if (c == 0)\n                                 /* End of name */\n                                 break;\n-                        else if (c <= 63) {\n-                                const char *label;\n-\n-                                /* Literal label */\n-                                label = (const char *)&optval[pos];\n-                                pos += c;\n-                                if (pos >= optlen)\n-                                        return -EMSGSIZE;\n-\n-                                if (!GREEDY_REALLOC(ret, allocated, n + !first + DNS_LABEL_ESCAPED_MAX)) {\n-                                        r = -ENOMEM;\n-                                        goto fail;\n-                                }\n-\n-                                if (first)\n-                                        first = false;\n-                                else\n-                                        ret[n++] = '.';\n-\n-                                r = dns_label_escape(label, c, ret + n, DNS_LABEL_ESCAPED_MAX);\n-                                if (r < 0)\n-                                        goto fail;\n-\n-                                n += r;\n-                                continue;\n-                        } else {\n-                                r = -EBADMSG;\n-                                goto fail;\n-                        }\n-                }\n+                        if (c > 63)\n+                                return -EBADMSG;\n+\n+                        /* Literal label */\n+                        label = (const char *)&optval[pos];\n+                        pos += c;\n+                        if (pos >= optlen)\n+                                return -EMSGSIZE;\n+\n+                        if (!GREEDY_REALLOC(ret, allocated, n + !first + DNS_LABEL_ESCAPED_MAX))\n+                                return -ENOMEM;\n+\n+                        if (first)\n+                                first = false;\n+                        else\n+                                ret[n++] = '.';\n+\n+                        r = dns_label_escape(label, c, ret + n, DNS_LABEL_ESCAPED_MAX);\n+                        if (r < 0)\n+                                return r;\n \n-                if (!GREEDY_REALLOC(ret, allocated, n + 1)) {\n-                        r = -ENOMEM;\n-                        goto fail;\n+                        n += r;\n                 }\n \n+                if (n == 0)\n+                        continue;\n+\n+                if (!GREEDY_REALLOC(ret, allocated, n + 1))\n+                        return -ENOMEM;\n+\n                 ret[n] = 0;\n \n                 r = strv_extend(&names, ret);\n                 if (r < 0)\n-                        goto fail;\n+                        return r;\n \n                 idx++;\n         }\n@@ -608,7 +603,4 @@ int dhcp6_option_parse_domainname(const uint8_t *optval, uint16_t optlen, char *\n         *str_arr = TAKE_PTR(names);\n \n         return idx;\n-\n-fail:\n-        return r;\n }\n", "changed_method_name": "dhcp6_option_parse_domainname"}
{"commit_url": "https://github.com/systemd/systemd/commit/8e060ec225b74bbf22e5bdbacd604efcc73294c0", "commit_message": "fs-util: increase start buffer size in readlinkat_malloc()\n\nI noticed while profiling journald that we invoke readlinkat() a ton on\nopen /proc/self/fd/<fd>, and that the returned paths are more often than\nnot longer than the 99 chars used before, when we look at archived\njournal files. This means for these cases we generally need to execute\ntwo rather than one syscalls.\n\nLet's increase the buffer size a tiny bit, so that we reduce the number\nof syscalls executed. This is really a low-hanging fruit of\noptimization.", "code_diff": "@@ -132,7 +132,7 @@ int rename_noreplace(int olddirfd, const char *oldpath, int newdirfd, const char\n }\n \n int readlinkat_malloc(int fd, const char *p, char **ret) {\n-        size_t l = 100;\n+        size_t l = FILENAME_MAX+1;\n         int r;\n \n         assert(p);\n", "changed_method_name": "readlinkat_malloc"}
{"commit_url": "https://github.com/gpg/libgcrypt/commit/ec2f8de409a93c80efa658134df22074a9bca5a4", "commit_message": "Optimize _gcry_burn_stack for 32-bit and 64-bit architectures\n\n* src/misc.c (_gcry_burn_stack): Add optimization for 32-bit and 64-bit\narchitectures.\n--\n\nBusy looping 'tests/benchmark --cipher-repetitions 10 cipher blowfish' on ARM\nCortex-A8 shows that _gcry_burn_stack takes 21% of CPU time. With this patch,\nthat number drops to 3.4%.\n\nOn AMD64 (Intel i5-4570) CPU usage for _gcry_burn_stack in the same test drops\nfrom 3.5% to 1.1%.\n\nSigned-off-by: Jussi Kivilinna <jussi.kivilinna@iki.fi>", "code_diff": "@@ -290,9 +290,35 @@ _gcry_log_printhex (const char *text, const void *buffer, size_t length)\n void\n _gcry_burn_stack (int bytes)\n {\n+#if SIZEOF_UNSIGNED_LONG == 4 || SIZEOF_UNSIGNED_LONG == 8\n+    /* Optimized burn_stack for 32-bit and 64-bit architectures.  In addition\n+       to loop unrolling, compiler sees that writes are within 'buf' and\n+       generation of stack-protection code is avoided.  */\n+    volatile unsigned long buf[64 / SIZEOF_UNSIGNED_LONG];\n+\n+    buf[0] = 0;\n+    buf[1] = 0;\n+    buf[2] = 0;\n+    buf[3] = 0;\n+    buf[4] = 0;\n+    buf[5] = 0;\n+    buf[6] = 0;\n+    buf[7] = 0;\n+# if SIZEOF_UNSIGNED_LONG == 4\n+    buf[8] = 0;\n+    buf[9] = 0;\n+    buf[10] = 0;\n+    buf[11] = 0;\n+    buf[12] = 0;\n+    buf[13] = 0;\n+    buf[14] = 0;\n+    buf[15] = 0;\n+# endif\n+#else\n     char buf[64];\n \n     wipememory (buf, sizeof buf);\n+#endif\n     bytes -= sizeof buf;\n     if (bytes > 0)\n         _gcry_burn_stack (bytes);\n", "changed_method_name": "_gcry_burn_stack"}
{"commit_url": "https://github.com/gpg/libgcrypt/commit/04cda6b7cc16f3f52c12d9d3e46c56701003496e", "commit_message": "PBKDF2: Use gcry_md_reset to speed up calculation.\n\n* cipher/kdf.c (_gcry_kdf_pkdf2): Use gcry_md_reset\nto speed up calculation.\n--\n\nCurrent PBKDF2 implementation uses gcry_md_set_key in every iteration\nwhich is extremely slow (even in comparison with other implementations).\n\nUse gcry_md_reset instead and set key only once.\n\nWith this test program:\n\n  char input[32000], salt[8], key[16];\n  gcry_kdf_derive(input, sizeof(input), GCRY_KDF_PBKDF2,\n                  gcry_md_map_name(\"sha1\"),\n                  salt, sizeof(salt), 100000, sizeof(key), key);\n\nrunning time without patch:\n  real    0m11.165s\n  user    0m11.136s\n  sys     0m0.000s\n\nand with patch applied\n  real    0m0.230s\n  user    0m0.184s\n  sys     0m0.024s\n\n(The problem was found when cryptsetup started to use gcrypt internal PBKDF2\nand for very long keyfiles unlocking time increased drastically.\nSee https://bugzilla.redhat.com/show_bug.cgi?id=1051733)\n\nSigned-off-by: Milan Broz <gmazyland@gmail.com>", "code_diff": "@@ -175,19 +175,21 @@ _gcry_kdf_pkdf2 (const void *passphrase, size_t passphraselen,\n       return ec;\n     }\n \n+  ec = _gcry_md_setkey (md, passphrase, passphraselen);\n+  if (ec)\n+    {\n+      _gcry_md_close (md);\n+      xfree (sbuf);\n+      return ec;\n+    }\n+\n   /* Step 3 and 4. */\n   memcpy (sbuf, salt, saltlen);\n   for (lidx = 1; lidx <= l; lidx++)\n     {\n       for (iter = 0; iter < iterations; iter++)\n         {\n-          ec = _gcry_md_setkey (md, passphrase, passphraselen);\n-          if (ec)\n-            {\n-              _gcry_md_close (md);\n-              xfree (sbuf);\n-              return ec;\n-            }\n+          _gcry_md_reset (md);\n           if (!iter) /* Compute U_1:  */\n             {\n               sbuf[saltlen]     = (lidx >> 24);\n", "changed_method_name": "_gcry_kdf_pkdf2"}
{"commit_url": "https://github.com/gpg/libgcrypt/commit/30bd759f398f45b04d0a783b875f59ce9bd1e51d", "commit_message": "Improved ripemd160 performance\n\n* cipher/rmd160.c (transform): Interleave the left and right lane\nrounds to introduce more instruction level parallelism.\n--\n\nThe benchmarks on different systems:\n\nIntel(R) Atom(TM) CPU N570   @ 1.66GHz\nbefore:\nHash:\n                |  nanosecs/byte   mebibytes/sec   cycles/byte\n RIPEMD160      |     13.07 ns/B     72.97 MiB/s         - c/B\nafter:\nHash:\n                |  nanosecs/byte   mebibytes/sec   cycles/byte\n RIPEMD160      |     11.37 ns/B     83.84 MiB/s         - c/B\n\nIntel(R) Core(TM) i5-4670 CPU @ 3.40GHz\nbefore:\nHash:\n                |  nanosecs/byte   mebibytes/sec   cycles/byte\n RIPEMD160      |      3.31 ns/B     288.0 MiB/s         - c/B\nafter:\nHash:\n                |  nanosecs/byte   mebibytes/sec   cycles/byte\n RIPEMD160      |      2.08 ns/B     458.5 MiB/s         - c/B\n\nSigned-off-by: Andrei Scherer <andsch@inbox.com>", "code_diff": "@@ -178,8 +178,7 @@ static unsigned int\n transform_blk ( void *ctx, const unsigned char *data )\n {\n   RMD160_CONTEXT *hd = ctx;\n-  register u32 a,b,c,d,e;\n-  u32 aa,bb,cc,dd,ee,t;\n+  register u32 al, ar, bl, br, cl, cr, dl, dr, el, er;\n   u32 x[16];\n   int i;\n \n@@ -201,196 +200,186 @@ transform_blk ( void *ctx, const unsigned char *data )\n #define F2(x,y,z)   ( ((x) | ~(y)) ^ (z) )\n #define F3(x,y,z)   ( ((x) & (z)) | ((y) & ~(z)) )\n #define F4(x,y,z)   ( (x) ^ ((y) | ~(z)) )\n-#define R(a,b,c,d,e,f,k,r,s) do { t = a + f(b,c,d) + k + x[r]; \\\n-\t\t\t\t  a = rol(t,s) + e;\t       \\\n+#define R(a,b,c,d,e,f,k,r,s) do { a += f(b,c,d) + k + x[r]; \\\n+\t\t\t\t  a = rol(a,s) + e;\t       \\\n \t\t\t\t  c = rol(c,10);\t       \\\n \t\t\t\t} while(0)\n \n-  /* left lane */\n-  a = hd->h0;\n-  b = hd->h1;\n-  c = hd->h2;\n-  d = hd->h3;\n-  e = hd->h4;\n-  R( a, b, c, d, e, F0, K0,  0, 11 );\n-  R( e, a, b, c, d, F0, K0,  1, 14 );\n-  R( d, e, a, b, c, F0, K0,  2, 15 );\n-  R( c, d, e, a, b, F0, K0,  3, 12 );\n-  R( b, c, d, e, a, F0, K0,  4,  5 );\n-  R( a, b, c, d, e, F0, K0,  5,  8 );\n-  R( e, a, b, c, d, F0, K0,  6,  7 );\n-  R( d, e, a, b, c, F0, K0,  7,  9 );\n-  R( c, d, e, a, b, F0, K0,  8, 11 );\n-  R( b, c, d, e, a, F0, K0,  9, 13 );\n-  R( a, b, c, d, e, F0, K0, 10, 14 );\n-  R( e, a, b, c, d, F0, K0, 11, 15 );\n-  R( d, e, a, b, c, F0, K0, 12,  6 );\n-  R( c, d, e, a, b, F0, K0, 13,  7 );\n-  R( b, c, d, e, a, F0, K0, 14,  9 );\n-  R( a, b, c, d, e, F0, K0, 15,  8 );\n-  R( e, a, b, c, d, F1, K1,  7,  7 );\n-  R( d, e, a, b, c, F1, K1,  4,  6 );\n-  R( c, d, e, a, b, F1, K1, 13,  8 );\n-  R( b, c, d, e, a, F1, K1,  1, 13 );\n-  R( a, b, c, d, e, F1, K1, 10, 11 );\n-  R( e, a, b, c, d, F1, K1,  6,  9 );\n-  R( d, e, a, b, c, F1, K1, 15,  7 );\n-  R( c, d, e, a, b, F1, K1,  3, 15 );\n-  R( b, c, d, e, a, F1, K1, 12,  7 );\n-  R( a, b, c, d, e, F1, K1,  0, 12 );\n-  R( e, a, b, c, d, F1, K1,  9, 15 );\n-  R( d, e, a, b, c, F1, K1,  5,  9 );\n-  R( c, d, e, a, b, F1, K1,  2, 11 );\n-  R( b, c, d, e, a, F1, K1, 14,  7 );\n-  R( a, b, c, d, e, F1, K1, 11, 13 );\n-  R( e, a, b, c, d, F1, K1,  8, 12 );\n-  R( d, e, a, b, c, F2, K2,  3, 11 );\n-  R( c, d, e, a, b, F2, K2, 10, 13 );\n-  R( b, c, d, e, a, F2, K2, 14,  6 );\n-  R( a, b, c, d, e, F2, K2,  4,  7 );\n-  R( e, a, b, c, d, F2, K2,  9, 14 );\n-  R( d, e, a, b, c, F2, K2, 15,  9 );\n-  R( c, d, e, a, b, F2, K2,  8, 13 );\n-  R( b, c, d, e, a, F2, K2,  1, 15 );\n-  R( a, b, c, d, e, F2, K2,  2, 14 );\n-  R( e, a, b, c, d, F2, K2,  7,  8 );\n-  R( d, e, a, b, c, F2, K2,  0, 13 );\n-  R( c, d, e, a, b, F2, K2,  6,  6 );\n-  R( b, c, d, e, a, F2, K2, 13,  5 );\n-  R( a, b, c, d, e, F2, K2, 11, 12 );\n-  R( e, a, b, c, d, F2, K2,  5,  7 );\n-  R( d, e, a, b, c, F2, K2, 12,  5 );\n-  R( c, d, e, a, b, F3, K3,  1, 11 );\n-  R( b, c, d, e, a, F3, K3,  9, 12 );\n-  R( a, b, c, d, e, F3, K3, 11, 14 );\n-  R( e, a, b, c, d, F3, K3, 10, 15 );\n-  R( d, e, a, b, c, F3, K3,  0, 14 );\n-  R( c, d, e, a, b, F3, K3,  8, 15 );\n-  R( b, c, d, e, a, F3, K3, 12,  9 );\n-  R( a, b, c, d, e, F3, K3,  4,  8 );\n-  R( e, a, b, c, d, F3, K3, 13,  9 );\n-  R( d, e, a, b, c, F3, K3,  3, 14 );\n-  R( c, d, e, a, b, F3, K3,  7,  5 );\n-  R( b, c, d, e, a, F3, K3, 15,  6 );\n-  R( a, b, c, d, e, F3, K3, 14,  8 );\n-  R( e, a, b, c, d, F3, K3,  5,  6 );\n-  R( d, e, a, b, c, F3, K3,  6,  5 );\n-  R( c, d, e, a, b, F3, K3,  2, 12 );\n-  R( b, c, d, e, a, F4, K4,  4,  9 );\n-  R( a, b, c, d, e, F4, K4,  0, 15 );\n-  R( e, a, b, c, d, F4, K4,  5,  5 );\n-  R( d, e, a, b, c, F4, K4,  9, 11 );\n-  R( c, d, e, a, b, F4, K4,  7,  6 );\n-  R( b, c, d, e, a, F4, K4, 12,  8 );\n-  R( a, b, c, d, e, F4, K4,  2, 13 );\n-  R( e, a, b, c, d, F4, K4, 10, 12 );\n-  R( d, e, a, b, c, F4, K4, 14,  5 );\n-  R( c, d, e, a, b, F4, K4,  1, 12 );\n-  R( b, c, d, e, a, F4, K4,  3, 13 );\n-  R( a, b, c, d, e, F4, K4,  8, 14 );\n-  R( e, a, b, c, d, F4, K4, 11, 11 );\n-  R( d, e, a, b, c, F4, K4,  6,  8 );\n-  R( c, d, e, a, b, F4, K4, 15,  5 );\n-  R( b, c, d, e, a, F4, K4, 13,  6 );\n-\n-  aa = a; bb = b; cc = c; dd = d; ee = e;\n-\n-  /* right lane */\n-  a = hd->h0;\n-  b = hd->h1;\n-  c = hd->h2;\n-  d = hd->h3;\n-  e = hd->h4;\n-  R( a, b, c, d, e, F4, KK0,\t5,  8);\n-  R( e, a, b, c, d, F4, KK0, 14,  9);\n-  R( d, e, a, b, c, F4, KK0,\t7,  9);\n-  R( c, d, e, a, b, F4, KK0,\t0, 11);\n-  R( b, c, d, e, a, F4, KK0,\t9, 13);\n-  R( a, b, c, d, e, F4, KK0,\t2, 15);\n-  R( e, a, b, c, d, F4, KK0, 11, 15);\n-  R( d, e, a, b, c, F4, KK0,\t4,  5);\n-  R( c, d, e, a, b, F4, KK0, 13,  7);\n-  R( b, c, d, e, a, F4, KK0,\t6,  7);\n-  R( a, b, c, d, e, F4, KK0, 15,  8);\n-  R( e, a, b, c, d, F4, KK0,\t8, 11);\n-  R( d, e, a, b, c, F4, KK0,\t1, 14);\n-  R( c, d, e, a, b, F4, KK0, 10, 14);\n-  R( b, c, d, e, a, F4, KK0,\t3, 12);\n-  R( a, b, c, d, e, F4, KK0, 12,  6);\n-  R( e, a, b, c, d, F3, KK1,\t6,  9);\n-  R( d, e, a, b, c, F3, KK1, 11, 13);\n-  R( c, d, e, a, b, F3, KK1,\t3, 15);\n-  R( b, c, d, e, a, F3, KK1,\t7,  7);\n-  R( a, b, c, d, e, F3, KK1,\t0, 12);\n-  R( e, a, b, c, d, F3, KK1, 13,  8);\n-  R( d, e, a, b, c, F3, KK1,\t5,  9);\n-  R( c, d, e, a, b, F3, KK1, 10, 11);\n-  R( b, c, d, e, a, F3, KK1, 14,  7);\n-  R( a, b, c, d, e, F3, KK1, 15,  7);\n-  R( e, a, b, c, d, F3, KK1,\t8, 12);\n-  R( d, e, a, b, c, F3, KK1, 12,  7);\n-  R( c, d, e, a, b, F3, KK1,\t4,  6);\n-  R( b, c, d, e, a, F3, KK1,\t9, 15);\n-  R( a, b, c, d, e, F3, KK1,\t1, 13);\n-  R( e, a, b, c, d, F3, KK1,\t2, 11);\n-  R( d, e, a, b, c, F2, KK2, 15,  9);\n-  R( c, d, e, a, b, F2, KK2,\t5,  7);\n-  R( b, c, d, e, a, F2, KK2,\t1, 15);\n-  R( a, b, c, d, e, F2, KK2,\t3, 11);\n-  R( e, a, b, c, d, F2, KK2,\t7,  8);\n-  R( d, e, a, b, c, F2, KK2, 14,  6);\n-  R( c, d, e, a, b, F2, KK2,\t6,  6);\n-  R( b, c, d, e, a, F2, KK2,\t9, 14);\n-  R( a, b, c, d, e, F2, KK2, 11, 12);\n-  R( e, a, b, c, d, F2, KK2,\t8, 13);\n-  R( d, e, a, b, c, F2, KK2, 12,  5);\n-  R( c, d, e, a, b, F2, KK2,\t2, 14);\n-  R( b, c, d, e, a, F2, KK2, 10, 13);\n-  R( a, b, c, d, e, F2, KK2,\t0, 13);\n-  R( e, a, b, c, d, F2, KK2,\t4,  7);\n-  R( d, e, a, b, c, F2, KK2, 13,  5);\n-  R( c, d, e, a, b, F1, KK3,\t8, 15);\n-  R( b, c, d, e, a, F1, KK3,\t6,  5);\n-  R( a, b, c, d, e, F1, KK3,\t4,  8);\n-  R( e, a, b, c, d, F1, KK3,\t1, 11);\n-  R( d, e, a, b, c, F1, KK3,\t3, 14);\n-  R( c, d, e, a, b, F1, KK3, 11, 14);\n-  R( b, c, d, e, a, F1, KK3, 15,  6);\n-  R( a, b, c, d, e, F1, KK3,\t0, 14);\n-  R( e, a, b, c, d, F1, KK3,\t5,  6);\n-  R( d, e, a, b, c, F1, KK3, 12,  9);\n-  R( c, d, e, a, b, F1, KK3,\t2, 12);\n-  R( b, c, d, e, a, F1, KK3, 13,  9);\n-  R( a, b, c, d, e, F1, KK3,\t9, 12);\n-  R( e, a, b, c, d, F1, KK3,\t7,  5);\n-  R( d, e, a, b, c, F1, KK3, 10, 15);\n-  R( c, d, e, a, b, F1, KK3, 14,  8);\n-  R( b, c, d, e, a, F0, KK4, 12,  8);\n-  R( a, b, c, d, e, F0, KK4, 15,  5);\n-  R( e, a, b, c, d, F0, KK4, 10, 12);\n-  R( d, e, a, b, c, F0, KK4,\t4,  9);\n-  R( c, d, e, a, b, F0, KK4,\t1, 12);\n-  R( b, c, d, e, a, F0, KK4,\t5,  5);\n-  R( a, b, c, d, e, F0, KK4,\t8, 14);\n-  R( e, a, b, c, d, F0, KK4,\t7,  6);\n-  R( d, e, a, b, c, F0, KK4,\t6,  8);\n-  R( c, d, e, a, b, F0, KK4,\t2, 13);\n-  R( b, c, d, e, a, F0, KK4, 13,  6);\n-  R( a, b, c, d, e, F0, KK4, 14,  5);\n-  R( e, a, b, c, d, F0, KK4,\t0, 15);\n-  R( d, e, a, b, c, F0, KK4,\t3, 13);\n-  R( c, d, e, a, b, F0, KK4,\t9, 11);\n-  R( b, c, d, e, a, F0, KK4, 11, 11);\n-\n-\n-  t\t   = hd->h1 + d + cc;\n-  hd->h1 = hd->h2 + e + dd;\n-  hd->h2 = hd->h3 + a + ee;\n-  hd->h3 = hd->h4 + b + aa;\n-  hd->h4 = hd->h0 + c + bb;\n-  hd->h0 = t;\n-\n-  return /*burn_stack*/ 108+5*sizeof(void*);\n+  /* left lane and right lanes interleaved */\n+  al = ar = hd->h0;\n+  bl = br = hd->h1;\n+  cl = cr = hd->h2;\n+  dl = dr = hd->h3;\n+  el = er = hd->h4;\n+  R( al, bl, cl, dl, el, F0, K0,  0, 11 );\n+  R( ar, br, cr, dr, er, F4, KK0,\t5,  8);\n+  R( el, al, bl, cl, dl, F0, K0,  1, 14 );\n+  R( er, ar, br, cr, dr, F4, KK0, 14,  9);\n+  R( dl, el, al, bl, cl, F0, K0,  2, 15 );\n+  R( dr, er, ar, br, cr, F4, KK0,\t7,  9);\n+  R( cl, dl, el, al, bl, F0, K0,  3, 12 );\n+  R( cr, dr, er, ar, br, F4, KK0,\t0, 11);\n+  R( bl, cl, dl, el, al, F0, K0,  4,  5 );\n+  R( br, cr, dr, er, ar, F4, KK0,\t9, 13);\n+  R( al, bl, cl, dl, el, F0, K0,  5,  8 );\n+  R( ar, br, cr, dr, er, F4, KK0,\t2, 15);\n+  R( el, al, bl, cl, dl, F0, K0,  6,  7 );\n+  R( er, ar, br, cr, dr, F4, KK0, 11, 15);\n+  R( dl, el, al, bl, cl, F0, K0,  7,  9 );\n+  R( dr, er, ar, br, cr, F4, KK0,\t4,  5);\n+  R( cl, dl, el, al, bl, F0, K0,  8, 11 );\n+  R( cr, dr, er, ar, br, F4, KK0, 13,  7);\n+  R( bl, cl, dl, el, al, F0, K0,  9, 13 );\n+  R( br, cr, dr, er, ar, F4, KK0,\t6,  7);\n+  R( al, bl, cl, dl, el, F0, K0, 10, 14 );\n+  R( ar, br, cr, dr, er, F4, KK0, 15,  8);\n+  R( el, al, bl, cl, dl, F0, K0, 11, 15 );\n+  R( er, ar, br, cr, dr, F4, KK0,\t8, 11);\n+  R( dl, el, al, bl, cl, F0, K0, 12,  6 );\n+  R( dr, er, ar, br, cr, F4, KK0,\t1, 14);\n+  R( cl, dl, el, al, bl, F0, K0, 13,  7 );\n+  R( cr, dr, er, ar, br, F4, KK0, 10, 14);\n+  R( bl, cl, dl, el, al, F0, K0, 14,  9 );\n+  R( br, cr, dr, er, ar, F4, KK0,\t3, 12);\n+  R( al, bl, cl, dl, el, F0, K0, 15,  8 );\n+  R( ar, br, cr, dr, er, F4, KK0, 12,  6);\n+  R( el, al, bl, cl, dl, F1, K1,  7,  7 );\n+  R( er, ar, br, cr, dr, F3, KK1,\t6,  9);\n+  R( dl, el, al, bl, cl, F1, K1,  4,  6 );\n+  R( dr, er, ar, br, cr, F3, KK1, 11, 13);\n+  R( cl, dl, el, al, bl, F1, K1, 13,  8 );\n+  R( cr, dr, er, ar, br, F3, KK1,\t3, 15);\n+  R( bl, cl, dl, el, al, F1, K1,  1, 13 );\n+  R( br, cr, dr, er, ar, F3, KK1,\t7,  7);\n+  R( al, bl, cl, dl, el, F1, K1, 10, 11 );\n+  R( ar, br, cr, dr, er, F3, KK1,\t0, 12);\n+  R( el, al, bl, cl, dl, F1, K1,  6,  9 );\n+  R( er, ar, br, cr, dr, F3, KK1, 13,  8);\n+  R( dl, el, al, bl, cl, F1, K1, 15,  7 );\n+  R( dr, er, ar, br, cr, F3, KK1,\t5,  9);\n+  R( cl, dl, el, al, bl, F1, K1,  3, 15 );\n+  R( cr, dr, er, ar, br, F3, KK1, 10, 11);\n+  R( bl, cl, dl, el, al, F1, K1, 12,  7 );\n+  R( br, cr, dr, er, ar, F3, KK1, 14,  7);\n+  R( al, bl, cl, dl, el, F1, K1,  0, 12 );\n+  R( ar, br, cr, dr, er, F3, KK1, 15,  7);\n+  R( el, al, bl, cl, dl, F1, K1,  9, 15 );\n+  R( er, ar, br, cr, dr, F3, KK1,\t8, 12);\n+  R( dl, el, al, bl, cl, F1, K1,  5,  9 );\n+  R( dr, er, ar, br, cr, F3, KK1, 12,  7);\n+  R( cl, dl, el, al, bl, F1, K1,  2, 11 );\n+  R( cr, dr, er, ar, br, F3, KK1,\t4,  6);\n+  R( bl, cl, dl, el, al, F1, K1, 14,  7 );\n+  R( br, cr, dr, er, ar, F3, KK1,\t9, 15);\n+  R( al, bl, cl, dl, el, F1, K1, 11, 13 );\n+  R( ar, br, cr, dr, er, F3, KK1,\t1, 13);\n+  R( el, al, bl, cl, dl, F1, K1,  8, 12 );\n+  R( er, ar, br, cr, dr, F3, KK1,\t2, 11);\n+  R( dl, el, al, bl, cl, F2, K2,  3, 11 );\n+  R( dr, er, ar, br, cr, F2, KK2, 15,  9);\n+  R( cl, dl, el, al, bl, F2, K2, 10, 13 );\n+  R( cr, dr, er, ar, br, F2, KK2,\t5,  7);\n+  R( bl, cl, dl, el, al, F2, K2, 14,  6 );\n+  R( br, cr, dr, er, ar, F2, KK2,\t1, 15);\n+  R( al, bl, cl, dl, el, F2, K2,  4,  7 );\n+  R( ar, br, cr, dr, er, F2, KK2,\t3, 11);\n+  R( el, al, bl, cl, dl, F2, K2,  9, 14 );\n+  R( er, ar, br, cr, dr, F2, KK2,\t7,  8);\n+  R( dl, el, al, bl, cl, F2, K2, 15,  9 );\n+  R( dr, er, ar, br, cr, F2, KK2, 14,  6);\n+  R( cl, dl, el, al, bl, F2, K2,  8, 13 );\n+  R( cr, dr, er, ar, br, F2, KK2,\t6,  6);\n+  R( bl, cl, dl, el, al, F2, K2,  1, 15 );\n+  R( br, cr, dr, er, ar, F2, KK2,\t9, 14);\n+  R( al, bl, cl, dl, el, F2, K2,  2, 14 );\n+  R( ar, br, cr, dr, er, F2, KK2, 11, 12);\n+  R( el, al, bl, cl, dl, F2, K2,  7,  8 );\n+  R( er, ar, br, cr, dr, F2, KK2,\t8, 13);\n+  R( dl, el, al, bl, cl, F2, K2,  0, 13 );\n+  R( dr, er, ar, br, cr, F2, KK2, 12,  5);\n+  R( cl, dl, el, al, bl, F2, K2,  6,  6 );\n+  R( cr, dr, er, ar, br, F2, KK2,\t2, 14);\n+  R( bl, cl, dl, el, al, F2, K2, 13,  5 );\n+  R( br, cr, dr, er, ar, F2, KK2, 10, 13);\n+  R( al, bl, cl, dl, el, F2, K2, 11, 12 );\n+  R( ar, br, cr, dr, er, F2, KK2,\t0, 13);\n+  R( el, al, bl, cl, dl, F2, K2,  5,  7 );\n+  R( er, ar, br, cr, dr, F2, KK2,\t4,  7);\n+  R( dl, el, al, bl, cl, F2, K2, 12,  5 );\n+  R( dr, er, ar, br, cr, F2, KK2, 13,  5);\n+  R( cl, dl, el, al, bl, F3, K3,  1, 11 );\n+  R( cr, dr, er, ar, br, F1, KK3,\t8, 15);\n+  R( bl, cl, dl, el, al, F3, K3,  9, 12 );\n+  R( br, cr, dr, er, ar, F1, KK3,\t6,  5);\n+  R( al, bl, cl, dl, el, F3, K3, 11, 14 );\n+  R( ar, br, cr, dr, er, F1, KK3,\t4,  8);\n+  R( el, al, bl, cl, dl, F3, K3, 10, 15 );\n+  R( er, ar, br, cr, dr, F1, KK3,\t1, 11);\n+  R( dl, el, al, bl, cl, F3, K3,  0, 14 );\n+  R( dr, er, ar, br, cr, F1, KK3,\t3, 14);\n+  R( cl, dl, el, al, bl, F3, K3,  8, 15 );\n+  R( cr, dr, er, ar, br, F1, KK3, 11, 14);\n+  R( bl, cl, dl, el, al, F3, K3, 12,  9 );\n+  R( br, cr, dr, er, ar, F1, KK3, 15,  6);\n+  R( al, bl, cl, dl, el, F3, K3,  4,  8 );\n+  R( ar, br, cr, dr, er, F1, KK3,\t0, 14);\n+  R( el, al, bl, cl, dl, F3, K3, 13,  9 );\n+  R( er, ar, br, cr, dr, F1, KK3,\t5,  6);\n+  R( dl, el, al, bl, cl, F3, K3,  3, 14 );\n+  R( dr, er, ar, br, cr, F1, KK3, 12,  9);\n+  R( cl, dl, el, al, bl, F3, K3,  7,  5 );\n+  R( cr, dr, er, ar, br, F1, KK3,\t2, 12);\n+  R( bl, cl, dl, el, al, F3, K3, 15,  6 );\n+  R( br, cr, dr, er, ar, F1, KK3, 13,  9);\n+  R( al, bl, cl, dl, el, F3, K3, 14,  8 );\n+  R( ar, br, cr, dr, er, F1, KK3,\t9, 12);\n+  R( el, al, bl, cl, dl, F3, K3,  5,  6 );\n+  R( er, ar, br, cr, dr, F1, KK3,\t7,  5);\n+  R( dl, el, al, bl, cl, F3, K3,  6,  5 );\n+  R( dr, er, ar, br, cr, F1, KK3, 10, 15);\n+  R( cl, dl, el, al, bl, F3, K3,  2, 12 );\n+  R( cr, dr, er, ar, br, F1, KK3, 14,  8);\n+  R( bl, cl, dl, el, al, F4, K4,  4,  9 );\n+  R( br, cr, dr, er, ar, F0, KK4, 12,  8);\n+  R( al, bl, cl, dl, el, F4, K4,  0, 15 );\n+  R( ar, br, cr, dr, er, F0, KK4, 15,  5);\n+  R( el, al, bl, cl, dl, F4, K4,  5,  5 );\n+  R( er, ar, br, cr, dr, F0, KK4, 10, 12);\n+  R( dl, el, al, bl, cl, F4, K4,  9, 11 );\n+  R( dr, er, ar, br, cr, F0, KK4,\t4,  9);\n+  R( cl, dl, el, al, bl, F4, K4,  7,  6 );\n+  R( cr, dr, er, ar, br, F0, KK4,\t1, 12);\n+  R( bl, cl, dl, el, al, F4, K4, 12,  8 );\n+  R( br, cr, dr, er, ar, F0, KK4,\t5,  5);\n+  R( al, bl, cl, dl, el, F4, K4,  2, 13 );\n+  R( ar, br, cr, dr, er, F0, KK4,\t8, 14);\n+  R( el, al, bl, cl, dl, F4, K4, 10, 12 );\n+  R( er, ar, br, cr, dr, F0, KK4,\t7,  6);\n+  R( dl, el, al, bl, cl, F4, K4, 14,  5 );\n+  R( dr, er, ar, br, cr, F0, KK4,\t6,  8);\n+  R( cl, dl, el, al, bl, F4, K4,  1, 12 );\n+  R( cr, dr, er, ar, br, F0, KK4,\t2, 13);\n+  R( bl, cl, dl, el, al, F4, K4,  3, 13 );\n+  R( br, cr, dr, er, ar, F0, KK4, 13,  6);\n+  R( al, bl, cl, dl, el, F4, K4,  8, 14 );\n+  R( ar, br, cr, dr, er, F0, KK4, 14,  5);\n+  R( el, al, bl, cl, dl, F4, K4, 11, 11 );\n+  R( er, ar, br, cr, dr, F0, KK4,\t0, 15);\n+  R( dl, el, al, bl, cl, F4, K4,  6,  8 );\n+  R( dr, er, ar, br, cr, F0, KK4,\t3, 13);\n+  R( cl, dl, el, al, bl, F4, K4, 15,  5 );\n+  R( cr, dr, er, ar, br, F0, KK4,\t9, 11);\n+  R( bl, cl, dl, el, al, F4, K4, 13,  6 );\n+  R( br, cr, dr, er, ar, F0, KK4, 11, 11);\n+\n+  dr += cl + hd->h1;\n+  hd->h1 = hd->h2 + dl + er;\n+  hd->h2 = hd->h3 + el + ar;\n+  hd->h3 = hd->h4 + al + br;\n+  hd->h4 = hd->h0 + bl + cr;\n+  hd->h0 = dr;\n+\n+  return /*burn_stack*/ 104+5*sizeof(void*);\n }\n \n \n", "changed_method_name": "transform_blk"}
{"commit_url": "https://github.com/gpg/libgcrypt/commit/e11895da1f4af9782d89e92ba2e6b1a63235b54b", "commit_message": "Add carryless 8-bit addition fast-path for AES-NI CTR mode\n\n* cipher/rijndael-aesni.c (do_aesni_ctr_4): Do addition using\nCTR in big-endian form, if least-significant byte does not overflow.\n--\n\nPatch improves AES-NI CTR speed by 20%.\n\nBenchmark on Intel Haswell (3.2 Ghz):\n\nBefore:\n AES            |  nanosecs/byte   mebibytes/sec   cycles/byte\n        CTR enc |     0.273 ns/B    3489.8 MiB/s     0.875 c/B\n        CTR dec |     0.273 ns/B    3491.0 MiB/s     0.874 c/B\n\nAfter:\n        CTR enc |     0.228 ns/B    4190.0 MiB/s     0.729 c/B\n        CTR dec |     0.228 ns/B    4190.2 MiB/s     0.729 c/B\n\nSigned-off-by: Jussi Kivilinna <jussi.kivilinna@iki.fi>", "code_diff": "@@ -787,6 +787,13 @@ static void\n do_aesni_ctr_4 (const RIJNDAEL_context *ctx,\n                 unsigned char *ctr, unsigned char *b, const unsigned char *a)\n {\n+  static const byte bige_addb_const[4][16] __attribute__ ((aligned (16))) =\n+    {\n+      { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1 },\n+      { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2 },\n+      { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3 },\n+      { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4 }\n+    };\n #define aesenc_xmm1_xmm0      \".byte 0x66, 0x0f, 0x38, 0xdc, 0xc1\\n\\t\"\n #define aesenc_xmm1_xmm2      \".byte 0x66, 0x0f, 0x38, 0xdc, 0xd1\\n\\t\"\n #define aesenc_xmm1_xmm3      \".byte 0x66, 0x0f, 0x38, 0xdc, 0xd9\\n\\t\"\n@@ -807,7 +814,25 @@ do_aesni_ctr_4 (const RIJNDAEL_context *ctx,\n       xmm6  endian swapping mask\n    */\n \n-  asm volatile (\"movdqa %%xmm5, %%xmm0\\n\\t\"     /* xmm0, xmm2 := CTR (xmm5) */\n+  asm volatile (/* detect if 8-bit carry handling is needed */\n+                \"cmpb   $0xfb, 15(%[ctr])\\n\\t\"\n+                \"ja     .Ladd32bit%=\\n\\t\"\n+\n+                \"movdqa %%xmm5, %%xmm0\\n\\t\"     /* xmm0 := CTR (xmm5) */\n+                \"movdqa %[addb_1], %%xmm2\\n\\t\"  /* xmm2 := be(1) */\n+                \"movdqa %[addb_2], %%xmm3\\n\\t\"  /* xmm3 := be(2) */\n+                \"movdqa %[addb_3], %%xmm4\\n\\t\"  /* xmm4 := be(3) */\n+                \"movdqa %[addb_4], %%xmm5\\n\\t\"  /* xmm5 := be(4) */\n+                \"paddb  %%xmm0, %%xmm2\\n\\t\"     /* xmm2 := be(1) + CTR (xmm0) */\n+                \"paddb  %%xmm0, %%xmm3\\n\\t\"     /* xmm3 := be(2) + CTR (xmm0) */\n+                \"paddb  %%xmm0, %%xmm4\\n\\t\"     /* xmm4 := be(3) + CTR (xmm0) */\n+                \"paddb  %%xmm0, %%xmm5\\n\\t\"     /* xmm5 := be(4) + CTR (xmm0) */\n+                \"movdqa (%[key]), %%xmm1\\n\\t\"   /* xmm1 := key[0] */\n+                \"movl   %[rounds], %%esi\\n\\t\"\n+                \"jmp    .Lstore_ctr%=\\n\\t\"\n+\n+                \".Ladd32bit%=:\\n\\t\"\n+                \"movdqa %%xmm5, %%xmm0\\n\\t\"     /* xmm0, xmm2 := CTR (xmm5) */\n                 \"movdqa %%xmm0, %%xmm2\\n\\t\"\n                 \"pcmpeqd %%xmm1, %%xmm1\\n\\t\"\n                 \"psrldq $8, %%xmm1\\n\\t\"         /* xmm1 = -1 */\n@@ -852,6 +877,8 @@ do_aesni_ctr_4 (const RIJNDAEL_context *ctx,\n                 \"pshufb %%xmm6, %%xmm3\\n\\t\"     /* xmm3 := be(xmm3) */\n                 \"pshufb %%xmm6, %%xmm4\\n\\t\"     /* xmm4 := be(xmm4) */\n                 \"pshufb %%xmm6, %%xmm5\\n\\t\"     /* xmm5 := be(xmm5) */\n+\n+                \".Lstore_ctr%=:\\n\\t\"\n                 \"movdqa %%xmm5, (%[ctr])\\n\\t\"   /* Update CTR (mem).  */\n \n                 \"pxor   %%xmm1, %%xmm0\\n\\t\"     /* xmm0 ^= key[0]    */\n@@ -956,7 +983,11 @@ do_aesni_ctr_4 (const RIJNDAEL_context *ctx,\n                   [src] \"r\" (a),\n                   [dst] \"r\" (b),\n                   [key] \"r\" (ctx->keyschenc),\n-                  [rounds] \"g\" (ctx->rounds)\n+                  [rounds] \"g\" (ctx->rounds),\n+                  [addb_1] \"m\" (bige_addb_const[0][0]),\n+                  [addb_2] \"m\" (bige_addb_const[1][0]),\n+                  [addb_3] \"m\" (bige_addb_const[2][0]),\n+                  [addb_4] \"m\" (bige_addb_const[3][0])\n                 : \"%esi\", \"cc\", \"memory\");\n #undef aesenc_xmm1_xmm0\n #undef aesenc_xmm1_xmm2\n", "changed_method_name": "do_aesni_ctr_4"}
{"commit_url": "https://github.com/gpg/libgcrypt/commit/bf6d5b10cb4173826f47ac080506b68bb001acb2", "commit_message": "cipher: Fix IDEA cipher for clearing memory.\n\n* cipher/idea.c (invert_key): Use wipememory, since this kind of memset\nmay be removed by compiler optimization.\n\n--\nReported-by: Zhaomo Yang and Brian Johannesmeyer\nSigned-off-by: NIIBE Yutaka <gniibe@fsij.org>", "code_diff": "@@ -152,7 +152,7 @@ invert_key( u16 *ek, u16 dk[IDEA_KEYLEN] )\n     *--p = t2;\n     *--p = t1;\n     memcpy(dk, temp, sizeof(temp) );\n-    memset(temp, 0, sizeof(temp) );  /* burn temp */\n+    wipememory(temp, sizeof(temp));\n }\n \n \n", "changed_method_name": "invert_key"}
{"commit_url": "https://github.com/gpg/libgcrypt/commit/8725c99ffa41778f382ca97233183bcd687bb0ce", "commit_message": "rsa: Add exponent blinding.\n\n* cipher/rsa.c (secret_core_crt): Blind secret D with randomized\nnonce R for mpi_powm computation.\n\n--\n\nCo-authored-by: Werner Koch <wk@gnupg.org>\nSigned-off-by: NIIBE Yutaka <gniibe@fsij.org>\n\nThe paper describing attack: https://eprint.iacr.org/2017/627\n\nSliding right into disaster: Left-to-right sliding windows leak\nby Daniel J. Bernstein and Joachim Breitner and Daniel Genkin and\nLeon Groot Bruinderink and Nadia Heninger and Tanja Lange and\nChristine van Vredendaal and Yuval Yarom\n\n  It is well known that constant-time implementations of modular\n  exponentiation cannot use sliding windows. However, software\n  libraries such as Libgcrypt, used by GnuPG, continue to use sliding\n  windows. It is widely believed that, even if the complete pattern of\n  squarings and multiplications is observed through a side-channel\n  attack, the number of exponent bits leaked is not sufficient to\n  carry out a full key-recovery attack against RSA. Specifically,\n  4-bit sliding windows leak only 40% of the bits, and 5-bit sliding\n  windows leak only 33% of the bits.\n\n  In this paper we demonstrate a complete break of RSA-1024 as\n  implemented in Libgcrypt. Our attack makes essential use of the fact\n  that Libgcrypt uses the left-to-right method for computing the\n  sliding-window expansion. We show for the first time that the\n  direction of the encoding matters: the pattern of squarings and\n  multiplications in left-to-right sliding windows leaks significantly\n  more information about exponent bits than for right-to-left. We show\n  how to incorporate this additional information into the\n  Heninger-Shacham algorithm for partial key reconstruction, and use\n  it to obtain very efficient full key recovery for RSA-1024. We also\n  provide strong evidence that the same attack works for RSA-2048 with\n  only moderately more computation.\n\nExponent blinding is a kind of workaround to add noise.  Signal (leak)\nis still there for non-constant-time implementation.", "code_diff": "@@ -1019,16 +1019,37 @@ secret_core_crt (gcry_mpi_t M, gcry_mpi_t C,\n   gcry_mpi_t m1 = mpi_alloc_secure ( Nlimbs + 1 );\n   gcry_mpi_t m2 = mpi_alloc_secure ( Nlimbs + 1 );\n   gcry_mpi_t h  = mpi_alloc_secure ( Nlimbs + 1 );\n-\n-  /* m1 = c ^ (d mod (p-1)) mod p */\n+  gcry_mpi_t D_blind = mpi_alloc_secure ( Nlimbs + 1 );\n+  gcry_mpi_t r;\n+  unsigned int r_nbits;\n+\n+  r_nbits = mpi_get_nbits (P) / 4;\n+  if (r_nbits < 96)\n+    r_nbits = 96;\n+  r = mpi_alloc_secure ( (r_nbits + BITS_PER_MPI_LIMB-1)/BITS_PER_MPI_LIMB );\n+\n+  /* d_blind = (d mod (p-1)) + (p-1) * r            */\n+  /* m1 = c ^ d_blind mod p */\n+  _gcry_mpi_randomize (r, r_nbits, GCRY_WEAK_RANDOM);\n+  mpi_set_highbit (r, r_nbits - 1);\n   mpi_sub_ui ( h, P, 1 );\n+  mpi_mul ( D_blind, h, r );\n   mpi_fdiv_r ( h, D, h );\n-  mpi_powm ( m1, C, h, P );\n+  mpi_add ( D_blind, D_blind, h );\n+  mpi_powm ( m1, C, D_blind, P );\n \n-  /* m2 = c ^ (d mod (q-1)) mod q */\n+  /* d_blind = (d mod (q-1)) + (q-1) * r            */\n+  /* m2 = c ^ d_blind mod q */\n+  _gcry_mpi_randomize (r, r_nbits, GCRY_WEAK_RANDOM);\n+  mpi_set_highbit (r, r_nbits - 1);\n   mpi_sub_ui ( h, Q, 1  );\n+  mpi_mul ( D_blind, h, r );\n   mpi_fdiv_r ( h, D, h );\n-  mpi_powm ( m2, C, h, Q );\n+  mpi_add ( D_blind, D_blind, h );\n+  mpi_powm ( m2, C, D_blind, Q );\n+\n+  mpi_free ( r );\n+  mpi_free ( D_blind );\n \n   /* h = u * ( m2 - m1 ) mod q */\n   mpi_sub ( h, m2, m1 );\n", "changed_method_name": "secret_core_crt"}
{"commit_url": "https://github.com/gpg/libgcrypt/commit/3841b23c0ccb24d555b7570083bba958e3126d26", "commit_message": "_gcry_burn_stack: use memset for clearing memory\n\n* src/misc.c (__gcry_burn_stack) [HAVE_VLA]: Use 'memset' for clearing\nstack.\n--\n\nPatch switches stacking burning to use faster memset instead of\nwipememory. Memset is accessed through volatile function pointer,\nso that compiler will not optimize away the call.\n\nSigned-off-by: Jussi Kivilinna <jussi.kivilinna@iki.fi>", "code_diff": "@@ -501,11 +501,12 @@ void\n __gcry_burn_stack (unsigned int bytes)\n {\n #ifdef HAVE_VLA\n+    static void *(*volatile memset_ptr)(void *, int, size_t) = (void *)memset;\n     /* (bytes == 0 ? 1 : bytes) == (!bytes + bytes) */\n     unsigned int buflen = ((!bytes + bytes) + 63) & ~63;\n-    volatile char buf[buflen];\n+    char buf[buflen];\n \n-    wipememory (buf, sizeof buf);\n+    memset_ptr (buf, 0, sizeof buf);\n #else\n     volatile char buf[64];\n \n", "changed_method_name": "__gcry_burn_stack"}
