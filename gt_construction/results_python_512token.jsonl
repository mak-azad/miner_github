{"commit_url":"https://github.com/astropy/astropy/commit/752887c906ebc093c2b67474feb8e0b496887beb","commit_message":"Replaced pow with a multiply","code_diff":"@@ -43,7 +43,7 @@ void compute_sigma_clipped_bounds(double data_buffer[], int count, int use_media\n \n       std = 0;\n       for (i = 0; i < count; i++) {\n-        std += pow(mean - data_buffer[i], 2);\n+        std += (data_buffer[i] - mean) * (data_buffer[i] - mean);\n       }\n       std = sqrt(std / count);\n \n","changed_method_name":"compute_sigma_clipped_bounds","commit_message_token_length":6,"code_token_length":150,"combined_token_length":156}
{"commit_url":"https://github.com/Bitmessage/PyBitmessage/commit/03316496b7c3380c5ac408f86d049855dbcedac6","commit_message":"Stop UDPSocket on socket.error 101 (Network is unreachable)","code_diff":"@@ -146,6 +146,9 @@ class UDPSocket(BMProto):  # pylint: disable=too-many-instance-attributes\n             retval = self.socket.sendto(\n                 self.write_buf, ('<broadcast>', self.port))\n         except socket.error as e:\n-            logger.error(\"socket error on sendato: %s\", e)\n+            logger.error(\"socket error on sendto: %s\", e)\n+            if e.errno == 101:\n+                self.announcing = False\n+                self.socket.close()\n             retval = 0\n         self.slice_write_buf(retval)\n","changed_method_name":"handle_write","commit_message_token_length":15,"code_token_length":268,"combined_token_length":283}
{"commit_url":"https://github.com/Bitmessage/PyBitmessage/commit/11bec55be56e73502fbd569bf0327a8876b54315","commit_message":"Don't put addresses into queue\n\n- attempt to fix #1598\n- seems to work\n- addresses won't be uploaded/announced anymore other than after connecting,\n  Later I need to find out how to announce them without causing problems, but\n  for the time disabling this seems an acceptable drawback","code_diff":"@@ -31,7 +31,7 @@ from network.dandelion import Dandelion\n from network.proxy import ProxyError\n from node import Node, Peer\n from objectracker import ObjectTracker, missingObjects\n-from queues import addrQueue, invQueue, objectProcessorQueue, portCheckerQueue\n+from queues import invQueue, objectProcessorQueue, portCheckerQueue\n from randomtrackingdict import RandomTrackingDict\n \n logger = logging.getLogger('default')\n@@ -466,8 +466,9 @@ class BMProto(AdvancedDispatcher, ObjectTracker):\n                             }\n                     # since we don't track peers outside of knownnodes,\n                     # only spread if in knownnodes to prevent flood\n-                    addrQueue.put((stream, peer, seenTime,\n-                                   self.destination))\n+                    # DISABLED TO WORKAROUND FLOOD/LEAK\n+                    # addrQueue.put((stream, peer, seenTime,\n+                    #               self.destination))\n         return True\n \n     def bm_command_portcheck(self):\n","changed_method_name":"bm_command_addr","commit_message_token_length":63,"code_token_length":441,"combined_token_length":504}
{"commit_url":"https://github.com/python-rope/rope/commit/ae8ea5d0a615936bc6f5b0964910566565d6b6b7","commit_message":"Modifies default_config.py","code_diff":"@@ -15,7 +15,8 @@ def set_prefs(prefs):\n     # 'build/*.o': matches 'build/lib.o' but not 'build/sub/lib.o'\n     # 'build//*.o': matches 'build/lib.o' and 'build/sub/lib.o'\n     prefs['ignored_resources'] = ['*.pyc', '*~', '.ropeproject',\n-                                  '.hg', '.svn', '_svn', '.git', '.tox']\n+                                  '.hg', '.svn', '_svn', '.git', '.tox',\n+                                  '.venv', 'venv']\n \n     # Specifies which files should be considered python files.  It is\n     # useful when you have scripts inside your project.  Only files\n","changed_method_name":"set_prefs","commit_message_token_length":7,"code_token_length":301,"combined_token_length":308}
{"commit_url":"https://github.com/scikit-bio/scikit-bio/commit/76b40140b6e9104288932f60c2a10b7b445f41fa","commit_message":"ENH: performance enhancement, fixes #411","code_diff":"@@ -1014,7 +1014,7 @@ class BiologicalSequence(Sequence):\n             step = k\n \n         for i in range(0, sequence_length - k + 1, step):\n-            yield constructor(self[i:i+k])\n+            yield self._sequence[i:i+k]\n \n     def k_word_counts(self, k, overlapping=True, constructor=str):\n         \"\"\"Get the counts of words of length k\n","changed_method_name":"k_words","commit_message_token_length":9,"code_token_length":158,"combined_token_length":167}
{"commit_url":"https://github.com/microsoft/ptvsd/commit/1a13aa2450fee2a0aac4ecbe84d448a1700309b7","commit_message":"Fix #967: Debugging Django in VSC with subprocess debugging is very slow\n\nAvoid hogging CPU while waiting on the subprocess notification queue.","code_diff":"@@ -1296,7 +1296,7 @@ class VSCodeMessageProcessor(VSCLifecycleMsgProcessor):\n     def _subprocess_notifier(self):\n         while not self.closed:\n             try:\n-                subprocess_request, subprocess_response = multiproc.subprocess_queue.get(block=False, timeout=0.1)\n+                subprocess_request, subprocess_response = multiproc.subprocess_queue.get(timeout=0.1)\n             except queue.Empty:\n                 continue\n \n","changed_method_name":"_subprocess_notifier","commit_message_token_length":33,"code_token_length":202,"combined_token_length":235}
{"commit_url":"https://github.com/GeoStat-Framework/GSTools/commit/c88f7bab0e309f7a32c1a61786ba340245d215a2","commit_message":"emcee: vectorize sampling since all ln_pdfs accept numpy arrays","code_diff":"@@ -86,7 +86,7 @@ class RNG:\n             self.random.rand(nwalkers).reshape((nwalkers, 1)) * sample_around\n         )\n         # initialize the sampler\n-        sampler = mc.EnsembleSampler(nwalkers, 1, ln_pdf)\n+        sampler = mc.EnsembleSampler(nwalkers, 1, ln_pdf, vectorize=True)\n         # burn in phase with saving of last position\n         initial_state = State(init_guess, copy=True)\n         initial_state.random_state = self.random.get_state()\n","changed_method_name":"sample_ln_pdf","commit_message_token_length":18,"code_token_length":207,"combined_token_length":225}
{"commit_url":"https://github.com/static-frame/static-frame/commit/2cda5f824ba56a082b3874a836c4a7c8c607d902","commit_message":"'Fix' property test by ignoring date cases. Is referenced by issue #132","code_diff":"@@ -158,7 +158,9 @@ class TestUnit(TestCase):\n     @given(sfst.get_frame()) # type: ignore\n     def test_frame_isin(self, f1: Frame) -> None:\n         value = f1.iloc[0, 0]\n-        if not isna_element(value):\n+        if (not isna_element(value) and\n+                not isinstance(value, np.datetime64) and\n+                not isinstance(value, np.timedelta64)):\n             self.assertTrue(f1.isin((value,)).iloc[0, 0])\n \n \n","changed_method_name":"test_frame_isin","commit_message_token_length":16,"code_token_length":216,"combined_token_length":232}
{"commit_url":"https://github.com/gem/oq-engine/commit/be813aa4a76c3689f45aca18c7b93aa64a446c0b","commit_message":"Fixed misprint making counting the ruptures ultra-slow in event_based","code_diff":"@@ -403,7 +403,7 @@ class EventBasedCalculator(base.HazardCalculator):\n         with self.monitor('counting ruptures', measuremem=True):\n             nrups = parallel.Starmap( # weighting the heavy sources\n                 count_ruptures, [(src,) for src in sources\n-                                 if src.code == b'AMSC'],\n+                                 if src.code in b'AMSC'],\n                 progress=logging.debug).reduce()\n             # NB: multifault sources must be considered light to avoid a large\n             # data transfer, even if .count_ruptures can be slow\n","changed_method_name":"build_events_from_sources","commit_message_token_length":15,"code_token_length":279,"combined_token_length":294}
{"commit_url":"https://github.com/gem/oq-engine/commit/c9a92dac9b354a5418c8771ceb5b7d529186c728","commit_message":"Gzipping the _rates","code_diff":"@@ -400,7 +400,7 @@ class ClassicalCalculator(base.HazardCalculator):\n         self.cmakers = read_cmakers(self.datastore, self.csm)\n         self.cfactor = numpy.zeros(3)\n         self.rel_ruptures = AccumDict(accum=0)  # grp_id -> rel_ruptures\n-        self.datastore.create_df('_rates', rates_dt.items())\n+        self.datastore.create_df('_rates', rates_dt.items(), 'gzip')\n         self.datastore.create_dset('_rates/slice_by_sid', slice_dt)\n         # NB: compressing the dataset causes a big slowdown in writing :-(\n \n","changed_method_name":"init_poes","commit_message_token_length":6,"code_token_length":233,"combined_token_length":239}
{"commit_url":"https://github.com/cc-archive/cccatalog-api/commit/f5f0f6eb8536bc32b04f009c933e6aebe984a3c7","commit_message":"Don't wait for replica shards.","code_diff":"@@ -322,18 +322,6 @@ class TableIndexer:\n                 }\n             }\n         )\n-        # Cluster status will always be yellow in development environments\n-        # because there will only be one node available. In production, there\n-        # are many nodes, and the index should not be promoted until all\n-        # shards have been initialized.\n-        environment = os.getenv('ENVIRONMENT', 'local')\n-        if environment != 'local':\n-            log.info('Waiting for replica shards. . .')\n-            es.cluster.health(\n-                index=write_index,\n-                wait_for_status='green',\n-                timeout=\"3h\"\n-            )\n         # If the index exists already and it's not an alias, delete it.\n         if live_alias in indices:\n             log.warning('Live index already exists. Deleting and realiasing.')\n","changed_method_name":"go_live","commit_message_token_length":7,"code_token_length":379,"combined_token_length":386}
{"commit_url":"https://github.com/uclouvain/osis-portal/commit/b0a2dbbc842c9e4a3f10f41a761c49cf5254b085","commit_message":"#824 modifictaion ordre nom/prenom","code_diff":"@@ -16,8 +16,8 @@ function fillPage(studentJson) {\n  * studentJson: a json containing the student results.\n  */\n function fillStudentInfo(studentJson) {\n-  var firstName = studentJson.etudiant.nom;\n-  var lastName = studentJson.etudiant.prenom;\n+  var firstName = studentJson.etudiant.prenom;\n+  var lastName = studentJson.etudiant.nom;\n   var academicYear = studentJson.monAnnee.anneeAcademique;\n   var programTitle = studentJson.monAnnee.monOffre.offre.intituleComplet;\n   $(\"#student_name\").append(\"<br>\");\n","changed_method_name":"fillStudentInfo","commit_message_token_length":15,"code_token_length":185,"combined_token_length":200}
