{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "# Load the CodeBERT tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "\n",
    "# Assuming final_df is your DataFrame with 'Commit_message' and 'code' columns\n",
    "# Tokenize the Commit_message and code, then get the token lengths\n",
    "\n",
    "#read gt into a df\n",
    "\n",
    "\n",
    "final_df['commit_message_token_length'] = final_df['commit_message'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "final_df['code_token_length'] = final_df['diff'].apply(lambda x: len(tokenizer.tokenize(x)))\n",
    "\n",
    "# Combine the token lengths\n",
    "final_df['combined_token_length'] = final_df['commit_message_token_length'] + final_df['code_token_length']\n",
    "\n",
    "# Display the final DataFrame with the new column\n",
    "print(final_df[['commit_message', 'diff', 'commit_message_token_length', 'code_token_length', 'combined_token_length']])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
