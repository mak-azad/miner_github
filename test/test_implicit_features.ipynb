{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your .jsonl file\n",
    "file_path = 'output_file.jsonl'\n",
    "\n",
    "# Read the .jsonl file into a pandas DataFrame\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify it's loaded correctly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Regex Pattern:\n",
      "slow.*fast|speed.*up|vector.*improve|vector.*improves|vector.*improving|vector.*improved|vectorize.*improve|vectorize.*improves|vectorize.*improving|vectorize.*improved|vectorzing.*improve|vectorzing.*improves|vectorzing.*improving|vectorzing.*improved|vectorized.*improve|vectorized.*improves|vectorized.*improving|vectorized.*improved|fast.*memory|faster.*memory|universal.*intrinsics|universal.*intrinsics|backend.*performance|backend.*performances|speedup.*added|speedups.*added|speed-up.*added|performance.*benefit|gain|increas|hit|more.*efficien|perf|optimiz|(speed.*up)|efficien|faster|benefit|gain|increas|hit|solution|patch|code|perf.*bug|large.*performance|large.*performances|better.*performance|better.*performances|patch.*improve|patch.*improves|patch.*improving|patch.*improved|accelerat|fixed.*performance|fixed.*performances|improv.*perf|optimize.*performance|optimize.*performances|optimizes.*performance|optimizes.*performances|optimized.*performance|optimized.*performances|optimizing.*performance|optimizing.*performances|(\\d+)% fast|(\\d+)x faster|increas.*perf|reduc.*overhead|optimiz|inefficien|memory.*optimiz|avoid.*overhead|reduce.*overhead|perf.*enhanc|perf.*gain|perf.*benefit|faster|perf.*improve|perf.*improves|perf.*improving|perf.*improved|perf.*improvement|memory.*leak|performance fix|performance.*optimiz|performance.*inefficien|performance.*bottleneck|performance.*hit|performance.*(increas|throughput)|performance.*regression|patch|perf.*(issue|problem|regression)\n"
     ]
    }
   ],
   "source": [
    "# Combined list of all regex patterns extracted from the provided Python functions\n",
    "combined_patterns = [\n",
    "    r'slow.*fast',\n",
    "    r'speed.*up',\n",
    "    r'vector.*improve|vector.*improves|vector.*improving|vector.*improved|vectorize.*improve|vectorize.*improves|vectorize.*improving|vectorize.*improved|vectorzing.*improve|vectorzing.*improves|vectorzing.*improving|vectorzing.*improved|vectorized.*improve|vectorized.*improves|vectorized.*improving|vectorized.*improved',\n",
    "    r'fast.*memory|faster.*memory',\n",
    "    r'universal.*intrinsics|universal.*intrinsics',\n",
    "    r'backend.*performance|backend.*performances',\n",
    "    'speedup.*added|speedups.*added|speed-up.*added',\n",
    "    'performance.*benefit|gain|increas|hit',\n",
    "    r'more.*efficien',\n",
    "    r'perf|optimiz|(speed.*up)|efficien|faster|benefit|gain|increas|hit|solution|patch|code',\n",
    "    r'perf.*bug',\n",
    "    r'large.*performance|large.*performances',\n",
    "    r'better.*performance|better.*performances',\n",
    "    r'patch.*improve|patch.*improves|patch.*improving|patch.*improved',\n",
    "    r'accelerat',\n",
    "    r'fixed.*performance|fixed.*performances',\n",
    "    r'improv.*perf',\n",
    "    r'optimize.*performance|optimize.*performances|optimizes.*performance|optimizes.*performances|optimized.*performance|optimized.*performances|optimizing.*performance|optimizing.*performances',\n",
    "    r'(\\d+)% fast',\n",
    "    r'(\\d+)x faster',\n",
    "    r'increas.*perf',\n",
    "    r'reduc.*overhead',\n",
    "    r'optimiz',\n",
    "    r'inefficien',\n",
    "    r'memory.*optimiz',\n",
    "    r'avoid.*overhead|reduce.*overhead',\n",
    "    r'perf.*enhanc',\n",
    "    r'perf.*gain',\n",
    "    r'perf.*benefit',\n",
    "    r'faster',\n",
    "    r'perf.*improve|perf.*improves|perf.*improving|perf.*improved|perf.*improvement',\n",
    "    'memory.*leak',\n",
    "    r'performance fix',\n",
    "    r'performance.*optimiz',\n",
    "    r'performance.*inefficien',\n",
    "    r'performance.*bottleneck',\n",
    "    r'performance.*hit',\n",
    "    r'performance.*(increas|throughput)',\n",
    "    r'performance.*regression',\n",
    "    r'patch',\n",
    "    r'perf.*(issue|problem|regression)'\n",
    "]\n",
    "\n",
    "# Combining the patterns into a single regex pattern with the \"or\" (|) operator\n",
    "regex_patterns = '|'.join(combined_patterns)\n",
    "\n",
    "print(\"Combined Regex Pattern:\")\n",
    "print(regex_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex_patterns=[] # all the regex patterns derived from the bi-gram \n",
    "\n",
    "\n",
    "# regex_patterns.append('slow.*fast')\n",
    "\n",
    "# regex_patterns.append('see.*speedup|see.*speedups|see.*speed-up|seeing.*speedup|seeing.*speedups|seeing.*speed-up|sees.*speedup|sees.*speedups|sees.*speed-up|observe.*speedup|observe.*speedups|observe.*speed-up|observes.*speedup|observes.*speedups|observes.*speed-up|observed.*speedup|observed.*speedups|observed.*speed-up|observing.*speedup|observing.*speedups|observing.*speed-up')\n",
    "# regex_patterns.append('vector.*improve|vector.*improves|vector.*improving|vector.*improved|vectorize.*improve|vectorize.*improves|vectorize.*improving|vectorize.*improved|vectorzing.*improve|vectorzing.*improves|vectorzing.*improving|vectorzing.*improved|vectorized.*improve|vectorized.*improves|vectorized.*improving|vectorized.*improved')\n",
    "# regex_patterns.append('fast.*memory|faster.*memory')\n",
    "# regex_patterns.append('universal.*intrinsics|universal.*intrinsics')\n",
    "# regex_patterns.append('backend.*performance|backend.*performances')\n",
    "# regex_patterns.append('speedup.*added|speedups.*added|speed-up.*added')\n",
    "# #regex_patterns.append('this.*improves|this.*improved')\n",
    "# #regex_patterns.append('fixed.*fast|fixes.*fast') #better to remove this seed as \n",
    "# regex_patterns.append('performance.*problem')\n",
    "# regex_patterns.append('more.*efficient')\n",
    "# #regex_patterns.append('secs.*time')\n",
    "# regex_patterns.append('performance.*bug|performance.*fix|performance.*optimization|performance.*inefficien|performance.*bottleneck|performance.*improv|performance.*hit|performance.*increas|performance.*regression')\n",
    "# regex_patterns.append('large.*performance|large.*performances')\n",
    "# regex_patterns.append('better.*performance|better.*performances')\n",
    "# #regex_patterns.append('(?<=\\s)patch.*improv(?:e|es|ing|ed)')\n",
    "# regex_patterns.append('patch.*improve|patch.*improves|patch.*improving|patch.*improved')\n",
    "# #regex_patterns.append('(?<!\\[)patch(?!]).*improve|(?<!\\[)patch(?!]).*improves|(?<!\\[)patch(?!]).*improving|(?<!\\[)patch(?!]).*improved')\n",
    "# regex_patterns.append('patch.*accelerate|patch.*accelerates|patch.*accelarated')\n",
    "# regex_patterns.append('fixed.*performance|fixed.*performances')\n",
    "# regex_patterns.append('improve.*performance|improve.*performances|improves.*performance|improves.*performances|improving.*performance|improving.*performances|improved.*performance|improved.*performances')\n",
    "# regex_patterns.append('optimize.*performance|optimize.*performances|optimizes.*performance|optimizes.*performances|optimized.*performance|optimized.*performances|optimizing.*performance|optimizing.*performances')\n",
    "# ############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_897671/2780629003.py:16: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  filtered_df = df[~df['commit_message'].str.contains(regex_patterns, flags=re.IGNORECASE, na=False)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>commit_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>initialize mt19937 statically in function  thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>drop trailing garbage of gzip decompress  i pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>reimplement transaction fetching to use a pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>net: don't wait if changing the network state ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>create_tx: fix unblinded value and improve ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15624</th>\n",
       "      <td>15626</td>\n",
       "      <td>navigator: reduce stack size by 50 bytes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15625</th>\n",
       "      <td>15627</td>\n",
       "      <td>mc_att_control: reduce stack mildly by 50 bytes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15626</th>\n",
       "      <td>15628</td>\n",
       "      <td>sensors: reduce stack mildly by 50 bytes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15627</th>\n",
       "      <td>15629</td>\n",
       "      <td>ardrone interface: reduce stack size  conflict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15628</th>\n",
       "      <td>15630</td>\n",
       "      <td>mpu6k: use usleep where usleep should be used ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4810 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx                                     commit_message\n",
       "2          2  initialize mt19937 statically in function  thi...\n",
       "3          3  drop trailing garbage of gzip decompress  i pr...\n",
       "9          9  reimplement transaction fetching to use a pers...\n",
       "10        10  net: don't wait if changing the network state ...\n",
       "11        11  create_tx: fix unblinded value and improve ran...\n",
       "...      ...                                                ...\n",
       "15624  15626           navigator: reduce stack size by 50 bytes\n",
       "15625  15627    mc_att_control: reduce stack mildly by 50 bytes\n",
       "15626  15628           sensors: reduce stack mildly by 50 bytes\n",
       "15627  15629  ardrone interface: reduce stack size  conflict...\n",
       "15628  15630  mpu6k: use usleep where usleep should be used ...\n",
       "\n",
       "[4810 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Example DataFrame and regex patterns\n",
    "#data = {'commit_message': ['fix bug #123', 'update README', 'feature add xyz', 'bug #123 fixed']}\n",
    "#df = pd.DataFrame(data)\n",
    "\n",
    "# List of regex patterns\n",
    "#regex_patterns = ['bug #\\\\d+', 'fix']\n",
    "\n",
    "# Combine regex patterns into a single pattern\n",
    "#combined_regex = '|'.join(regex_patterns)\n",
    "\n",
    "# Filter rows where 'commit_message' matches any of the regex patterns\n",
    "# The ~ operator is used to get rows that do NOT match the pattern, remove it if you want rows that DO match\n",
    "filtered_df = df[~df['commit_message'].str.contains(regex_patterns, flags=re.IGNORECASE, na=False)]\n",
    "\n",
    "#print(filtered_df.head())\n",
    "filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>commit_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>initialize mt19937 statically in function  thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>drop trailing garbage of gzip decompress  i pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>reimplement transaction fetching to use a pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>net: don't wait if changing the network state ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>create_tx: fix unblinded value and improve ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15624</th>\n",
       "      <td>15626</td>\n",
       "      <td>navigator: reduce stack size by 50 bytes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15625</th>\n",
       "      <td>15627</td>\n",
       "      <td>mc_att_control: reduce stack mildly by 50 bytes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15626</th>\n",
       "      <td>15628</td>\n",
       "      <td>sensors: reduce stack mildly by 50 bytes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15627</th>\n",
       "      <td>15629</td>\n",
       "      <td>ardrone interface: reduce stack size  conflict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15628</th>\n",
       "      <td>15630</td>\n",
       "      <td>mpu6k: use usleep where usleep should be used ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4810 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         idx                                     commit_message\n",
       "2          2  initialize mt19937 statically in function  thi...\n",
       "3          3  drop trailing garbage of gzip decompress  i pr...\n",
       "9          9  reimplement transaction fetching to use a pers...\n",
       "10        10  net: don't wait if changing the network state ...\n",
       "11        11  create_tx: fix unblinded value and improve ran...\n",
       "...      ...                                                ...\n",
       "15624  15626           navigator: reduce stack size by 50 bytes\n",
       "15625  15627    mc_att_control: reduce stack mildly by 50 bytes\n",
       "15626  15628           sensors: reduce stack mildly by 50 bytes\n",
       "15627  15629  ardrone interface: reduce stack size  conflict...\n",
       "15628  15630  mpu6k: use usleep where usleep should be used ...\n",
       "\n",
       "[4810 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your DataFrame containing the idx column\n",
    "df_new = pd.read_csv('/home/akazad/Downloads/out.csv')\n",
    "\n",
    "# Assuming 'filtered_df' is already defined and loaded, and both DataFrames have the 'idx' column\n",
    "if 'idx' in df_new.columns and 'idx' in filtered_df.columns:\n",
    "    # Create a set of idx values from df_new for faster membership testing\n",
    "    idx_set = set(df_new['idx'])\n",
    "\n",
    "    # Filter filtered_df by checking if each idx is in the set of idx from df_new\n",
    "    filtered_result_df = filtered_df[filtered_df['idx'].isin(idx_set)]\n",
    "\n",
    "    # Display or analyze the filtered result\n",
    "    #print(filtered_result_df)\n",
    "else:\n",
    "    print(\"Ensure both 'df_new' and 'filtered_df' have an 'idx' column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx               33\n",
       "commit_message    33\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_result_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idx               100\n",
       "commit_message    100\n",
       "pred_m            100\n",
       "pred_roberta      100\n",
       "color               0\n",
       "Unnamed: 5          9\n",
       "Unnamed: 6          0\n",
       "Unnamed: 7          4\n",
       "Unnamed: 8          4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 randomly selected lines have been saved to:\n",
      "JSONL file: sampled_output_file.jsonl\n",
      "CSV file: sampled_output_file.csv\n"
     ]
    }
   ],
   "source": [
    "# Sample 200 random lines from the DataFrame\n",
    "sampled_df = filtered_df.sample(n=300, random_state=1)  # random_state for reproducibility\n",
    "\n",
    "# Paths to the output files\n",
    "output_jsonl_path = 'sampled_output_file.jsonl'\n",
    "output_csv_path = 'sampled_output_file.csv'\n",
    "\n",
    "# Write the sampled DataFrame to a new .jsonl file\n",
    "sampled_df.to_json(output_jsonl_path, orient='records', lines=True)\n",
    "\n",
    "# Write the sampled DataFrame to a new CSV file\n",
    "sampled_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(\"200 randomly selected lines have been saved to:\")\n",
    "print(\"JSONL file:\", output_jsonl_path)\n",
    "print(\"CSV file:\", output_csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
