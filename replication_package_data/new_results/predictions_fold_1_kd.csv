commit_message,True Labels,Predicted Labels
fix for removing unnecessary cpu usage by infinite loop,1,1
"don't use -dbcache for bdb anymore -dbcache was originally used to set the maximum buffer size in the bdb environment, and was later changed to set the chainstate cache and leveldb caches. no need to use it for bdb now that only the wallet remains there. this should reduce memory allocation (but not necessarily memory usage) a bit.",1,1
"drop vaddrtosend after sending big addr message we send a newly-accepted peer a 1000-entry addr message, and then only use vaddrtosend for small messages. deallocate vaddrtosend after it's been used for the big message to save about 40 kb per connected inbound peer.",1,1
mdev-19586: remove unnecessary iteration recv_apply_hashed_log_recs(): refer directly to recs.last->end_lsn instead of iterating the entire list starting from recs.log.,1,1
* sort draw calls with the new forcefield shader to reduce shader binds.,1,1
[libfuzzer] try to use less ram while processing the initial corpus llvm-svn: 310881,1,1
improve offset calculation of pgraph tile and zcomp registers,1,1
switch to using a bitwise and instead of modulus. llvm-svn: 39038,1,1
teach allocbox_to_stack that init_existential and destroy_addr don't inherently keep a stack object alive. this allows it to remove 50 more stack allocations from the stdlib. swift svn r9307,1,1
"x86: avoid redundant loop in io_apic_level_ack_pending() if one can find an ack pending pin, there is no need to check the rest of them. signed-off-by: akinobu mita <akinobu.mita@gmail.com> signed-off-by: ingo molnar <mingo@elte.hu>",1,1
move function call out of hot loop,1,1
reduce memory usage in case we read a lot of auth replies at once. --hg-- branch : head,1,1
only calculate expected_time for stage 2 ram_save_remaining() is an expensive operation when there is a lot of memory. so we only call the function when we need it. signed-off-by: juan quintela <quintela@redhat.com>,1,1
replace a loop with a constant time check. git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@45875 91177308-0d34-0410-b5e6-96231b3b80d8,1,1
"coinselection prunes extraneous inputs from approximatebestsubset a further pass over the available inputs has been added to approximatebestsubset after a candidate set has been found. it will prune any extraneous inputs in the selected subset, in order to decrease the number of input and the resulting change.",1,1
r600/si: improve vector interpolation prevent loading m0 multiple times. signed-off-by: christian k√∂nig <christian.koenig@amd.com> git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@178023 91177308-0d34-0410-b5e6-96231b3b80d8,1,1
bulletproofs: shave off a lot of scalar muls from the g/h construction,1,1
avoid unnecessary strlen(3) calls when parsing configuration.,1,1
"eliminate unnecessary call to checkblock processnewblock would return failure early if checkblock failed, before calling acceptblock. acceptblock also calls checkblock, and upon failure would update mapblockindex to indicate that a block was failed. by returning early in processnewblock, we were not marking blocks that fail a check in checkblock as permanently failed, and thus would continue to re-request and reprocess them.",1,1
err reporting: reserve memory to reduce useless memory reallocations,1,1
cxx-992 rewrite bsoncxx::document::view::find() to avoid string allocation,1,1
"capture player by reference in comestible inventory lambdas (#26272) the lambdas for determining calories and joy for the player in the
comestible menu were capturing a copy of the player. with the
current map memory bugs, this meant a potentially very large object was
being copied several times, every time the comestible menu was
displayed, leading to a large delay.",1,1
avoid repeated function calls and cache the result instead,1,1
replace the 1ms delay for 2 nops to get a 100ns delay. #259,1,1
output movie file in a binary format to reduce the size of output,1,1
remove 6x9 font in dogm_lcd_implementation.h by using standard font and shifting down temperature displays by one pixel saves 2300 bytes.,1,1
libtaskmanager: use qbav more to reduce allocations.,1,1
avoid unnecessary conversion from 32bit int to 64bit unsigned int,1,1
"numa: move large array from stack to _initdata section * move large array ""struct bootnode nodes"" from stack to _initdata section to reduce amount of stack space required. cc: h. peter anvin <hpa@zytor.com> signed-off-by: mike travis <travis@sgi.com> signed-off-by: ingo molnar <mingo@elte.hu>",1,1
"pci: utilize calculated results when detecting msi features in msi_capability_init, we can make use of the calculated results instead of calling is_mask_bit_support and is_64bit_address twice. signed-off-by: jike song <albcamus@gmail.com> signed-off-by: jesse barnes <jbarnes@virtuousgeek.org>",1,1
reduce model loading time (#43) * use buffering * use vector * minor --------- co-authored-by: georgi gerganov <ggerganov@gmail.com>,1,1
switch from an o(n) method to an o(1) method for changing non-constant operands. llvm-svn: 55127,1,1
don't recalculate the size of the vector each time through the loop. llvm-svn: 150436,1,1
use variable type for index into mnemonic table. shrinks size of index field on in tree targets. saving static data space. llvm-svn: 164108,1,1
"make broken_col_range() take log(n) time, by using binary search.",1,1
"tsbp: avoid re-reading file portions when loading segments we read a chunk of the file when looking for program headers, so if loading a segment that's (all or partially) within that chunk, copy from the chunk rather than re-reading the same portion of the file.",1,1
ocfs2: don't populate uptodate cache in ocfs2_force_read_journal() this greatly reduces the amount of memory useded during recovery. signed-off-by: mark fasheh <mark.fasheh@oracle.com>,1,1
"numa: move large array from stack to _initdata section * move large array ""struct bootnode nodes"" from stack to _initdata section to reduce amount of stack space required. cc: h. peter anvin <hpa@zytor.com> signed-off-by: mike travis <travis@sgi.com> signed-off-by: ingo molnar <mingo@elte.hu>",1,1
update ewma.cpp saves one multiplication operation per call.,1,1
hal_vrbrain: reduce the number of times we split up uart reads and writes,1,1
switching to o(n) duplicate counting using unordered_set. change: 116831946,1,1
use std::move to avoid allocations. piperorigin-revid: 160354628,1,1
improve 'current cache' eliminates possibility of randomly getting a crappy bilinear frame when the amaze version has already been cached,1,1
change the boolarray member to a function's parameter to reduce the data copy's cost,1,1
"shrink the builtinid down by 3 bits, allowing all the bitfields to fit in 32-bits, shrinking identifierinfo by a word. this shrinks the total size of the identifier pool from 1817264 to 1634428 bytes (11%) on carbon.h. git-svn-id: https://llvm.org/svn/llvm-project/cfe/trunk@42719 91177308-0d34-0410-b5e6-96231b3b80d8",1,1
bench: prevent thread oversubscription this change decreases the variance of benchmark results.,1,1
comment three test vectors in sort_test.cc since they take much time,1,1
obj: fix degrading runs for certain edge cases for very large allocation classes the run degrading algorithm didn't work properly. this was caused by a number of blocks per chunk being smaller than the max allowed blocks per allocation.,1,0
switch to using xinternatoms for caching the atom numbers. saves a pile of function calls and server roundtrips. ok okan@,1,1
optmize .dic parsing a little bit. now there are less temporaries when calling to_title() when parsing dic.,1,1
now we use ngx_log_debugn macros to emit debugging outputs instead of info level error logging because the latter is costy in production.,1,1
"try razoring only for depth > oneply because razoring verification after qsearch() cuts more then 40% of candidates, do not waste a costly qsearch for nodes at depth one that will be probably discarded anyway by futility. also tight razoring conditions to keep dangerous false negatives below 0,05%. still not clear if it is enough. signed-off-by: marco costalba <mcostalba@gmail.com>",1,1
don't calculate a new transition if the new track is not fully loaded. this avoids usless calculations with mixed data from the old and the new track.,1,1
fixup: cpu: x64: gemm: reduce number of tasks spawned for threadpool,1,1
"gpu: jit: ir: avoid unnecessary masking in send_plan_t transforms masking expressions from x = (base + s_i * v_i + s_j * v_j) * c / block a <= x < b to x = (base + s_i * v_i + s_j * v_j) * c / (block * gcd(c, a, b)) a/gcd(c, a, b) <= x < b/gcd(c, a, b)",1,1
"[shared/curve_view] only redraw labels if banner has changed this prevents the bottom of the screen from blinking when the cursor is moved on a fixed screen, which slowed down navigation.",1,1
lower used memory footprint by change stringstream to snprintf,1,1
"reduced excessive io stack size (had 4k, is using 0.7k, has now 2k)",1,1
paralellize the mode sum computation for the waveform better by fusing the two nested loops,1,1
disable usage of sse3 haddpd that is extremely slow.,1,1
usbfs micro optimitation the memory barrier is needed only with smp. signed-off-by: oliver neukum <oneukum@suse.de> signed-off-by: greg kroah-hartman <gregkh@suse.de>,1,1
use apint::getonebitset instead of apint::getbitsset for sign bit mask creation avoids all the unnecessary extra bitrange creation/shift stages. llvm-svn: 296871,1,1
use iterative do-while loop instead of recursive dfspass calls to reduce amount of stack space used at runtime. llvm-svn: 30167,1,1
qemu-common.h: optimise muldiv64 if int128 is available let compiler do the job to optimise the function. signed-off-by: frediano ziglio <frediano.ziglio@huawei.com> signed-off-by: paolo bonzini <pbonzini@redhat.com> signed-off-by: frediano ziglio <freddy77@gmail.com>,1,1
"fold arrays down to a single element. this causes huge wins on some benchmarks for example: 197.parser (64m->14m), 164.gzip (14m->2.7m). the actual graphs represented should not change at all. git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@4643 91177308-0d34-0410-b5e6-96231b3b80d8",1,1
"make gvn be more intelligent about redundant load elimination: when finding dependent load/stores, realize that they are the same if aliasing claims must alias instead of relying on the pointers to be exactly equal. this makes load elimination more aggressive. for example, on 403.gcc, we had: < 68 gvn - number of instructions pre'd < 152718 gvn - number of instructions deleted < 49699 gvn - number of loads deleted < 6153 memdep - number of dirty cached non-local responses < 169336 memdep - number of fully cached non-local responses < 162428 memdep - number of uncached non-local responses now we have: > 64 gvn - number of instructions pre'd > 153623 gvn - number of instructions deleted > 49856 gvn - number of loads deleted > 5022 memdep - number of dirty cached non-local responses > 159030 memdep - number of fully cached non-local responses > 162443 memdep - number of uncached non-local responses that's an extra 157 loads deleted and extra 905 other instructions nuked. this slows down gvn very slightly, from 3.91 to 3.96s. git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@60314 91177308-0d34-0410-b5e6-96231b3b80d8",1,1
modify the query using bidding tokenizer for sponsored search before doing the fuzzy search to reduce the search time,1,1
hal_avr: reduce the latency of semaphore waits this reduces the average cost of waiting for the mpu6000 semaphore from the main loop,1,1
"enh: make sure the error is printed once, otherwise the otput slows down the execution of the filter too much git-svn-id: http://svn.slicer.org/slicer4/trunk@21759 3bd1e089-480b-0410-8dfb-8563597acbee",1,1
"fix for bug 74328, removing o(n^2) algorithm from contentappended. this saves time on big pages. r=waterson sr=jst",1,1
"softmax: move the hls pipeline command into the outer loop i ran into a few issues with pipeline in the inner loop. basically, i could not meet timing for the device i was simulating (xc7z020clg484-1) for the keras_3layer example, and the critical path traced back to the exp_diff_res lookup and accumulate. with some empiprical testing, i found moving hls pipeline to the outer loop gets much better results: 1. timing improved from a min of 6.6 ns to 4.32 2. latency reduced in the softmax from 106 to 70 (likely driven by size of the softmax input) 3. other resource usage stayed pretty similar. a big bigger in softmax, but ok overall this should only impact serial mode",1,1
improve processing time to read camconst.json by almost factor 2. additionally make it future-proof by reducing o(n¬≤) copying amount in reallocate phase to o(n),1,1
"[constraint solver] replace a use of simplifytype() with getfixedtyperecursive() the latter is cheaper to compute, and suitable for the is-it-a-metatype check.",1,1
tst_qmouseevent_modal: replace some qwait with qtry_verify. takes the total time for this test from ~1.2 seconds to ~0.42 seconds for me. change-id: i426e600a7afe01d7343108b432eda8b83d6f3d85 reviewed-by: joerg bornemann <joerg.bornemann@digia.com>,1,1
*some optimisation in unit::hasnegativeaurawithinterruptflag. --hg-- branch : trunk,1,1
"in constantarray::getasstring(), we know the size of the resultant string in advance so we can pre-allocate it and just fill in the entries. this improves the time for the asmprinter on instructioncombining.cpp from 0.4248s to 0.3370s. git-svn-id: https://llvm.org/svn/llvm-project/llvm/trunk@52690 91177308-0d34-0410-b5e6-96231b3b80d8",1,1
hid: use single threaded work queue for hid_compat use single threaded work queue for hid_compat i doubt hid really needs to scale over multiple cpus. so only use a single threaded workqueue for hid_compat. this avoids some excessive thread use on systems with a larger number of cpus. signed-off-by: andi kleen <ak@linux.intel.com> signed-off-by: jiri kosina <jkosina@suse.cz>,1,1
"improve 'match similar lines' (related to the issue #1013 vertical shifting needed when some lines do not match) (2) - reduce the execution time of the getmatchcost() function - remove the 15-line limit for a single diff block, and instead make the limit to 4096 characters per diff block",1,1
"microblaze: improve src microblaze carry is mirrored in msr[31], pick it directly from there. also, no need to mask cpu_r[dc->ra] when calling write_carry. 15% improvement in linux-user src loops. signed-off-by: edgar e. iglesias <edgar.iglesias@gmail.com>",1,1
some speed for the gradient mask calculation,1,1
use memset for addr_cache initialization - slightly quicker startup,1,1
"fix(visrawreader): clear the page cache as well as the memory map if this is not done, the file will still remain in memory, potentially slowing down other operations which need to acquire memory.",1,1
reduced loading time of qualityelevation layer dramatically,1,1
paralellize the mode sum computation for the waveform better by fusing the two nested loops,1,1
add a bit of lazy evaluation to populatecompilationgraph(). only the tools that are mentioned in the compilation graph definition are now inserted by populatecompilationgraph(). this should cut down plugin loading time a little. llvm-svn: 59097,1,1
"a densemap of a std::map isn't a very good idea because the ""grow()"" method will need to make a deep copy of each of the std::maps. use a std::map of the std::map instead. this improves the compile time of sqlite3 by ~2%. llvm-svn: 148003",1,1
fixed textlistcomponent marquee running at 2x speed. adjusted marquee constants.,1,1
"[x86] avoid unnecessary shuffle mask math in combinex86shufflesrecursively() this is a follow-up to https://reviews.llvm.org/d34174 / https://reviews.llvm.org/rl305398. we mentioned replacing the multiplies with shifts, but the real win seems to be in bypassing the extra ops in the common case when the rootratio and opratio are one. this gives us another 1-2% overall win for the test in pr32037: https://bugs.llvm.org/show_bug.cgi?id=32037 llvm-svn: 305414",1,1
removed reinit of macrocell. lda stiffness matrix construction got sped up by 12.5 times for n2 molecule,1,1
avoid running queries for views when fuzzing (#6859) this gives a 10x execution speed boost to the config fuzzer.,1,1
disable usage of sse3 haddpd that is extremely slow.,1,1
nfs: reduce latency by using conditional rescheduling in nfs_scan_list signed-off-by: trond myklebust <trond.myklebust@netapp.com>,1,1
fix major slowdown as draw definitions accumulate --hg-- branch : sceneoverhaul,1,1
[unroll] use a small set to de-duplicate operands prior to putting them into the worklist. this avoids allocating lots of worklist memory for them when there are large numbers of repeated operands. llvm-svn: 229052,1,1
refactor eosio_exit for WAVM; improve long running performance  WAVM becomes increasingly slow as more and more contracts are activated. The ultimate reason is due to high exception overhead from eosio_exit. I believe this steams from the huge number of memory mappings and interaction with the unwinder. Refactor eosio_exit implementation on WAVM to not use exceptions and instead longjmp out of the running wasm code.,1,1
More face detection refinements. Note massive performance improvements in release builds (~20fps) vs. debug (~4fps).,1,1
take work out of d3 ticker loop to improve performance,1,1
rewrite code of on_response_writable to be simpler/more efficient,1,1
More efficient GraphBuilder - probably should be in another branch...,1,1
Extension performance improvement  * Introduced Git repo stat TTL. This helps to avoid unnecessary fetch   requests to remote repository * Configuration file restructured. It's easier to have mapping for file   name in Git repository on resource rather then vise versa,1,1
"sync: don't block the flusher thread waiting on IO  When sync does it's WB_SYNC_ALL writeback, it issues data Io and then immediately waits for IO completion. This is done in the context of the flusher thread, and hence completely ties up the flusher thread for the backing device until all the dirty inodes have been synced. On filesystems that are dirtying inodes constantly and quickly, this means the flusher thread can be tied up for minutes per sync call and hence badly affect system level write IO performance as the page cache cannot be cleaned quickly.  We already have a wait loop for IO completion for sync(2), so cut this out of the flusher thread and delegate it to wait_sb_inodes(). Hence we can do rapid IO submission, and then wait for it all to complete.  Effect of sync on fsmark before the patch:  FSUse%        Count         Size    Files/sec     App Overhead .....      0       640000         4096      35154.6          1026984      0       720000         4096      36740.3          1023844      0       800000         4096      36184.6           916599      0       880000         4096       1282.7          1054367      0       960000         4096       3951.3           918773      0      1040000         4096      40646.2           996448      0      1120000         4096      43610.1           895647      0      1200000         4096      40333.1           921048  And a single sync pass took:    real    0m52.407s   user    0m0.000s   sys     0m0.090s  After the patch, there is no impact on fsmark results, and each individual sync(2) operation run concurrently with the same fsmark workload takes roughly 7s:    real    0m6.930s   user    0m0.000s   sys     0m0.039s  IOWs, sync is 7-8x faster on a busy filesystem and does not have an adverse impact on ongoing async data write operations.",1,1
Performance Fixes  More query performance fixes for txid,1,1
"mm: hugetlbfs: fix hugetlbfs optimization  commit 27c73ae759774e63313c1fbfeb17ba076cea64c5 upstream.  Commit 7cb2ef56e6a8 (""mm: fix aio performance regression for database caused by THP"") can cause dereference of a dangling pointer if split_huge_page runs during PageHuge() if there are updates to the tail_page->private field.  Also it is repeating compound_head twice for hugetlbfs and it is running compound_head+compound_trans_head for THP when a single one is needed in both cases.  The new code within the PageSlab() check doesn't need to verify that the THP page size is never bigger than the smallest hugetlbfs page size, to avoid memory corruption.  A longstanding theoretical race condition was found while fixing the above (see the change right after the skip_unlock label, that is relevant for the compound_lock path too).  By re-establishing the _mapcount tail refcounting for all compound pages, this also fixes the below problem:    echo 0 >/sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages    BUG: Bad page state in process bash  pfn:59a01   page:ffffea000139b038 count:0 mapcount:10 mapping:          (null) index:0x0   page flags: 0x1c00000000008000(tail)   Modules linked in:   CPU: 6 PID: 2018 Comm: bash Not tainted 3.12.0+ #25   Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011   Call Trace:     dump_stack+0x55/0x76     bad_page+0xd5/0x130     free_pages_prepare+0x213/0x280     __free_pages+0x36/0x80     update_and_free_page+0xc1/0xd0     free_pool_huge_page+0xc2/0xe0     set_max_huge_pages.part.58+0x14c/0x220     nr_hugepages_store_common.isra.60+0xd0/0xf0     nr_hugepages_store+0x13/0x20     kobj_attr_store+0xf/0x20     sysfs_write_file+0x189/0x1e0     vfs_write+0xc5/0x1f0     SyS_write+0x55/0xb0     system_call_fastpath+0x16/0x1b",1,0
Improving performance of ConversionResult usages of orThrow with String.format,1,1
2006-11-25  Roman Kennke  [URL]>  	* javax/swing/text/GapContent.java 	(getPositionsInRange): Rewritten to use the more efficient 	binary search searchFirst() and avoid an NPE that was caused 	by GC'ed positions.,1,1
[CHG] improve performance when previewing partner and solve some deprecated methods uses,1,1
"Add prefetch option for queries, which defaults to false for inserts (#6077)  ## What is the goal of this PR?    On executing a Graql query, Grakn automatically streams the first batch of responses back to the client. This ensures they get their answers to a `match` query as fast as possible. But, for an `insert` query, they usually don't need those answers. And the CPU cost of compiling these unwanted response messages was inflicting a significant performance penalty. To remedy this, we made `prefetch` a configurable per-query option, which defaults to true, except for Insert queries where it defaults to false.    ## What are the changes implemented in this PR?    - Don't prefetch responses to Insert queries unless specified with a configurable flag in QueryOptions (fixes [URL]/graknlabs/grakn/issues/6072)",1,1
"Refine stack op to improve xlnet performance, test=develop (#22142)  stack's wait cost a lot of cpu time, use cuda kernel to do memory copy  will reduce cpu time.",1,1
"[PATCH] USER-DPD: performance optimizations to ssa_update() in
 fix_shardlow Overall improvements range from 2% to 18% on our benchmarks 1)
 Newton has to be turned on for SSA, so remove those conditionals 2) Rework
 the math in ssa_update() to eliminate many ops and temporaries 3) Split
 ssa_update() into two versions, based on DPD vs. DPDE 4) Reorder code in
 ssa_update_*() to reduce register pressure",1,1
"f2fs: improve write performance under frequent fsync calls  When considering a bunch of data writes with very frequent fsync calls, we are able to think the following performance regression.  N: Node IO, D: Data IO, IO scheduler: cfq  Issue    pending IOs 	 D1 D2 D3 D4  D1         D2 D3 D4 N1  D2            D3 D4 N1 N2  N1            D3 D4 N2 D1  --> N1 can be selected by cfq becase of the same priority of N and D.      Then D3 and D4 would be delayed, resuling in performance degradation.  So, when processing the fsync call, it'd better give higher priority to data IOs than node IOs by assigning WRITE and WRITE_SYNC respectively. This patch improves the random wirte performance with frequent fsync calls by up to 10%.",1,1
Optimized new CC box performance Fixed: removed duplicate entries when performing code-complete,1,1
"CCPR: Transform path points before parsing  Transforms a path's points into a local buffer up front, rather than transforming as we parse. This hopefully gets better vector performance as well as allowing us to skip the transformation step for paths that are known to be in device space already.  Introduces a test for parsing empty paths and does general cleanup.  Bug: skia:7190",1,1
Split up tasks across cores more efficiently,1,1
crypto: msm: Update clock vote for improved performance,1,1
"Some twiks  EstimateA_L1_logistic - corrected NaN issues when lambda=x=0 on some components GetStat - removed ""throw away stats with low amount of measurement heuristic"". There seem to be no affect construct_bal_weights - modified script to remove ""unobserved neurons"", and make network with circular boundary conditions construct_block_weights_lognormal.m - added a function that generarte blocks from a lognormal distribution. Sometimes this gives better performance",1,1
"Fix a potential performance problem in placing ARM constant pools. In the case where there are no good places to put constants and we fall back upon inserting unconditional branches to make new blocks, allow all constant pool references in range of those blocks to put constants there, even if that means resetting the ""high water marks"" for those references.  This will still terminate because you can't keep splitting blocks forever, and in the bad cases where we have to split blocks, it is important to avoid splitting more than necessary.",1,1
"Ported a patch from the old repository, which improve the suppression on Android, where high gains have been seen in the upper frequency band. Review URL: [URL]/68005",1,0
"[PATCH] Modified nb_accv to improve performance of accumulates to
 processors on the same SMP node.",1,1
ARROW-3321: [C++] Improve integer parsing performance  Before: ``` --------------------------------------------------------------------- Benchmark                              Time           CPU Iterations --------------------------------------------------------------------- BM_IntegerParsing<Int8Type>         1388 ns       1387 ns     502861   5.49911M items/s BM_IntegerParsing<Int16Type>        1475 ns       1475 ns     468724   5.17179M items/s BM_IntegerParsing<Int32Type>        1730 ns       1729 ns     405693   4.41194M items/s BM_IntegerParsing<Int64Type>        2131 ns       2131 ns     328192   3.58034M items/s BM_IntegerParsing<UInt8Type>        1238 ns       1238 ns     572573   6.16483M items/s BM_IntegerParsing<UInt16Type>       1302 ns       1301 ns     537960   5.86206M items/s BM_IntegerParsing<UInt32Type>       1391 ns       1391 ns     502859    5.4857M items/s BM_IntegerParsing<UInt64Type>       1637 ns       1637 ns     427832     4.661M items/s BM_FloatParsing<FloatType>          4437 ns       4436 ns     156887   1.71973M items/s BM_FloatParsing<DoubleType>         4593 ns       4592 ns     152459   1.66129M items/s ```  After: ``` --------------------------------------------------------------------- Benchmark                              Time           CPU Iterations --------------------------------------------------------------------- BM_IntegerParsing<Int8Type>           23 ns         23 ns   29800687   324.788M items/s BM_IntegerParsing<Int16Type>          27 ns         27 ns   26593165   287.438M items/s BM_IntegerParsing<Int32Type>          34 ns         34 ns   20689813   226.211M items/s BM_IntegerParsing<Int64Type>          49 ns         49 ns   14256379   155.424M items/s BM_IntegerParsing<UInt8Type>          17 ns         17 ns   42295211   454.911M items/s BM_IntegerParsing<UInt16Type>         16 ns         16 ns   42663172   464.397M items/s BM_IntegerParsing<UInt32Type>         21 ns         21 ns   33372432   363.209M items/s BM_IntegerParsing<UInt64Type>         33 ns         33 ns   21502295   234.255M items/s BM_FloatParsing<FloatType>          4554 ns       4553 ns     153207   1.67565M items/s BM_FloatParsing<DoubleType>         4579 ns       4578 ns     152304   1.66651M items/s ```  Author: Antoine Pitrou [URL]>  Closes #2619 from pitrou/ARROW-3321-faster-int-conversion and squashes the following commits:  9834b28e6 <Antoine Pitrou> ARROW-3321:  Improve integer parsing performance,1,1
"Make THaVarList a THashList instead of a TList for better performance.  (Almost) everything just happens automagically as we inherit from THashList instead of TList. THaVarList::Find(const char* name) automatically makes hash table lookups, vastly improving the search speed if a large number of global variables is defined.  Also, make THaVarList the owner of its objects, so as the list is deleted, so are all of its elements. This was already the previous behavior; this just eliminates duplicate code.  Closes #27.",1,1
"lowmemorykiller: adapt to vmpressure  There were issues reported, where page cache thrashing was observed because of LMK not killing tasks when required, resulting in sluggishness and higher app launch latency. LMK does not kill a task for the following reasons. 1. The free and file pages are above the LMK thresholds 2. LMK tries to pick task with an adj level corresponding to current thresholds, but fails to do so because of the absence of tasks in that level. But sometimes it is better to kill a lower adj task, than thrashing. And there are cases where the number of file pages are huge, though we dont thrash, the reclaim process becomes time consuming, since LMK triggers will be delayed because of higher number of file pages. Even in such cases, when reclaim path finds it difficult to reclaim pages, it is better to trigger lmk to free up some memory faster.  The basic idea here is to make LMK more aggressive dynamically when such a thrashing scenario is detected.  To detect thrashing, this patch uses vmpressure events. The values of vmpressure upon which an action has to be taken, was derived empirically.  This patch also adds tracepoints to validate this feature, almk_shrink and almk_vmpressure.  Two knobs are available for the user to tune adaptive lmk behaviour.  /sys/module/lowmemorykiller/parameters/adaptive_lmk - Write 1 to enable the feature, 0 to disable. By default disabled.  /sys/module/lowmemorykiller/parameters/vmpressure_file_min - This parameter controls the behaviour of LMK when vmpressure is in the range of 90-94. Adaptive lmk triggers based on number file pages wrt vmpressure_file_min, when vmpressure is in the range of 90-94. Usually this is a pseudo minfree value, higher than the highest configured value in minfree array.",1,1
"mutex: Queue mutex spinners with MCS lock to reduce cacheline contention  The current mutex spinning code (with MUTEX_SPIN_ON_OWNER option turned on) allow multiple tasks to spin on a single mutex concurrently. A potential problem with the current approach is that when the mutex becomes available, all the spinning tasks will try to acquire the mutex more or less simultaneously. As a result, there will be a lot of cacheline bouncing especially on systems with a large number of CPUs.  This patch tries to reduce this kind of contention by putting the mutex spinners into a queue so that only the first one in the queue will try to acquire the mutex. This will reduce contention and allow all the tasks to move forward faster.  The queuing of mutex spinners is done using an MCS lock based implementation which will further reduce contention on the mutex cacheline than a similar ticket spinlock based implementation. This patch will add a new field into the mutex data structure for holding the MCS lock. This expands the mutex size by 8 bytes for 64-bit system and 4 bytes for 32-bit system. This overhead will be avoid if the MUTEX_SPIN_ON_OWNER option is turned off.  The following table shows the jobs per minute (JPM) scalability data on an 8-node 80-core Westmere box with a 3.7.10 kernel. The numactl command is used to restrict the running of the fserver workloads to 1/2/4/8 nodes with hyperthreading off.  +-----------------+-----------+-----------+-------------+----------+ |  Configuration  | Mean JPM  | Mean JPM  |  Mean JPM   | % Change | |                 | w/o patch | patch 1   | patches 1&2 |  1->1&2  | +-----------------+------------------------------------------------+ |                 |              User Range 1100 - 2000            | +-----------------+------------------------------------------------+ | 8 nodes, HT off |  227972   |  227237   |   305043    |  +34.2%  | | 4 nodes, HT off |  393503   |  381558   |   394650    |   +3.4%  | | 2 nodes, HT off |  334957   |  325240   |   338853    |   +4.2%  | | 1 node , HT off |  198141   |  197972   |   198075    |   +0.1%  | +-----------------+------------------------------------------------+ |                 |              User Range 200 - 1000             | +-----------------+------------------------------------------------+ | 8 nodes, HT off |  282325   |  312870   |   332185    |   +6.2%  | | 4 nodes, HT off |  390698   |  378279   |   393419    |   +4.0%  | | 2 nodes, HT off |  336986   |  326543   |   340260    |   +4.2%  | | 1 node , HT off |  197588   |  197622   |   197582    |    0.0%  | +-----------------+-----------+-----------+-------------+----------+  At low user range 10-100, the JPM differences were within +/-1%. So they are not that interesting.  The fserver workload uses mutex spinning extensively. With just the mutex change in the first patch, there is no noticeable change in performance.  Rather, there is a slight drop in performance. This mutex spinning patch more than recovers the lost performance and show a significant increase of +30% at high user load with the full 8 nodes. Similar improvements were also seen in a 3.8 kernel.  The table below shows the %time spent by different kernel functions as reported by perf when running the fserver workload at 1500 users with all 8 nodes.  +-----------------------+-----------+---------+-------------+ |        Function       |  % time   | % time  |   % time    | |                       | w/o patch | patch 1 | patches 1&2 | +-----------------------+-----------+---------+-------------+ | __read_lock_failed    |  34.96%   | 34.91%  |   29.14%    | | __write_lock_failed   |  10.14%   | 10.68%  |    7.51%    | | mutex_spin_on_owner   |   3.62%   |  3.42%  |    2.33%    | | mspin_lock            |    N/A    |   N/A   |    9.90%    | | __mutex_lock_slowpath |   1.46%   |  0.81%  |    0.14%    | | _raw_spin_lock        |   2.25%   |  2.50%  |    1.10%    | +-----------------------+-----------+---------+-------------+  The fserver workload for an 8-node system is dominated by the contention in the read/write lock. Mutex contention also plays a role. With the first patch only, mutex contention is down (as shown by the __mutex_lock_slowpath figure) which help a little bit. We saw only a few percents improvement with that.  By applying patch 2 as well, the single mutex_spin_on_owner figure is now split out into an additional mspin_lock figure. The time increases from 3.42% to 11.23%. It shows a great reduction in contention among the spinners leading to a 30% improvement. The time ratio 9.9/2.33=4.3 indicates that there are on average 4+ spinners waiting in the spin_lock loop for each spinner in the mutex_spin_on_owner loop. Contention in other locking functions also go down by quite a lot.  The table below shows the performance change of both patches 1 & 2 over patch 1 alone in other AIM7 workloads (at 8 nodes, hyperthreading off).  +--------------+---------------+----------------+-----------------+ |   Workload   | mean % change | mean % change  | mean % change   | |              | 10-100 users  | 200-1000 users | 1100-2000 users | +--------------+---------------+----------------+-----------------+ | alltests     |      0.0%     |     -0.8%      |     +0.6%       | | five_sec     |     -0.3%     |     +0.8%      |     +0.8%       | | high_systime |     +0.4%     |     +2.4%      |     +2.1%       | | new_fserver  |     +0.1%     |    +14.1%      |    +34.2%       | | shared       |     -0.5%     |     -0.3%      |     -0.4%       | | short        |     -1.7%     |     -9.8%      |     -8.3%       | +--------------+---------------+----------------+-----------------+  The short workload is the only one that shows a decline in performance probably due to the spinner locking and queuing overhead.  [myfluxi: On our 3.4 base, this patch series gives another reproducable 3.5% advantage compared to commit a84eb3bd6fee57881e9405f6b1e2c91e2e88c5e0, which is significantly above the +- 1-2% standard variation.   Performance counter stats for 'hackbench 10  ' (10 runs):         2885.888073 task-clock                #    3.565 CPUs utilized  ( +-  0.75% )              16429 context-switches          #    0.006 M/sec  ( +-  7.47% )               4234 CPU-migrations            #    0.001 M/sec  ( +- 11.08% )              21541 page-faults               #    0.007 M/sec  ( +-  0.02% )         5959743473 cycles                    #    2.065 GHz  ( +-  0.70% ) [85.81%]                  0 stalled-cycles-frontend   #    0.00% frontend cycles idle  ( +-  0.00% ) [86.55%]                  0 stalled-cycles-backend    #    0.00% backend  cycles idle  ( +-  0.00% ) [88.53%]         2018815336 instructions              #    0.34  insns per cycle  ( +-  0.57% ) [88.31%]          195542833 branches                  #   67.968 M/sec  ( +-  0.80% ) [89.30%]            4178524 branch-misses             #    2.14% of all branches  ( +-  2.39% ) [76.06%]         0.807441968 seconds time elapsed  ( +-  1.86% )]",1,1
"Change in_tag_browser generation to not build the list of books if the tag browser categories haven't been restricted by 'find'. As the comment in the code says, this will improve performance while making in_tag_browser:true fail in extremely rare cases.",1,1
"[PATCH] Modified locate region to use more efficient algorithms for
 most block-cyclic distributions.",1,1
IPDatabase uses more efficient unordered_map instead,1,1
"[PATCH] Check in changes to improve performance for nb_puts and
 nb_gets on GPU-hosted global arrays.",1,1
"PR#5201: ocamlbuild: add --norc to the bash invocation to help Windows performances  This change was recommend by daweil on the bugtracker. According to the Bash documentation, the option -c that is already passed by ocamlbuild should already imply --norc, but daweil reported a 30% performance speedup with this change anyway. I'm a bit surprised, but this cannot hurt...",1,1
"Build support libs with AAPT2  Use AAPT2 to build the framework support libraries. Apps built with AAPT2 can more efficiently link against these libraries by specifying their module name in LOCAL_STATIC_ANDROID_LIBRARIES.  Ex:  LOCAL_STATIC_ANDROID_LIBRARIES := android-support-v7-appcompat android-support-v4  Apps built with AAPT2 do not need to specify --auto-add-overlay or --extra-packages, as these are automatically added as needed by the build system.  This change will not affect any apps that currently depend on the support libraries. This is because they import the resources directly.  We use LOCAL_JAR_EXCLUDE_FILES := none only to support javac when building javadoc. Jack builds are correct because the build system passes in the latest generated R.java ahead of any previous ones packaged in classes.jack. This means we can dynamically reference a support lib module, correctly seeing non-final R.java. Then at app package time, we only include the final R.java generated by the AAPT2 packaging step.  Bug:25958912",1,0
improves SM cascade performances and fixes announcement text (#67240)  Changes the cascade walls from turfs to objects to improve the performances of the roundending cascade.  The issue was that ChangeTurf() was a pretty expensive proc to be called that many times so i moved the cascade wall into an object. It doesn't delete anything other than living mobs and the portal to prevent edge case runtimes.  Plus remove a span_bold() from the announcement text since it wasn't making the text bold but was leaving behind,1,1
Use zuul-cloner instead of git clone  Use zuul-cloner for more efficient cloning because it can take advantage of the local git cache on disk,1,1
ENH: hugely improve performance of to_datetime on ISO8601 data #1571,1,1
Wrapped tight loop in a transaction to dramatically improve performance,1,1
"Correctly iterate over all SSA functions  Include methods and anonymous functions, and do it more efficiently.",1,1
Moved some things around in the crawler for slightly better performance,1,1
Added more efficient constructor to array-based sets,1,1
"core: Remove member init in business entities  Since the upgrade to GWT 2.5.1, we've seen several cases of GWT pruning member initialization.  To prevent these (and future) bugs, this series of patches removes all such initializations from the packages that should be compiled by GWT. These initialization are either moved to the appropriate constructor(s), or removed them completely if they are redundant. Constants with the wrong modifiers are amended to have static final, and are allowed to be initialized directly.  As a side bonus, this patch offers a minor performance improvement, as some of these members are now only initialized once instead of twice (once in the member initialization and then again via a constructor parameter).  This patch takes care of all the project's business entities, as noted in the subject.",1,1
cmake: set CCACHE_BASEDIR & CCACHE_NOHASHDIR when using ccache  Dramatically improves build performance when building multiple projects in different directories.,1,1
Allocated buffer for first_comment only if needed  Minor performance improvement to reduce the number of calls to malloc(),1,1
Separated all of the filters to make more readable and efficient,1,1
Merge pull request #331 from nicolasmiller/rendering_performance  GUI: patch rendering performance improvements,1,1
Optimized detail query flow and cleanup (#691)  * Optimizing detail query    * Optimizing detail query flow    * Optimizing detail query flow    * Optimized raw detail query to improve push up performance.    * Fixed bugs    * reverted wrong check in    * Rebased the code    * Removed aggregation from core    * Refactored core package and fixed test cases    * Fixed bugs    * Fixed review comments and deleted aggregate classes after merge from master    * Removed unused code    * Optimized scanner flow    * Optimized scanner flow    * Optimized scanning flow    * Optimized scanner flow    * Refactored code    * Refactored code    * Removed unused code    * Reverted unnecessary comment    * Reverted queryinterface package from core    * Removed queryinterface package from core    * Handled review comments    * Handled review comments    * Added assert,1,1
use type_hierarchical_dictionary to store couplings; improved performance of dictionary type,1,1
added a AddRange method to FullyObservableCollection  more efficient collection updating - it only raises 1 event for the whole batch,1,1
RBD: Don't query Ceph on stats for exclusive pools  Collecting stats for provisioned_capacity_gb takes a long time since we have to query each individual image for the provisioned size.  If we are using the pool just for Cinder and/or are willing to accept a potential deviation in Cinder stats we could just not retrieve this information and calculate this based on the DB information for the volumes.  This patch adds configuration option `rbd_exclusive_cinder_pool` that allows us to disable the size collection and thus improve the stats reporting speed.,1,1
Cache the window selector as 'viewport' in an attempt to improve performance.  (imported from commit 3e01382260938737fbee663f6a9e94ad495ef21e),1,1
"perf_counter, x86: make x86_pmu data a static struct  Instead of using a pointer to reference to the x86 pmu we now have one single data structure that is initialized at the beginning. This saves the pointer access when using this memory.  [ Impact: micro-optimization ]",1,1
"Implement flood pruning and make stack state changes more efficient.  If a non-root switch has multiple links towards the root, only propogate floods from the root, from one known good link (otherwise non-root connected hosts might receive more than one copy of a broadcast).  When processing a stack state port change, process all changed ports first before generating new flows to reduce number of flows sent.",1,1
"ARM: 7178/1: fault.c: Port OOM changes into do_page_fault  Commit d065bd810b6deb67d4897a14bfe21f8eb526ba99 (mm: retry page fault when blocking on disk transfer) and commit 37b23e0525d393d48a7d59f870b3bc061a30ccdb (x86,mm: make pagefault killable)  The above commits introduced changes into the x86 pagefault handler for making the page fault handler retryable as well as killable.  These changes reduce the mmap_sem hold time, which is crucial during OOM killer invocation.  Port these changes to ARM.  Without these changes, my ARM board encounters many hang and livelock scenarios. After applying this patch, OOM feature performance improves according to my testing.",1,1
Avoid regex in the common case  Escaped characters in field names are highly unusual. We can quickly test for their presence and if none are found do the path splitting using the more efficient binary module instead of regular expressions. A microbenchmark shows this approach to be a little more than twice as fast as the original.,1,1
4 of 4 commit (sorry my svn clinet is crazy for moment) Commit w3seek patch from bug 1609 : file attachment (id=910)  The attached patch implements QueueUserWorkItem()/RtlQueueWorkItem() (lacks optimizations!!!). WINE's latest rpcrt4 relies on it.  1. Implement QueueUserWorkItem()/RtlQueueWorkItem() : 2. A slightly optimized  3. Supports WT_TRANSFER_IMPERSONATION 4. Slightly improved handling of growing/shrinking the pool by assuming work items with WT_EXECUTELONGFUNCTION run longer 5. Fixes a hack that made a worker thread always terminate if there were at least one more thread available,1,0
"[SYSTEMML-1683] Improved codegen row template (indexing, cbind)  This patch makes two improvements to the code generator row-wise template in order to further reduce the number of intermediates in scripts such as MLogreg as well as minor explain improvements):  (1) Column indexing support w/ unknown indexing expressions.  (2) Fusion of cbind with empty matrix after row-wise template (row aggregates).  (3) Extended explain to show the line numbers (of the original script) for generated operators.  For example, on MLogreg and a dense 100M x 10 scenario, this reduces the buffer pool writes from (76/30/1) to (60/30/1) and execution time from 282s to 256s (compared to the baseline w/ existing fused operators of 529s).   Note that there is substantial additional potential, which can be exploited to reduce the number evictions. However, this will be addressed in separate changes as it requires optimizer changes (e.g., considering multi-aggregates while considering materialization, and materialization points per consumer).",1,1
"[PATCH] Stage bonded kernel atomics through shared memory

Fixes performance bug introduced in 01b2f20bd5 by staging energy step
atomics through shared memory rather than have all threads write
atomically directly to global memory.

Fixes #3443",1,1
"Safari: block programmatic image requests, more thorough XHR  Currently, this is done the same way we block XMLHttpRequests: mess with the constructor. This was done in the most efficient way I could think of (overhead is relatively minimal). This also injects uBlock's blocking interceptor earlier, thusly covering more requests that may have slipped through before.",1,1
"Remove custom batch methods, smarter cholesky inverse, no dtype cast  This PR  1. Removes the custom batch_svd and batch_qr, methods since these are natively supported in pytorch 1.2.0 2. Replaces a `.inverse()` call on a cholesky factor with a triangular solve agaist the identity (using broadcasting across batches). This results in significant speedups for large matrices. 3. Removes casting to double before performing choleksy decompostion and cholesky solve. Profiling reveals that a non-trivial amount of time is being spent on these conversions. I believe these were added for numerical stability in the past, but with the changes to cholesky (both internal and upstream) this may not be an issue anymore.",1,1
Improve material test performance. 18 to 15.3 seconds.,1,1
"Introduce a SEARCH_AFTER index pagination type  Current Paginated interface only allows to restart a query from a given offset. Update it to also allow restarting queries using a searchAfter key. searchAfter can help with performance of queries such as [1] where the visibility is being queried for an account that cannot see most/all changes. [1] finishes in ~45 mins with OFFSET and ~10 mins with SEARCH_AFTER when the site has around 1M abandoned changes.  Index config has been updated to add a paginationType entry with OFFSET and SEARCH_AFTER as supported values. The default is set to OFFSET to keep the current pagination type unchanged.  Gerrit's Lucene index implementation has been updated to support this new pagination type with search-after[2]. Elasticsearch index implementation has also been updated to paginate using search-after[3] and can be further improved to use PIT[4]. Lucene and Elasticsearch tests have been updated to run with both pagination types. Also, Elasticsearch tests now use the official docker image as it can handle running tests with multiple index config suites.  Note that, searchAfter will not impact using offsets in Gerrit query APIs.  [1] gerrit query 'status:abandoned visibleto:guest' [2] [URL]/core/6_6_5/core/org/apache/lucene/search/IndexSearcher.html#search-org.apache.lucene.search.Query-int-org.apache.lucene.search.Sort-boolean-boolean- [3] https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html#search-after [4] https://www.elastic.co/guide/en/elasticsearch/reference/current/point-in-time-api.html  Release-Notes: Index searches now support search-after pagination",1,1
"rcu: Provide OOM handler to motivate lazy RCU callbacks In kernels built with CONFIG_RCU_FAST_NO_HZ=y, CPUs can accumulate a large number of lazy callbacks, which as the name implies will be slow to be invoked.  This can be a problem on small-memory systems, where the default 6-second sleep for CPUs having only lazy RCU callbacks could well be fatal.  This commit therefore installs an OOM hander that ensures that every CPU with lazy callbacks has at least one non-lazy callback, in turn ensuring timely advancement for these callbacks.  Updated to fix bug that disabled OOM killing, noted by Lai Jiangshan.  Updated to push the for_each_rcu_flavor() loop into rcu_oom_notify_cpu(), thus reducing the number of IPIs, as suggested by Steven Rostedt.  Also to make the for_each_online_cpu() loop be preemptible.  (Later, it might be good to use smp_call_function(), as suggested by Peter Zijlstra.)",1,1
ARM: dts: msm: Add default prefetching size for secure playback  Prefetching for heaps designated for secure playback provides a good performance boost. Add the optimized default prefetching size for clients to use.,1,1
"Optimize intersection detection.  By unioning the features for the ""other"", self's features can be compared to a single giant blob of geometry instead of many individual rows. This improved performance 3x in testing when intersecting Sites onto TslAreas.",1,1
Adds a new animation and deletes some testing files  Adds MoveAnimation Removes the web page and algorithm used for testing Adds a SortedList utility Change Animations so that it uses the SortedList to improve performance,1,1
[stats] Improved materialized views for better performance in queries,1,1
"ENH:Faster, less memory intensive triangle filter",1,1
"io_uring: make CQ ring wakeups be more efficient  For batched IO, it's not uncommon for waiters to ask for more than 1 IO to complete before being woken up. This is a problem with wait_event() since tasks will get woken for every IO that completes, re-check condition, then go back to sleep. For batch counts on the order of what you do for high IOPS, that can result in 10s of extra wakeups for the waiting task.  Add a private wake function that checks for the wake up count criteria being met before calling autoremove_wake_function(). Pavel reports that one test case he has runs 40% faster with proper batching of wakeups.  Reported-by: Pavel Begunkov [URL]> Tested-by: Pavel Begunkov [URL]>",1,1
"[DASHBOARD] Improbe autoscale, prevent some glitch and improve performances by adding soft_redraw method",1,1
"crypto: arc4 - improve performance by adding ecb(arc4)  Currently arc4.c provides simple one-byte blocksize cipher which is wrapped by ecb() module, giving function call overhead on every encrypted byte. This patch adds ecb(arc4) directly into arc4.c for higher performance.  tcrypt results (speed ratios: new/old):  AMD Phenom II, x86-64 : x2.7 Intel Core 2, x86-64  : x1.9 Intel Atom N260, i386 : x1.4  Cc: Jon Oberheide [URL]>",1,1
[PATCH] Use more efficient iterators in MeshCommunication,1,1
"f2fs: remove percpu_count due to performance regression  This patch removes percpu_count usage due to performance regression in iozone.  Fixes: 523be8a6b3 (""f2fs: use percpu_counter for page counters"")",1,1
8172921: Zip filesystem performance improvement and code cleanup,1,1
finagle-http: Improve performance of TraceInfo  Problem  `c.t.f.http.TraceInfo` has some easy opportunities for optimizimation.  Solution  Do our basics:  * Convert `Option.map` into `match` * Avoid `foreach` when manual iteration will do * Use `try-catch` instead of a `Try`  Result  Less allocations in common code.  This also moves the code off of the internally exposed Netty3 APIs onto our public APIs.  Also removes some `private[finagle]` code that was only used in tests.  RB_ID=887684,1,1
Added specular highlights  Also improved performance when compiled with SIMD support.,1,1
Merge pull request #8299 from JosJuice/volumeverifier-performance  VolumeVerifier: Performance improvements,1,1
Introduce ClrArray and API for reading multiple values from arrays (#482)  * Add GetArrayElementsValues API for getting multiple values from array in  one call.    Measurements shows performance of new API is ~4-5 times faster than  calling getting the elements one by one.    * Fix bug return early reading multiple array values    * Introduce new ClrArray type for methods pertaining to array operations.    * Fix nullability and early return    * Update some XML documentation    * Update XML doc    * ReadArray writes into given T[]    * Conform to style convention of rep    * Update Equals(Object?) to support ClrObject and ulong    * Use underlying Read instead of introducing new ReadArray    * Add early exit on GetValuesFromAddress    * Compare to buffer.length not values.length    * Add early out to Equals(object),1,1
"[PATCH] Introduce self-pairs search in nbsearch

Make it possible to search for all pairs within a single set of
positions using AnalysisNeighborhood.  This effectively excludes half of
the pairs from the search, speeding things up.

Not used yet anywhere, but this makes the code a better reference for
performance comparisons, and for places where this is applicable it has
potential for speeding things up quite a bit.

Change-Id: Ib0e6f36460b8dbda97704447222c864c149d8e56",1,1
Merge pull request #329 from zhmcclient/andy/improve-objectid-filter  Fixes #261: Improved performance of lookup by object-id,1,1
"more efficient implementation of toList, toOptList and flatten",1,1
"sh: Optimise FDE/CIE lookup by using red-black trees  Now that the DWARF unwinder is being used to provide perf callstacks unwinding speed is an issue. It is no longer being used in exceptional circumstances where we don't care about runtime performance, e.g. when panicing, so it makes sense improve performance is possible.  With this patch I saw a 42% improvement in unwind time when calling return_address(1). Greater improvements will be seen as the number of levels unwound increases as each unwind is now cheaper.  Note that insertion time has doubled but that's just the price we pay for keeping the trees balanced. However, this is a one-time cost for kernel boot/module load and so the improvements in lookup time dominate the extra time we spend keeping the trees balanced.",1,1
"lib: introduce some memory copy macros and functions  the kernel's memcpy and memmove is very inefficient. But the glibc version is quite fast, in some cases it is 10 times faster than the kernel version. So I introduce some memory copy macros and functions of the glibc to improve the kernel version's performance.  The strategy of the memory functions is: 1. Copy bytes until the destination pointer is aligned. 2. Copy words in unrolled loops.  If the source and destination are not aligned    in the same way, use word memory operations, but shift and merge two read    words before writing. 3. Copy the few remaining bytes.",1,1
Performance optimization for displaying earlier script version,1,1
"Revert ""Revert ""Use debug level instead of info for logging, and some logging performance improvements""""  This reverts commit d7c2463abd8fc265e7a657ded00c6f5330c50a27.",1,0
Improved performances of presence server list notify,1,1
Better performance with everything in a single function.,1,1
"[PATCH] using int instead of size_t should be more efficient and
 range doesn't seem to be needed",1,1
"Implement ignore lists.  Glob patterns in BitKeeper/etc/ignore are matched against each file basename in sfiles, and if any of them match, the file is skipped.  sfiles -A will bypass the ignore file. Also contains some performance improvements in sfiles itself and in sccs_root.  t.basic 	Add tests of ignore-list functionality. glob.c  	BitKeeper file /work/src/bk/dev/src/glob.c takepatch.c	sccs_root takes one arg.  Remove redundant call to sccs_root. slib.c  	sccs_root takes one argument only. slib.c  	name2sccs: if it can't have an s.file name, return null instead slib.c  	of aborting. sfind.c 	Rewrite for ignore list support: sfind.c 	  new option -A means don't use ignore list sfind.c 	  lftw() guts split to lftw_inner() sfind.c 	  read BitKeeper/etc/ignore in lftw() sfind.c 	  check each file against the ignore list in lftw_inner() sfind.c 	General cleanup: sfind.c 	  file() duplicate processing removed sfind.c 	  lftw() uses new algorithm which uses way less stack sfind.c 	  use d_type field if present (no stat ops on BSD, Linux 2.3) sfind.c 	  some functions that always return an ignored zero changed to sfind.c 	  return nothing. sccs.h  	sccs_root takes one arg now.  Delete extra prototype of sccs.h  	sccs_root.  Add proto for freeLines.  Add protos for functions sccs.h  	in glob.c. Makefile	Take PORTOBJ out of SCCSOBJ.  Rearrange bk.ver rule so it  Makefile	isn't rebuilt every time you recompile prs.  Add glob.o to Makefile	SCCSOBJ.  Add deps for glob.o. sccs_root.c	Squash Windows and Unix versions together.  Check device number sccs_root.c	of / as well as inode.  Kill second argument.  Use O(n) algorithm.  bk: 37f397aapPpfJ3HinOWO2hjpeDEDoA",1,1
improve geoannotator performance and cleanup code,1,1
Implement MetaApi in ArgUtils; split implementations for better IDEA performance.,1,1
Make the inert flag independently inherit  Improve performance of changing inertness.  Bug: 1360404,1,1
"fix(library/unifier): in the context_check, we should not consider local constants that occur in the type of other constants  This was a performance bug. We were missing higher-order pattern constraints due to this bug.",1,1
"Renamed create_face_neighbors_index() to its_face_edge_ids(). Renamed its_create_neighbors_index() / its_create_neighbors_index_par() to its_face_neighbors() / its_face_neighbors_par(). New variant of its_face_edge_ids() to create edge IDs from face neighbors. Fixed some incorrect use of _NDEBUG, it should be NDEBUG. PrintObject::slice_support_volumes() returns newly Polygons, which are cheaper than ExPolygons. Updated SeamPlacer and SupportMaterial to use regions defined as Polygons, not ExPolygons. TriangleSelector::get_facets_strict() returning a patch with T-joints retriangulated. New slice_mesh_slabs() - slicing projections of a triangle patch into top / bottom layers of slices, for MMU top / bottom segmentation. TriangleMeshSlicer - use 64 mutexes instead of one when scattering sliced triangles into layers. This makes a big difference on modern many core desktop computers. When applying MM segmented regions to input regions, the split regions are now re-merged with 10x higher positive offset epsilon to avoid creating gaps. When testing for existence of paint-on supports or seam, use a more efficient has_facets() test, which does not deserialize into the expensive TriangleSelector tree structure. GLIndexedVertexArray newly uses Eigen::AlignedBox<float, 3> for efficiency instead of our double based BoundingBoxf3. Improved MMU painting refresh speed by optimizing generation of the vertex buffers. Refactored MMU segmentation - projection of painted surfaces from top / bottom. 	1) Parallelized. 	2) Using the new slice_mesh_slabs() instead of projecting one triangle by the other and merging them with Clipper.",1,1
- Patch #13224 by Richard Archer and Gerhard: improved gzip caching.,1,1
"Provide better support for libucontext  For some reason, the Makefile in libucontext is broken -- building it with meson fixes the generated libraries, which do not export the symbols and as a result, no symbol interposition ends up taking place.  To force those symbols to be used, use the `libucontext_` prefixed versions; at least we'll get a build error in Lwan if libucontext wasn't built correctly rather than silently building and then using the libc ucontext functions and definitions.  I have confirmed that Lwan doesn't make calls to block/unblock the signal mask on AARCH64, which happens when using the libc ucontext functions.  This should improve performance on non-x86 systems where libucontext is supported.",1,1
"[PATCH] Removed Reaction-Field-nec

The RF no exclusion correction option was only introduced for
backward compatibility and a performance advantage for systems
with only rigid molecules (e.g. water). For all other systems
the forces are incorrect. The Verlet scheme did not support this
option and if it would, it wouldn't even improve performance.

Change-Id: Ic22ccf76d50b5bb7951fcac2293621b5eef285c5",1,1
"[PATCH] resolved performance degrating changed introduced in revision
 1319",1,1
Improve commit() performance and actionize it so it can be processed in a batch,1,1
Admin: improve picotable filters choice defaults  Choice default as false was causing unexpected behavior. Also when the data is empty the default values was not applied at all.  While at it make both groups and shops lists values list to improve performance on situation when there is a lot of groups or shops.,1,1
"ASoC: Make LZO cache compression optional  Make LZO cache compression optional as it pulls in the kernel wide LZO implementation and rbtree compression is generally more efficient for typical register maps, especially in terms of CPU performance.",1,1
"Updated the function eval_h  Upon testing the code, I realized that the inner sum were going out of bounds. It is more efficient to only evaluate the sums needed within each case.",1,1
"net: Don't force epoll/kqueue to wake up in order to add new events.  In conjunction with the non-blocking system call CL, this gives about an 8% performance improvement on a client/server test running on my local machine.  R=rsc, iant2 CC=golang-dev [URL]/4272057",1,1
"APNs: set MaxIdleConnsPerHost as same as core.worker_num.  As worker_num is typically larger than MaxIdleConnsPerHost, the performance should be improved.",1,1
Check SecurityChanges when ensuring currency data feeds  A performance improvement to the way we process currency conversion data began saving the security reference instead of just the symbol. When added via universe selection (not AddSecurity) the security doesn't exist in the security manager until it's added in the algorithm manager. This was caused key not found exceptions when attempting to retrieve the security from the security manager.  The fix here is to also check SecurityChanges when resolving the data feed. A future improvement might be to decouple the cash object from the currency feed required to provide it conversions to the account currency.  Fixes #1635,1,1
[Wallet] Improve performance when listing mints,1,1
"Release 1.1, many new features and performance improvements. See README.md",1,1
Merge branch 'rc/diff-cleanup-records'  * rc/diff-cleanup-records:   xdiff/xprepare: improve O(n*m) performance in xdl_cleanup_records(),1,1
Small hack to get better performance on data_cleaning,1,1
cache performance and thread safety issues fixed.,1,1
Performance improvement: FIRE-140 thanks Nicky Dasmijn,1,1
"Change internal _headers attribute to be a dictionary of columns instead of a numpy structured array.  This should make a lot of the header manipulations more efficient, since the majority of them are column-based.",1,1
Improved linphone_friend_list_parse_multipart_related_body performances by preventing parsing multiple times a multipart body,1,1
"sched: reinitialize rq->next_balance when a CPU is hot-added  Reinitialize rq->next_balance when a CPU is hot-added.  Otherwise, scheduler domain rebalancing may be skipped if rq->next_balance was set to a future time when the CPU was last active, and the newly-re-added CPU is in idle_balance().  As a result, the newly-re-added CPU will remain idle with no tasks scheduled until the softlockup watchdog runs - potentially 4 seconds later.  This can waste energy and reduce performance.  This behavior can be observed in some SoC kernels, which use CPU hotplug to dynamically remove and add CPUs in response to load.  In one case that triggered this behavior,  0. the system started with all cores enabled, running multi-threaded    CPU-bound code;  1. the system entered some single-threaded code;  2. a CPU went idle and was hot-removed;  3. the system started executing a multi-threaded CPU-bound task;  4. the CPU from event 2 was re-added, to respond to the load.  The time interval between events 2 and 4 was approximately 300 milliseconds.  Of course, ideally CPU hotplug would not be used in this manner, but this patch does appear to fix a real bug.  Nvidia folks: this patch is submitted as at least a partial fix for bug 1243368 (""[sched] Load-balancing not happening correctly after cores brought online"")",1,1
"[SYSTEMML-1836] Reduced GC overhead codegen rowwise ops (static buffer)   Scripts like Kmeans and Mlogreg showed unnecessarily large GC overhead when ran with codegen enabled. These scripts heavily rely on rowwise fused operators, which already used a thread-local buffer for row intermediates (where the size of this buffer is derived from the cplan, usually <10). However, this ring buffer used a poor implementation based on linked lists, which created new objects per vector allocation (i.e., per row intermediate).   This patch changes this implementation to a static array ring buffer, which significantly improved end-to-end performance. For example, here are the results for Kmeans and Mlogreg on a 10Mx10 scenario:  Baselines w/o codegen: Kmeans 1,399s, Mlogreg 507s. Kmeans w/ codegen: 466s (102s GC) -> 326s (13s GC) Mlogreg w/ codegen: 196s (37s GC) -> 134s (6s GC)  Furthermore, this patch also cleans up the statistics collection (collect all outside loop and only for top-level problems), statistics output formatting (mis-aligned outputs), and introduces a new util function for integer power 2^x in order to increase readability while leveraging the performance benefits of simply shifts.",1,1
Merge pull request #13 from asiekierka/1.10.x  Optimize doesClassImplement performance by caching,1,1
"usb: ehci: make HC see up-to-date qh/qtd descriptor ASAP  This patch introduces the helper of ehci_sync_mem to flush qtd/qh into memory immediately on some ARM, so that HC can see the up-to-date qtd/qh descriptor asap.  This patch fixs one performance bug on ARM Cortex A9 dual core platform, which has been reported on quite a few ARM machines (OMAP4, Tegra 2, snowball...), see details from link of [URL]/bugs/709245.  The patch has been tested ok on OMAP4 panda A1 board, and the performance of 'dd' over usb mass storage can be increased from 4~5MB/sec to 14~16MB/sec after applying this patch.  Cc: Alan Stern [URL]> Cc: Russell King [URL].uk>",1,1
"Optimization (performance regression fix): Use bigger buffer for server reads.  Change the server read buffer limits to 16KB minimum and 256KB maximum. Used to be: 2KB and 2GB. And before r9766: 4KB and SQUID_TCP_SO_RCVBUF.  Trunk r9766 (Remove limit on HTTP headers read) made the default HTTP server read buffer size 2KB instead of 4KB, visibly slowing down Squid when kernel network buffers are full and can sustain larger Squid reads. Doing up to twice as many network reads is expensive (and probably not just because of the extra system call overheads).  We never grow that buffer size if the _parser_ does not need a bigger buffer:  Even if the HTTP client is slower than the server, the buffer stays small because it gives all the data to Store and Store eventually just stalls reading via delayAwareRead() and read_ahead_gap. The situation may be different with RESPMOD, but if the adaptation service is fast, the buffer would still not grow.  This change does not reset the minimum buffer size to the old 4KB default because memory is much cheaper compared to the days where that default was set. 8KB may have worked too, but with 12KB median typical response size a larger buffer may be a good idea for a busy Squid. More performance work is needed to find the optimal value (which could depend on the environment).  This change does not set the maximum buffer size to the current 2GB limit because we have not tested how header and chunking parsers would cope with malicious messages trying to run Squid out of RAM; and also because no good parser should need that much lookahead space. Is 256KB enough for all legitimate real-world response headers? We do not know.  It is tempting to use Config.tcpRcvBufsz or SQUID_TCP_SO_RCVBUF to find the right minimum or maximum buffer size, but those parameters deal with low-level TCP buffering aspects while this buffer deals with HTTP parsing.",1,1
Improved the performance and memory usage of parsing individual selectors.,1,1
"Added several performance improvements, most of them still experimental, plus started to prepare for a release.",1,1
"We meant fIsAutoParsingSuspended instead of IsAutoLoadingEnabled()  There used to be just one way of resolving an unknown name (eg. MyClass) -- by using the TCling::AutoLoad interface. However, there are two ingredients to resolve a name -- make the name known to the cling and make its library known to the JIT. Historically, these were one function.  Later, we implemented performance optimization on top which divides the two steps in order to avoid excessive library loading. Now we have an auto parse step which is designed to avoid the heavy TCling::Autoload.  The particular callback calls tryAutoParseInternal which is controlled by fIsAutoParsingSuspended.",1,1
Merge pull request #1921 from lafranceinsoumise/gdp/try-to-improve-vpr-matching-script-performances  Try to improve `match_available_proxies_with_requests` query time,1,1
Optimized boarding logic. Now it works correct. Adjust speed at the end to ensure that vehicles park closer to the cargo when carriers are in formation.,1,1
performance improvements:  check for empty instance before going into writeLock  configure timeout on waiting for construction thread,1,1
"Replace _group_matching with an inward-out grouping algorithm  All the matching between open/close was done all the time, first finding the matching closing token, and then grouping the tokens in between, and recurse over the newly created list.  Instead, it is more efficient to look for the previous open-token on finding a closing-token, group these two together, and then continue on.  squashed: Handle token indices in group_tokens_between and find_matching.",1,1
"switch mem3 cache from ets to mochiglobal, 20% speedup :)",1,1
Optimized and commented the GGen_Data_2D::Noise function (profiler suggests 30-40% performance increase),1,1
"Merge branch 'asnyc-when-necessary' to master  This adds synchronous diffing, until an asynchronous `expect.it` is encountered, when it breaks out to asynchronous diffing. This should improve performance for the majority of cases (where synchronous is all that is needed), and reduce performance for the odd case where async is required.",1,1
"Re-work annotation -- less wonky, more efficient",1,1
"Performance improvement: Update textures of city labels, rather than creating a new texture and mesh for every city label update.",1,1
"8030714: The steps attribute, flow and desugar are unnecessary for implicit classes when compiling with -implicit:none Summary: When compiling with -implicit:none, attribute, flow and desugar is skipped for better performance.",1,1
"8036860: Pad and cache-align the BiasedMappedArray Summary: Pad and cache-align BiasedMappedArray instances by default to avoid performance variability problems due to false sharing, as instances of this data structures are typically used for performance sensitive code.",1,1
"f2fs: optimize fs_lock for better performance  There is a performance problem: when all sbi->fs_lock are holded, then all the following threads may get the same next_lock value from sbi->next_lock_num in function mutex_lock_op, and wait for the same lock(fs_lock[next_lock]), it may cause performance reduce. So we move the sbi->next_lock_num++ before getting lock, this will average the following threads if all sbi->fs_lock are holded.  v1-->v2: 	Drop the needless spin_lock as Jaegeuk suggested.  Suggested-by: Jaegeuk Kim [URL]>",1,1
Improve performance of symbolic integral computation,1,1
IB/qib: Convert qib_user_sdma_pin_pages() to use get_user_pages_fast()  qib_user_sdma_queue_pkts() gets called with mmap_sem held for writing. Except for get_user_pages() deep down in qib_user_sdma_pin_pages() we don't seem to need mmap_sem at all.  Even more interestingly the function qib_user_sdma_queue_pkts() (and also qib_user_sdma_coalesce() called somewhat later) call copy_from_user() which can hit a page fault and we deadlock on trying to get mmap_sem when handling that fault.  So just make qib_user_sdma_pin_pages() use get_user_pages_fast() and leave mmap_sem locking for mm.  This deadlock has actually been observed in the wild when the node is under memory pressure.  Cc: [URL]>,1,1
Merge pull request #38 from loudnate/loudnate/performance  Insulin effect performance improvements,1,1
refactor codes to have better performance,1,1
Merge pull request #8873 from andrepereiradasilva/jlanguage-knowlanguages  JLanguage::parseLanguageFiles performance improvements,1,1
"[PATCH] s390x: Use new sgemm kernel also for strmm on Z14 and newer

Employ the newly added GEMM kernel also for STRMM on Z14. The
implementation in C with vector intrinsics exploits FP32 SIMD operations
and thereby gains performance over the existing assembly code. Extend
the implementation for handling triangular matrix multiplication,
accordingly. As added benefit, the more flexible C code enables us to
adjust register blocking in the subsequent commit.

Tested via make -C test / ctest / utest and by a couple of additional
unit tests that exercise blocking.

Signed-off-by: Marius Hillenbrand <mhillen@linux.ibm.com>",1,1
"Enable highQualityFilter_SSE2  With SSE2, bitmap_BGRA_8888_A_scale_rotate_bicubic gains about 40% performance improvement on desktop i7-3770.  BUG=skia:  Committed: [URL]/skia/+/b381fa10d8079c58928058bb8a6db32b39f05e51  CQ_EXTRA_TRYBOTS=tryserver.skia:Test-Mac10.6-MacMini4.1-GeForce320M-x86_64-Release-Trybot [URL], [URL]  Author: [URL]  Review URL: [URL]/525283002",1,1
"[PATCH] lagrangian: Rationalized the handling of multi-component
 liquids and solids Ensures consistency between the mixture thermodynamics and
 composition specifications for the parcels. Simpler more efficient
 implementation. Resolves bug-report
 http://www.openfoam.org/mantisbt/view.php?id=1395 as well as other
 consistency issues not yet reported.",1,1
improve performance by compiling the OEMASK regexp out of the loop catch faulty OEMASKs and emit a user friendly error message,1,1
"Refactor the garbage collector for BDD/ZBDD  Only the unique table is managed by the garbage collector. Other tables are treated as local containers, and cleaning is done by the functions that use them. The performance is mixed, but the memory consumptions is decreased by 2-10x.",1,1
[FLINK-22022][table-planner-blink] Reduce the ExecNode scan scope to improve performance when converting json plan to ExecNodeGraph  This closes #15426,1,1
Session helpers are improved with better dot notation access in performance.,1,1
"pinctrl: Fix two deadlocks  commit db93facfb0ef542aa5d8079e47580b3e669a4d82 upstream.  This patch is to fix two deadlock cases. Deadlock 1: CPU #1  pinctrl_register-> pinctrl_get ->  create_pinctrl  (Holding lock pinctrl_maps_mutex)  -> get_pinctrl_dev_from_devname  (Trying to acquire lock pinctrldev_list_mutex) CPU #0  pinctrl_unregister  (Holding lock pinctrldev_list_mutex)  -> pinctrl_put ->> pinctrl_free ->  pinctrl_dt_free_maps -> pinctrl_unregister_map  (Trying to acquire lock pinctrl_maps_mutex)  Simply to say CPU#1 is holding lock A and trying to acquire lock B, CPU#0 is holding lock B and trying to acquire lock A.  Deadlock 2: CPU #3  pinctrl_register-> pinctrl_get ->  create_pinctrl  (Holding lock pinctrl_maps_mutex)  -> get_pinctrl_dev_from_devname  (Trying to acquire lock pinctrldev_list_mutex) CPU #2  pinctrl_unregister  (Holding lock pctldev->mutex)  -> pinctrl_put ->> pinctrl_free ->  pinctrl_dt_free_maps -> pinctrl_unregister_map  (Trying to acquire lock pinctrl_maps_mutex) CPU #0  tegra_gpio_request  (Holding lock pinctrldev_list_mutex)  -> pinctrl_get_device_gpio_range  (Trying to acquire lock pctldev->mutex)  Simply to say CPU#3 is holding lock A and trying to acquire lock D, CPU#2 is holding lock B and trying to acquire lock A, CPU#0 is holding lock D and trying to acquire lock B.",1,0
"[PATCH] #1295 Refactored MX::setSub(IMatrix,IMatrix) The new
 implementation should be much more efficient and handle non-monotone indices
 correctly",1,1
Fix for bug Blades/BLD-152. Added test for bugfix. Optimized bug fix.,1,0
Merge pull request #6 from lob/performance  feat(performance): Performance improvements,1,1
"eal/arm64: optimize memcpy  This patch provides an option to do rte_memcpy() using 'restrict' qualifier, which can induce GCC to do optimizations by using more efficient instructions, providing some performance gain over memcpy() on some ARM64 platforms/enviroments.  The memory copy performance differs between different ARM64 platforms. And a more recent glibc (e.g. 2.23 or later) can provide a better memcpy() performance compared to old glibc versions. It's always suggested to use a more recent glibc if possible, from which the entire system can get benefit. If for some reason an old glibc has to be used, this patch is provided for an alternative.  This implementation can improve memory copy on some ARM64 platforms, when an old glibc (e.g. 2.19, 2.17...) is being used. It is disabled by default and needs ""RTE_ARCH_ARM64_MEMCPY"" defined to activate. It's not always proving better performance than memcpy() so users need to run DPDK unit test ""memcpy_perf_autotest"" and customize parameters in ""customization section"" in rte_memcpy_64.h for best performance.  Compiler version will also impact the rte_memcpy() performance. It's observed on some platforms and with the same code, GCC 7.2.0 compiled binary can provide better performance than GCC 4.8.5. It's suggested to use GCC 5.4.0 or later.",1,1
Sync networks added in OOBE to first account.  Any networks that are added during OOBE should be considered to be owned by first user to log in for the purposes of sync.  Bug: 966270,0,0
"feat: created a networks config in docker-compose, added new networks to the devserver and reaction services",0,0
"added test for distances, few corrections and improvements to computation of certain distances",0,0
Improve handling of custom type constructors,0,0
"gpu: ion: Set the dma_address of the sg list at alloc time  This patch sets the dma_address field of the sglist representing an allocation at allocation time.  This technically breaks the dma api which states that these addresses should be set when a particular device takes ownership of a buffer via the dma_map apis.  In the case of our systems the only dma address space is physical addresses.  Additionally, we can not afford the overhead of calling dma_map_sg from this location as it implies a cache invalidate that is not necessary if the memory was previously mapped cached.  Instead, the expectation is that memory being returned from the heaps is ready for dma in that if any cached mappings of that memory exist they have been invalidated.",0,0
Merge pull request #15189 from aeslaughter/find-exe-15017  Improve logic in mooseutils.find_moose_executable,0,0
"drm/i915: [GEN7] Use HW scheduler for fixed function shaders  commit a1e969e0332de7a430e62822cee8f2ec8d83cd7c upstream.  This originally started as a patch from Bernard as a way of simply setting the VS scheduler. After submitting the RFC patch, we decided to also modify the DS scheduler. To be most explicit, I've made the patch explicitly set all scheduler modes, and included the defines for other modes (in case someone feels frisky later).  The rest of the story gets a bit weird. The first version of the patch showed an almost unbelievable performance improvement. Since rebasing my branch it appears the performance improvement has gone, unfortunately. But setting these bits seem to be the right thing to do given that the docs describe corruption that can occur with the default settings.  In summary, I am seeing no more perf improvements (or regressions) in my limited testing, but we believe this should be set to prevent rendering corruption, therefore cc stable.  v1: Clear bit 4 also (Ken + Eugeni) Do a full clear + set of the bits we want (Me).  Cc: Bernard Kilarski [URL]> Reviewed-by (RFC): Kenneth Graunke [URL]>",0,1
ErrorMsg  Improve error message log for user,0,0
Adding documentation concerning local memory allocation issues that may happen in the future.,0,0
[GeneratorBundle] Improve code style and code quality of generated classes,0,0
"ARM: 7492/1: add strstr declaration for decompressors  With the generic unaligned.h, more kernel headers get pulled in including dynamic_debug.h which needs strstr. As it is not really used, we only need a declaration here.",0,0
"Bug#14633008 MISLEADING ERROR WHEN TRYING TO UPDATE NON-EXISTING P_S TABLES  Before this change, INSERT / UPDATE / DELETE / LOCK TABLES performed on unknown performance_schema tables would fail with errors such as ER_TABLEACCESS_DENIED_ERROR.  For users with the proper grants, the error message for similar cases with non performance_schema tables is simply ER_NO_SUCH_TABLE.  While this behavior is correct (the performance_schema has some extra security privileges checks that are built in), it is also confusing.  This fix relaxes the built in privilege checks for the performance schema, so that DML on tables that do not exist simply fails with ER_NO_SUCH_TABLE.  This is mostly cosmetic, to improve ease of use.",0,0
msm: vidc: free the recon buffers in cleanup function  - The recon buffers were not released when video recording   was killed abruptly leading to memory leak.  - Fix provided to release the recon buffers when media   server killed abruptly.,0,0
"Improved update last info methods, only change DOM when necessary",0,0
"Normalize all merge/split code into block-type agnostic class  Hooray, a single class for all the merge/split code. It probably still needs a cleanup, but this is a vast improvement from what we had before. No more sub-class for every block type that each contained hundreds of lines of duplicated code!",0,0
[Private sites] Hide VideoPress switch on private atomic sites (#40470)  * Move EligibilityWarnings gate from CDN features fo main performance tab and hide Videopress behind it    * Remove obsolete class name    * Add videoPress to list of blacklisted modules in the selector,0,0
Improved user experience when deleting causes databsae constraints to fail,0,0
"VM: Simplify dispatcher code for closure calls.  The getter call to "".call"" can be avoided for Function objects, since it just returns the receiver there.  This makes the unoptimized code smaller. Optimized code will only be affected if the getter call was not inlined before.  [URL]  Review URL: [URL]//890573002",0,1
"chore: Rakefile improvements  - run init task before all other tasks - ensure a Logs/ directory exists in init and output all build logs there - redirect STDERR to STDOUT for all xcodebuild invocations, and fail the Rakefile task if the build fails - skip existing ruby installs with rbenv",0,0
libvortex-1.1: * [fix] More fixings (memory leaks fixes) due to vortex sequencer   rewrite.,0,0
interfaces/hardware-observe: allow lsmem and sysfs memory status and ranges,0,0
"Merge branch 'dev/gui-enhancements' into dev/gui-enhancements-update  * dev/gui-enhancements: (41 commits)   Update GUI user manual   Add image options   Add projected-to-ground image in world view   Remove default translucency of trails   Update user manual   Add method to get camera projection matrix   Move image loading to MainWindow   Fix performance updating tracks   Fix landmark initial visibility   Use simple get object method in place of vtkGetObjectMacro   Don't leak ""internal"" objects   Add option to toggle perspective   Add more view rotation presets   Make links in about dialog clickable   Fix rich text generation in about dialog   Add basic description text to about dialog   Fix minor error in README   Implement simple markdown parsing for About dialog   Disable lighting of ground plane grid   Add option for historic-only trails   ...  Conflicts:         gui/CameraView.cxx",0,0
Merge pull request #8 from brianloveswords/error-handling  Improve error handling.,0,0
sched: export cpu_clock  the rcutorture module relies on cpu_clock.,0,0
add information about network programming in python,0,0
sched/fair: Add irq load awareness to the tick CPU selection logic  IRQ load is not taken into account when determining whether a task should be migrated to a different CPU.  A task that runs for a long time could get stuck on CPU with high IRQ load causing degraded performance.  Add irq load awareness to the tick CPU selection logic.  CRs-fixed: 809119,0,1
"JavaScriptCore:          Reviewed by Maciej Stachowiak.                  Fixed [URL]/show_bug.cgi?id=15490         Iteration statements sometimes incorrectly evaluate to the empty value          (KDE r670547).                   [ Broken off from [URL]/show_bug.cgi?id=14868 ]                  This patch is a merge of KDE r670547, with substantial modification          for performance.                  It fixes do-while statements to evaluate to a value. (They used         to evaluate to the empty value in all cases.)           It also fixes SourceElementsNode to maintain the value of abnormal          completions like ""break"" and ""continue.""                  It also re-works the main execution loop in SourceElementsNode so that         it (1) makes a little more sense and (2) avoids unnecessary work. This          is a .28% speedup on command-line JS iBench.          * kjs/nodes.cpp:         (DoWhileNode::execute):         (SourceElementsNode::execute):  LayoutTests:          Reviewed by Maciej Stachowiak.                  Layout tests for [URL]/show_bug.cgi?id=15490         Iteration statements sometimes incorrectly evaluate to the empty value          (KDE r670547)                  * fast/js/do-while-expression-value-expected.txt: Added.         * fast/js/do-while-expression-value.html: Added.         * fast/js/while-expression-value-expected.txt: Added.         * fast/js/while-expression-value.html: Added.",0,1
finishing up some of the performance testing.  Found a bug in one of the edge files.,0,0
Simulator update. Memory read/write functions implemented. updateCpu function mostly implemented.,0,0
"Preparations for more performance: Introducing token_key.  The first 8 characters of a token will be saved as token_key, so in future knox won't iterate over all hashes, only over all with the first 8 chars.  For a smooth migration, this minor release doesn't include the actual performance improvements. If a token is valid, it will fill the token_key, but is still running over all tokens. In the next (I would say) major release, a breaking change will come, because the token_key will become not null. All reused tokens between this and the upcoming (major) release will be updated automatically and are not affected. Any other inactive user must reauthenticate. Then the actual performance improvement will work.  Bonus: Code cleanup, more PEP8.",0,1
"Discrete model, using histograms  Possible improvement: the model-building phase should abort as soon as the number of classes becomes too large",0,0
"Throttle DOM timers on hidden pages. [URL]/show_bug.cgi?id=98474  Patch by Kiran Muppala [URL]> on 2012-10-08 Reviewed by Maciej Stachowiak.  Source/JavaScriptCore:  Add HIDDEN_PAGE_DOM_TIMER_THROTTLING feature define.  * Configurations/FeatureDefines.xcconfig:  Source/WebCore:  When the visibility of a page changes to ""hidden"", all it's DOM timers are updated to align their fire times on one second intervals.  This limits the number of CPU wakes due to a hidden pages to one per second.  Test: fast/dom/timer-throttling-hidden-page.html  * Configurations/FeatureDefines.xcconfig: * WebCore.exp.in: * dom/Document.cpp: (WebCore): (WebCore::Document::timerAlignmentInterval): Read Page::timerAlignmentInterval and pass it along to DOMTimer.  * dom/Document.h: (Document): * dom/ScriptExecutionContext.cpp: (WebCore): (WebCore::ScriptExecutionContext::didChangeTimerAlignmentInterval): Scan through self DOM Timers and tell them to recompute their fire time based on the updated alignment interval. (WebCore::ScriptExecutionContext::timerAlignmentInterval):  * dom/ScriptExecutionContext.h: (ScriptExecutionContext): * page/DOMTimer.cpp: (WebCore): (WebCore::DOMTimer::alignedFireTime): If the document's alignment interval is non zero, round up the fire time to the next multiple of alignment interval.  * page/DOMTimer.h: (DOMTimer): (WebCore::DOMTimer::defaultTimerAlignmentInterval): (WebCore::DOMTimer::setDefaultTimerAlignmentInterval): * page/Page.cpp: (WebCore::Page::Page): (WebCore): (WebCore::Page::setTimerAlignmentInterval): (WebCore::Page::timerAlignmentInterval): (WebCore::Page::setVisibilityState): Getter and Setter for alignment interval.  Expose setVisibilityState if either PAGE_VISIBILITY_API is enabled or if HIDDEN_PAGE_DOM_TIMER_REDUCTION is enabled.  * page/Page.h: (Page): * page/Settings.cpp: (WebCore): (WebCore::Settings::setDefaultDOMTimerAlignmentInterval): (WebCore::Settings::defaultDOMTimerAlignmentInterval): (WebCore::Settings::setDOMTimerAlignmentInterval): (WebCore::Settings::domTimerAlignmentInterval): * page/Settings.h: (Settings): * page/SuspendableTimer.cpp: (WebCore::SuspendableTimer::suspend): Save the time remaining to the original unaligned fire time, so that on resuming, the fire time will be correctly aligned using the latest alignment interval.  * platform/ThreadTimers.cpp: (WebCore::ThreadTimers::sharedTimerFiredInternal): Clear m_unalignedNextFireTime along with m_nextFireTime to keep them always in sync.  * platform/Timer.cpp: (WebCore::TimerBase::TimerBase): (WebCore::TimerBase::setNextFireTime): Save the requested fire time in m_unalignedNextFireTime and set m_nextFireTime to the aligned value.  The unalinged value is used to recompute fire time if alignment interval changes. (WebCore): (WebCore::TimerBase::didChangeAlignmentInterval): Recompute next fire time from m_unalignedNextFireTime. (WebCore::TimerBase::nextUnalignedFireInterval): Interval from current time to the original unaligned fire time.  * platform/Timer.h: (TimerBase): (WebCore::TimerBase::alignedFireTime):  Source/WebKit/mac:  Add HIDDEN_PAGE_DOM_TIMER_THROTTLING feature define and provide a SPI for DumpRenderTree to modify the visibility state of a page.  The latter is needed to test throttling of timers on hidden pages through DumpRenderTree.  * Configurations/FeatureDefines.xcconfig: * WebView/WebView.mm: (-[WebView _setVisibilityState:isInitialState:]): * WebView/WebViewPrivate.h:  Source/WebKit2:  Add HIDDEN_PAGE_DOM_TIMER_THROTTLING feature define.  Use existing code of PAGE_VISIBILITY_API to detect changes to page visibility state.  * Configurations/FeatureDefines.xcconfig: * UIProcess/WebPageProxy.cpp: (WebKit::WebPageProxy::WebPageProxy): Check visibility state on construction. (WebKit::WebPageProxy::initializeWebPage): Send initial visibility state message if HIDDEN_PAGE_DOM_TIMER_THROTTLING is enabled or if PAGE_VISIBILITY_API is enabled. (WebKit::WebPageProxy::viewStateDidChange): When PAGE_VISIBILITY_API is not enabled, compare new visibility against WebPageProxy::m_isVisible, to minimize number of messages sent. Remove unnecessary second call to PageClient::isViewVisible for updating visibility state.  * WebProcess/InjectedBundle/InjectedBundle.cpp: (WebKit::InjectedBundle::setPageVisibilityState): WebKitTestRunner uses this method to implement testRunner.setPageVisibility(), hence enable it for testing hidden page timer throttling as well.  * WebProcess/WebPage/WebPage.cpp: (WebKit): (WebKit::WebPage::setVisibilityState): Ensure Page::setVisibilityState is called either if PAGE_VISIBILITY_API is enabled or if HIDDEN_PAGE_DOM_TIMER_THROTTLING is enabled.  * WebProcess/WebPage/WebPage.h: (WebPage): * WebProcess/WebPage/WebPage.messages.in:  Tools:  Implement testRunner.setPageVisibility on mac for testing throttling of timers on hidden pages using DumpRenderTree.  * DumpRenderTree/mac/Configurations/Base.xcconfig: Fix build error on mac-ews bot.  Add JSC copy of ICU headers to search path.  * DumpRenderTree/mac/TestRunnerMac.mm: (TestRunner::resetPageVisibility): (TestRunner::setPageVisibility):  WebKitLibraries:  Add HIDDEN_PAGE_DOM_TIMER_THROTTLING feature define.  * win/tools/vsprops/FeatureDefines.vsprops: * win/tools/vsprops/FeatureDefinesCairo.vsprops:  LayoutTests:  Add a test for DOM timer throttling on hidden pages.  * fast/dom/timer-throttling-hidden-page-expected.txt: Added. * fast/dom/timer-throttling-hidden-page.html: Added. * platform/chromium/TestExpectations: * platform/efl/TestExpectations: * platform/gtk/TestExpectations: * platform/qt/TestExpectations: * platform/win/TestExpectations: Skip the test since HIDDEN_PAGE_DOM_TIMER_THROTTLING is not enabled by default.",0,0
"I have renamed 'NewCoalescentLikelihood' as 'CoalescentLikelihood' to clarify things a bit. NewCoalescentLikelihood was more efficient and clean implementation and it's parser was installed as the default 'coalescentLikelihood' anyway since BEAST v1.4.x.  I have renamed 'CoalescentLikelihood' to AbstractCoalescentLikelihood and removed the parser (made it abstract).  This class is used as a base by a number of other classes (i.e., BayesianSkylineLikelihood). I guess that ideally, we see what of AbstractCoalescentLikelihood the descendents actually use and strip out some of it.",0,0
improved loggin and data emitting,0,0
Merge pull request #720 from Microsoft-CISL/weimer_size_to_memory  Replace size with explicit memory in examples and tests,0,0
"sched: window-stats: adjust RQ curr, prev sums on task migration  Adjust cpu's busy time in its recent and previous window upon task migration. This would enable scheduler to provide better inputs to cpufreq governor on a cpu's busy time in a given window.",0,0
Merge pull request #52 from maurocolella/feature/improve-style-and-function  Improve style and function,0,0
"Bug#51741 Unit test pfs-t failing in mysql-next-mr-bugfixing  The root cause of the failure is that when Bug#51447 performance schema evil twin files was fixed, instrumented file names got normalized.  The pfs-t unit test depends on this file normalization, but it was not updated.  This fix aligns pfs-t.cc lookup_file_by_name() with the logic in pfs_instr.cc find_or_create_file().",0,0
"interfaces/network-control: additional ethernet rule  This should allow an access of the form:  AVC apparmor=""DENIED"" operation=""open"" profile=""snap.name.app"" name=/sys/devices/platform/ /30800000.bus/30be0000.ethernet/net/eth0/address pid=18219 comm=""vgc-bc"" requested_mask=""r"" denied_mask=""r"" fsuid=0 ouid=0",0,0
Split SCTP initmsg test into two test cases  The original test allocates 65535 output streams which may fail on older kernels due to lack of memory. Split the test into two test cases: - allocate 10 output streams and accept no errors (functional test) - allocate 65535 output streams and accept ENOMEM (stress test)  Also clean up some unnecessary code and check that the test message is transferred correctly.,0,0
"AP_ADSB: delete furthest when buffer is full  - added lowest/highest_threat tracking. This is currently defined as 2D distance. Room for improvement to make it 3D and be flight vector based instead of distance - when trying to add a vehicle but  the buffer is full, overwrite the lowest_threat/furthest - added basic THREAT enum of high/low which means in or our of the 200m radius. Room for improvement here.",0,1
"Create property attributes on demand.  This reduces the memory footprint of large projects. Unfortunately, I haven't seen much of a performance difference.",0,1
"statistics: draw legend as a QSGNode  In order not to waste CPU by constantly rerendering the chart, we must use these weird OpenGL QSGNode things. The interface is appallingly low-level and unfriendly.  As a first test, try to convert the legend. Create a wrapper class that represents a rectangular item with a texture and that will certainly need some (lots of) optimization.  Make sure that all low-level QSG-objects are only accessed in the rendering thread. This means that the wrapper has to maintain a notion of ""dirtiness"" of the state. I.e. which part of the QSG-objects have to be modified.  From the low-level wrapper derive a class that draws a rounded rectangle for every resize. The child class of that must then paint on the rectangle after every resize.  That looks all not very fortunate, but it displays a legend and will make it possible to move the legend without and drawing operations, only shifting around an OpenGL surface.  The render thread goes through all chart-items and rerenders them if dirty. Currently, on deletion of these items, this list is not reset. I.e. currently it is not supported to remove individual items. Only the full scene can be cleared!",0,1
Add more memory usage stats  Added support for teasing apart different parts of the dalvik heap.  Note this adds more public api and we should talk to hackbod before going into master with this.  (cherry picked from commit 73407daf3f6110e933d8614605b21586c4c5fde2),0,0
"new description for C calls  ==> ChangeLog <== 2005-03-25  Paolo Bonzini  [URL]>  	* kernel/Class.st: Implement ""active"" method annotations and 	C-call method annotations. 	* kernel/CompildMeth.st: Implement C-call method annotations. 	* kernel/ObjMemory.st: Call ""Class initialize"".  	* examples/gdbm-c.st: Switch to new C-call description. 	* examples/md5.st: Likewise. 	* examples/regex.st: Likewise. 	* kernel/Behavior.st: Likewise. 	* kernel/CFuncs.st: Likewise. 	* kernel/ClassDesc.st: Likewise. 	* kernel/DLD.st: Likewise. 	* kernel/Directory.st: Likewise. 	* kernel/File.st: Likewise. 	* kernel/VFS.st: Likewise.  ==> gtk/ChangeLog <== 2005-03-25  Paolo Bonzini  [URL]>  	* gtk/MoreFuncs.st: Switch to new C-call descriptions. 	* gtk/funcs.awk: Switch to new C-call descriptions.  ==> blox-tk/ChangeLog <== 2005-03-25  Paolo Bonzini  [URL]>  	* blox-tk/BloxBasic.st: Switch to new C-call descriptions.  ==> tcp/ChangeLog <== 2005-03-25  Paolo Bonzini  [URL]>  	* tcp/cfuncs.st: Switch to new C-call descriptions.  ==> i18n/ChangeLog <== 2005-03-25  Paolo Bonzini  [URL]>  	* i18n/Locale.st: Switch to new C-call descriptions. 	* i18n/Sets.st: Switch to new C-call descriptions.  ==> libgst/ChangeLog <== 2005-03-25  Paolo Bonzini  [URL]>  	* libgst/comp.c (install_method): Evaluate pragma handlers. 	Make CompiledMethod read-only. 	(method_new): Do not make CompiledMethod read-only here. 	* libgst/dict.c (class_info): Include pragmaHandlers instance 	variable for Class. 	(init_class): Initialize it here. 	* libgst/dict.h (gst_class): Include pragmaHandlers instance variable. 	* libgst/sym.c (_gst_find_pragma_handler): New. 	* libgst/sym.h (_gst_find_pragma_handler): Declare it.   git-archimport-id: [URL]--2004b/smalltalk--devo--2.2--patch-23",0,0
"Merge branch 'next' of [URL]/pub/scm/linux/kernel/git/benh/powerpc  Pull main powerpc updates from Ben Herrenschmidt:  ""This time around, the powerpc merges are going to be a little bit more   complicated than usual.    This is the main pull request with most of the work for this merge   window.  I will describe it a bit more further down.    There is some additional cpuidle driver work, however I haven't   included it in this tree as it depends on some work in tip/timer-core   which Thomas accidentally forgot to put in a topic branch.  Since I   didn't want to carry all of that tip timer stuff in powerpc -next, I   setup a separate branch on top of Thomas tree with just that cpuidle   driver in it, and Stephen has been carrying that in next separately   for a while now.  I'll send a separate pull request for it.    Additionally, two new pieces in this tree add users for a sysfs API   that Tejun and Greg have been deprecating in drivers-core-next.   Thankfully Greg reverted the patch that removes the old API so this   merge can happen cleanly, but once merged, I will send a patch   adjusting our new code to the new API so that Greg can send you the   removal patch.    Now as for the content of this branch, we have a lot of perf work for   power8 new counters including support for our new ""nest"" counters   (also called 24x7) under pHyp (not natively yet).    We have new functionality when running under the OPAL firmware   (non-virtualized or KVM host), such as access to the firmware error   logs and service processor dumps, system parameters and sensors, along   with a hwmon driver for the latter.    There's also a bunch of bug fixes accross the board, some LE fixes,   and a nice set of selftests for validating our various types of copy   loops.    On the Freescale side, we see mostly new chip/board revisions, some   clock updates, better support for machine checks and debug exceptions,   etc...""  * 'next' of [URL]/pub/scm/linux/kernel/git/benh/powerpc: (70 commits)   powerpc/book3s: Fix CFAR clobbering issue in machine check handler.   powerpc/compat: 32-bit little endian machine name is ppcle, not ppc   powerpc/le: Big endian arguments for ppc_rtas()   powerpc: Use default set of netfilter modules (CONFIG_NETFILTER_ADVANCED=n)   powerpc/defconfigs: Enable THP in pseries defconfig   powerpc/mm: Make sure a local_irq_disable prevent a parallel THP split   powerpc: Rate-limit users spamming kernel log buffer   powerpc/perf: Fix handling of L3 events with bank == 1   powerpc/perf/hv_{gpci, 24x7}: Add documentation of device attributes   powerpc/perf: Add kconfig option for hypervisor provided counters   powerpc/perf: Add support for the hv 24x7 interface   powerpc/perf: Add support for the hv gpci (get performance counter info) interface   powerpc/perf: Add macros for defining event fields & formats   powerpc/perf: Add a shared interface to get gpci version and capabilities   powerpc/perf: Add 24x7 interface headers   powerpc/perf: Add hv_gpci interface header   powerpc: Add hvcalls for 24x7 and gpci (Get Performance Counter Info)   sysfs: create bin_attributes under the requested group   powerpc/perf: Enable BHRB access for EBB events   powerpc/perf: Add BHRB constraint and IFM MMCRA handling for EBB   ...",0,0
Changes merged for Unified Memory-based tree rep on GPU. Not too good though.,0,0
"doc: kernel-parameters.txt: fix documentation of elevator parameter  Legacy IO schedulers (cfq, deadline and noop) were removed in f382fb0bcef4.  The documentation for deadline was retained because it carries over to mq-deadline as well, but location of the doc file was changed over time.  The old iosched algorithms were removed from elevator= kernel parameter and mq-deadline, kyber and bfq were added with a reference to their documentation.  Fixes: f382fb0bcef4 (""block: remove legacy IO schedulers"")",0,0
"Merge branch 'upstream/xen' of [URL]/pub/scm/linux/kernel/git/jeremy/xen  * 'upstream/xen' of [URL]/pub/scm/linux/kernel/git/jeremy/xen: (23 commits)   xen/panic: use xen_reboot and fix smp_send_stop   Xen: register panic notifier to take crashes of xen guests on panic   xen: support large numbers of CPUs with vcpu info placement   xen: drop xen_sched_clock in favour of using plain wallclock time   pvops: do not notify callers from register_xenstore_notifier   Introduce CONFIG_XEN_PVHVM compile option   blkfront: do not create a PV cdrom device if xen_hvm_guest   support multiple .discard.* sections to avoid section type conflicts   xen/pvhvm: fix build problem when !CONFIG_XEN   xenfs: enable for HVM domains too   x86: Call HVMOP_pagetable_dying on exit_mmap.   x86: Unplug emulated disks and nics.   x86: Use xen_vcpuop_clockevent, xen_clocksource and xen wallclock.   implement O_NONBLOCK for /proc/xen/xenbus   xen: Fix find_unbound_irq in presence of ioapic irqs.   xen: Add suspend/resume support for PV on HVM guests.   xen: Xen PCI platform device driver.   x86/xen: event channels delivery on HVM.   x86: early PV on HVM features initialization.   xen: Add support for HVM hypercalls.   ...",0,0
"Removed the keydispatcher.  I'm now sending almost all key events to the top widget itself (except the button). The button needs to be improved, so it's easier to distinguis if it's clicked what to do. I tried a signal connect, but can't stop the event loop in the view. That somehow needs a better solution.",0,0
"upgrade in the base library (strings::Join now supports int and int64 vectors), file operations uses status; improve the code on symmetries; API for assumptions on sat",0,0
"am 44fdcf26: Merge ""Update no wifi networks string"" into mnc-dev  * commit '44fdcf26421c4c2a59888739fa003a14e09e8391':   Update no wifi networks string",0,0
"Improve appearance of markers and paths  1. Markers are now yellow points 2. Trajectories are blue lines 3. Scaled models of bodies are as they were 4. Classes have been named more descriptively 5. Much of the code has been split out into .cpp files 5. The colors are set in style.hpp for convenient adjustment  The display looks much more elegant now. The earlier markers, which were circles with a small non-zero size, looked clunky. Making them points made busy displays, such as the asteroids scenario, look really nice. The problem with the points was that we no longer got the nice markers gliding over the paths when we advanced time. Making the markers yellow and the paths blue makes the points stand out and now the animation looks quite nice. In a busy scene like the asteroids we get a nicely visible cloud of yellow points over a blue background.",0,0
"Merge [URL]/pub/scm/linux/kernel/git/nab/target-pending  Pull SCSI target fixes from Nicholas Bellinger:  ""The executive summary includes:     - Post-merge review comments for tcm_vhost (MST + nab)    - Avoid debugging overhead when not debugging for tcm-fc(FCoE) (MDR)    - Fix NULL pointer dereference bug on alloc_page failulre (Yi Zou)    - Fix REPORT_LUNs regression bug with pSCSI export (AlexE + nab)    - Fix regression bug with handling of zero-length data CDBs (nab)    - Fix vhost_scsi_target structure alignment (MST)    Thanks again to everyone who contributed a bugfix patch, gave review   feedback on tcm_vhost code, and/or reported a bug during their own   testing over the last weeks.    There is one other outstanding bug reported by Roland recently related   to SCSI transfer length overflow handling, for which the current   proposed bugfix has been left in queue pending further testing with   other non iscsi-target based fabric drivers.    As the patch is verified with loopback (local SGL memory from SCSI   LLD) + tcm_qla2xxx (TCM allocated SGL memory mapped to PCI HW) fabric   ports, it will be included into the next 3.6-rc-fixes PULL request.""  * [URL]/pub/scm/linux/kernel/git/nab/target-pending:   target: Remove unused se_cmd.cmd_spdtl   tcm_fc: rcu_deref outside rcu lock/unlock section   tcm_vhost: Fix vhost_scsi_target structure alignment   target: Fix regression bug with handling of zero-length data CDBs   target/pscsi: Fix bug with REPORT_LUNs handling for SCSI passthrough   tcm_vhost: Change vhost_scsi_target->vhost_wwpn to char *   target: fix NULL pointer dereference bug alloc_page() fails to get memory   tcm_fc: Avoid debug overhead when not debugging   tcm_vhost: Post-merge review changes requested by MST   tcm_vhost: Fix incorrect IS_ERR() usage in vhost_scsi_map_iov_to_sgl",0,0
Fully switched the addon manager to the new network subsystem.,0,0
Add back reasoner worse performance but was a requirement :( And add a fix for Jena 2.4,0,0
bacula-web: Improved and fixed small bugs in php code,0,0
"Improved animations and ""Add Book""/""Remove Book"". Added AnimateSelector(string selectorString, string animationString) to perform animate.css animations.",0,0
"Test that network_interface is explicitly set on POST/PATCH  This patch adds unit tests to ensure that node POST and PATCH requests always end up with the network interface explicitly set, based on the previous patch that changes the node object to always set this attribute.",0,0
"Revert of net: merge two versions of SetTCPNoDelay() function into one (patchset #4 id:60001 of [URL]/1728853006/ )  Reason for revert: net-unittests failure on Mac. [URL]/p/chromium.mac/builders/Mac10.9%20Tests/builds/16976/steps/net_unittests%20on%20Mac-10.9/logs/CertVerifyProcTest.CybertrustGTERoot  Original issue's description: > net: merge DisableNagle() with two other SetTCPNoDelay() implementations > > This patch merges SetTCPNoDelay() function from tcp_socket_posix.cc, > SetTCPNoDelay() function from tcp_socket_util.cc and DisableNagle() function > from tcp_socket_win.cc, into a single slightly improved one in tcp_socket.cc > with the following prototype: > > bool SetTCPNoDelay(SocketDescriptor socket, bool no_delay); > > BUG=None > TEST=net_unittests > [URL] > > Committed: [URL]/2d1f2621d8e6dd10feba6cab380fb46d60cb3098 >",0,0
"some improvements for the repl  - running ""tests"" no longer fails silently and lists individual tests - repl file is removed from the model after execution - repl can run private functions (again)",0,0
"mm: compaction: partially revert capture of suitable high-order page  Eric Wong reported on 3.7 and 3.8-rc2 that ppoll() got stuck when waiting for POLLIN on a local TCP socket.  It was easier to trigger if there was disk IO and dirty pages at the same time and he bisected it to commit 1fb3f8ca0e92 (""mm: compaction: capture a suitable high-order page immediately when it is made available"").  The intention of that patch was to improve high-order allocations under memory pressure after changes made to reclaim in 3.6 drastically hurt THP allocations but the approach was flawed.  For Eric, the problem was that page->pfmemalloc was not being cleared for captured pages leading to a poor interaction with swap-over-NFS support causing the packets to be dropped.  However, I identified a few more problems with the patch including the fact that it can increase contention on zone->lock in some cases which could result in async direct compaction being aborted early.  In retrospect the capture patch took the wrong approach.  What it should have done is mark the pageblock being migrated as MIGRATE_ISOLATE if it was allocating for THP and avoided races that way.  While the patch was showing to improve allocation success rates at the time, the benefit is marginal given the relative complexity and it should be revisited from scratch in the context of the other reclaim-related changes that have taken place since the patch was first written and tested.  This patch partially reverts commit 1fb3f8ca0e92 (""mm: compaction: capture a suitable high-order page immediately when it is made available"").",0,0
Fixed: Crash during initialization of GraphicEQ/Convolution filters when loading the configuration in multiple threads concurrently. This occurred most often when using GraphicEQ both for playback and capture devices. Improved: Updated FFTW to version 3.3.6-pl2.,0,1
"net_sched: invoke ->attach() after setting dev->qdisc  [ Upstream commit 86e363dc3b50bfd50a1f315934583fbda673ab8d ]  For mq qdisc, we add per tx queue qdisc to root qdisc for display purpose, however, that happens too early, before the new dev->qdisc is finally set, this causes q->list points to an old root qdisc which is going to be freed right before assigning with a new one.  Fix this by moving ->attach() after setting dev->qdisc.  For the record, this fixes the following crash:   ------------[ cut here ]------------  WARNING: CPU: 1 PID: 975 at lib/list_debug.c:59 __list_del_entry+0x5a/0x98()  list_del corruption. prev->next should be ffff8800d1998ae8, but was 6b6b6b6b6b6b6b6b  CPU: 1 PID: 975 Comm: tc Not tainted 4.1.0-rc4+ #1019  Hardware name: Bochs Bochs, BIOS Bochs 01/01/2011   0000000000000009 ffff8800d73fb928 ffffffff81a44e7f 0000000047574756   ffff8800d73fb978 ffff8800d73fb968 ffffffff810790da ffff8800cfc4cd20   ffffffff814e725b ffff8800d1998ae8 ffffffff82381250 0000000000000000  Call Trace:   [<ffffffff81a44e7f>] dump_stack+0x4c/0x65   [<ffffffff810790da>] warn_slowpath_common+0x9c/0xb6   [<ffffffff814e725b>] ? __list_del_entry+0x5a/0x98   [<ffffffff81079162>] warn_slowpath_fmt+0x46/0x48   [<ffffffff81820eb0>] ? dev_graft_qdisc+0x5e/0x6a   [<ffffffff814e725b>] __list_del_entry+0x5a/0x98   [<ffffffff814e72a7>] list_del+0xe/0x2d   [<ffffffff81822f05>] qdisc_list_del+0x1e/0x20   [<ffffffff81820cd1>] qdisc_destroy+0x30/0xd6   [<ffffffff81822676>] qdisc_graft+0x11d/0x243   [<ffffffff818233c1>] tc_get_qdisc+0x1a6/0x1d4   [<ffffffff810b5eaf>] ? mark_lock+0x2e/0x226   [<ffffffff817ff8f5>] rtnetlink_rcv_msg+0x181/0x194   [<ffffffff817ff72e>] ? rtnl_lock+0x17/0x19   [<ffffffff817ff72e>] ? rtnl_lock+0x17/0x19   [<ffffffff817ff774>] ? __rtnl_unlock+0x17/0x17   [<ffffffff81855dc6>] netlink_rcv_skb+0x4d/0x93   [<ffffffff817ff756>] rtnetlink_rcv+0x26/0x2d   [<ffffffff818544b2>] netlink_unicast+0xcb/0x150   [<ffffffff81161db9>] ? might_fault+0x59/0xa9   [<ffffffff81854f78>] netlink_sendmsg+0x4fa/0x51c   [<ffffffff817d6e09>] sock_sendmsg_nosec+0x12/0x1d   [<ffffffff817d8967>] sock_sendmsg+0x29/0x2e   [<ffffffff817d8cf3>] ___sys_sendmsg+0x1b4/0x23a   [<ffffffff8100a1b8>] ? native_sched_clock+0x35/0x37   [<ffffffff810a1d83>] ? sched_clock_local+0x12/0x72   [<ffffffff810a1fd4>] ? sched_clock_cpu+0x9e/0xb7   [<ffffffff810def2a>] ? current_kernel_time+0xe/0x32   [<ffffffff810b4bc5>] ? lock_release_holdtime.part.29+0x71/0x7f   [<ffffffff810ddebf>] ? read_seqcount_begin.constprop.27+0x5f/0x76   [<ffffffff810b6292>] ? trace_hardirqs_on_caller+0x17d/0x199   [<ffffffff811b14d5>] ? __fget_light+0x50/0x78   [<ffffffff817d9808>] __sys_sendmsg+0x42/0x60   [<ffffffff817d9838>] SyS_sendmsg+0x12/0x1c   [<ffffffff81a50e97>] system_call_fastpath+0x12/0x6f  ---[ end trace ef29d3fb28e97ae7 ]---  For long term, we probably need to clean up the qdisc_graft() code in case it hides other bugs like this.  Fixes: 95dc19299f74 (""pkt_sched: give visibility to mq slave qdiscs"") Cc: Jamal Hadi Salim [URL]>",0,0
Improved feedback after an action (on redirect) and also put a navigation check link up the top.,0,0
- Patch #268914 by catch: small usability improvements to taxonomy and content type overview pages.,0,0
toolchain: gcc 4.5: PR tree-optimization/42906 fix,0,0
master - f298de368 test(mdc-menu): add performance tests for mdc-menu (#20494),0,0
more changes in the new segmentation algorithm which is not finished,0,0
- Add begin and end to vector class. So we can use std::find algorithm on it. - Add the test case to test it.,0,0
canevas translation - first pass to improve later,0,0
[PULL_REQUEST_TEMPLATE.md] Add checkable Improvement options PR's purpose,0,0
e100: Fix ring parameter change handling regression.  When the PCI pool changes were added to fix resume failures:  commit 98468efddb101f8a29af974101c17ba513b07be1 e100: Use pci pool to work around GFP_ATOMIC order 5 memory allocation failu  and  commit 70abc8cb90e679d8519721e2761d8366a18212a6 e100: Fix broken cbs accounting due to missing memset.  This introduced a problem that can happen if the TX ring size is increased.  We need to size the PCI pool using cbs->max instead of the default cbs->count value.,0,0
"USB: gadget: ether: Clean up req->buf to avoid wild pointer  When OOM, the req->buf will fail to get memory from kmalloc. And all the req->buf in dev->tx_reqs will be freed in the error handler. But they are not cleared to NULL. So they are not allocated while below function got called again.  int alloc_tx_buffer(struct eth_dev *dev) {    list_for_each(act, &dev->tx_reqs) {        if ((!req->buf)         ->3. it can't allocate again.           req->buf = kmalloc();->1. it fails to get memory as OOM.        if (!req->buf)           goto free_buf;         ...    }    return 0; free_buf:    ...    kfree(req->buf);             ->2. It's freed.    return -ENOMEM; } So these pointers will be freed multi times. What's worse, once they are used as normally, system maybe be panic due to wild pointer. CRs-fixed: 571628",0,0
Make VectorConstantCoefficient::GetVec const (const-correctness),0,0
- fixes retry on plus PUSH - workaround for the famous Windows 10 Update 2004 issue that also breaks optimal smoothing - update numpy on Windows with updated OpenBLAS that might fix some of the Windows 10 Update 2004 issues - resets PID RS actions on PID ON - removes check for CPU state in S7 port,0,0
Merge pull request #3781 from yogstation13/upstream-merge-41832  [MIRROR] Cleans up and improves microwave code,0,0
"VS Code change theme, minor improvements",0,0
Improve Circularize Action,0,0
Merge pull request #1 from Wilfred/patch-1  Improve example in README.md,0,0
Merge pull request #749 from dr3amf4ll/patch-1  Documentation frontend improvement,0,0
Added performance guidelines  Fixes gitlab-org/gitlab-ce#15254 gitlab-org/gitlab-ce#14277  [ci skip],0,0
FAQ module - improve display (accordions),0,0
[PATCH] uml: Improve SIGBUS diagnostics  UML can get a SIGBUS anywhere if the tmpfs mount being used for its memory runs out of space.  This patch adds a printk before the panic to provide a clue as to what likely went wrong.,0,0
ncd: modules: net_ipv4_route: allow destination network in CIDR notation,0,0
"cpufreq: interactive: Make skipping delay for migration optional  Commit 92352c0a65bc (""cpufreq: interactive: Ramp up directly if cpu_load exceeds 100"") and commit 594945e67031 (""cpufreq: interactive: Skip delay in frequency changes due to migration"") allow interactive governor to skip above_hispeed_delay and min_sample_time if the frequency evaluation request comes from scheduler. Power and performance benefits of these two features are dependent on the behavior of each workload. Adverse load pattern may experience regression instead of improvement.  Make both features optional by introducing a sysfs file for each. Both features are disabled by default.",0,1
-Added Captain's Backpack & Satchel: [URL]/u/831776/comdoms.png -A few minor improvements to my own sprites  -Map changes to the Kitchen so the chef is more visible to his patrons -Arrivals airlocks are no longer airless when shuttles dock,0,0
"Fixed one-to-one relation bug, with foreignkey [worked only with localkey] Fixed session flushing bug Faster session flushing algorithm Fixed couple of require_once errors",0,0
"More improvements to the _Command_ object.  Actually removed the 'more flexible' magic __get & __set options, this was never a good idea.  Also, built an Abstract class with which to extend into concrete classes. The _Dispatch_ object should know completely what it is being passed.",0,0
Improved description for intro problem 1&3,0,0
"futex: Handle futex_pi OWNER_DIED take over correctly  Siddhesh analyzed a failure in the take over of pi futexes in case the owner died and provided a workaround. See: [URL]/bugzilla/show_bug.cgi?id=14076  The detailed problem analysis shows:  Futex F is initialized with PTHREAD_PRIO_INHERIT and PTHREAD_MUTEX_ROBUST_NP attributes.  T1 lock_futex_pi(F);  T2 lock_futex_pi(F);    --> T2 blocks on the futex and creates pi_state which is associated        to T1.  T1 exits    --> exit_robust_list() runs        --> Futex F userspace value TID field is set to 0 and            FUTEX_OWNER_DIED bit is set.  T3 lock_futex_pi(F);    --> Succeeds due to the check for F's userspace TID field == 0    --> Claims ownership of the futex and sets its own TID into the        userspace TID field of futex F    --> returns to user space  T1 --> exit_pi_state_list()        --> Transfers pi_state to waiter T2 and wakes T2 via        	   rt_mutex_unlock(&pi_state->mutex)  T2 --> acquires pi_state->mutex and gains real ownership of the        pi_state    --> Claims ownership of the futex and sets its own TID into the        userspace TID field of futex F    --> returns to user space  T3 --> observes inconsistent state  This problem is independent of UP/SMP, preemptible/non preemptible kernels, or process shared vs. private. The only difference is that certain configurations are more likely to expose it.  So as Siddhesh correctly analyzed the following check in futex_lock_pi_atomic() is the culprit:  	if (unlikely(ownerdied || !(curval & FUTEX_TID_MASK))) {  We check the userspace value for a TID value of 0 and take over the futex unconditionally if that's true.  AFAICT this check is there as it is correct for a different corner case of futexes: the WAITERS bit became stale.  Now the proposed change  -	if (unlikely(ownerdied || !(curval & FUTEX_TID_MASK))) { +       if (unlikely(ownerdied || +                       !(curval & (FUTEX_TID_MASK | FUTEX_WAITERS)))) {  solves the problem, but it's not obvious why and it wreckages the ""stale WAITERS bit"" case.  What happens is, that due to the WAITERS bit being set (T2 is blocked on that futex) it enforces T3 to go through lookup_pi_state(), which in the above case returns an existing pi_state and therefor forces T3 to legitimately fight with T2 over the ownership of the pi_state (via pi_state->mutex). Probelm solved!  Though that does not work for the ""WAITERS bit is stale"" problem because if lookup_pi_state() does not find existing pi_state it returns -ERSCH (due to TID == 0) which causes futex_lock_pi() to return -ESRCH to user space because the OWNER_DIED bit is not set.  Now there is a different solution to that problem. Do not look at the user space value at all and enforce a lookup of possibly available pi_state. If pi_state can be found, then the new incoming locker T3 blocks on that pi_state and legitimately races with T2 to acquire the rt_mutex and the pi_state and therefor the proper ownership of the user space futex.  lookup_pi_state() has the correct order of checks. It first tries to find a pi_state associated with the user space futex and only if that fails it checks for futex TID value = 0. If no pi_state is available nothing can create new state at that point because this happens with the hash bucket lock held.  So the above scenario changes to:  T1 lock_futex_pi(F);  T2 lock_futex_pi(F);    --> T2 blocks on the futex and creates pi_state which is associated        to T1.  T1 exits    --> exit_robust_list() runs        --> Futex F userspace value TID field is set to 0 and            FUTEX_OWNER_DIED bit is set.  T3 lock_futex_pi(F);    --> Finds pi_state and blocks on pi_state->rt_mutex  T1 --> exit_pi_state_list()        --> Transfers pi_state to waiter T2 and wakes it via        	   rt_mutex_unlock(&pi_state->mutex)  T2 --> acquires pi_state->mutex and gains ownership of the pi_state    --> Claims ownership of the futex and sets its own TID into the        userspace TID field of futex F    --> returns to user space  This covers all gazillion points on which T3 might come in between T1's exit_robust_list() clearing the TID field and T2 fixing it up. It also solves the ""WAITERS bit stale"" problem by forcing the take over.  Another benefit of changing the code this way is that it makes it less dependent on untrusted user space values and therefor minimizes the possible wreckage which might be inflicted.  As usual after staring for too long at the futex code my brain hurts so much that I really want to ditch that whole optimization of avoiding the syscall for the non contended case for PI futexes and rip out the maze of corner case handling code. Unfortunately we can't as user space relies on that existing behaviour, but at least thinking about it helps me to preserve my mental sanity. Maybe we should nevertheless :)  Reported-and-tested-by: Siddhesh Poyarekar [URL]> Link:   Acked-by: Darren Hart [URL]>",0,0
Merge pull request #244 from ladybug-tools/test_coverage_improvement  Added test for Radiance trans material,0,0
"It turns out that now that the propagator definition macrology is worked out (and do-apply-prop no longer tries to wrap a direct propagator constructor in a with-network-group), the basic tests of the metadata facility just pass again.",0,0
"Replace '--' with None (fixed #27) (#35)  * Unify the retry behavior in TWSEFetcher and TPEXFetcher, and improve coding style    * Replace '--' with None    * Add unit test for data with prices '--'",0,0
Improve keywords in package.json,0,0
"add back decryption check to cas shell encrypt function (#3907)  * add back decryption check to cas shell encrypt function    * add unit test to validate all good algorithms, warn if bad alg used    * Don't allow blacklisted jsypt algorirthms    * Don't test decrypt in shell b/c attempt to use blacklist alg will fail    * fix string format    * add method to allow setting bad algorithm (for unit tests)",0,0
"[Soup] CookieJarSoup::deleteCookie() should stop looking for the cookie after it is removed [URL]/show_bug.cgi?id=110100  Reviewed by Kenneth Rohde Christiansen.  CookieJarSoup::deleteCookie() retrieves the list of cookies that apply to a given URL, then iterates through the cookies to find the one with the right name and delete it. However, the current implementation keeps on comparing cookie names after the cookie was removed. This patch introduces a ""wasDeleted"" boolean to stop comparing cookie names after the cookie was deleted. Note that we cannot break as soon as the cookie is found as we need to keep iterating so that the cookies get freed by GOwnPtr.  No new tests, no behavior change.  * platform/network/soup/CookieJarSoup.cpp: (WebCore::deleteCookie):",0,0
"finished main algorithm, added forward probability",0,0
Release control of PPMT to GPU interpreter,0,0
lobby: Improve filter CSS loading to avoid ugly flashing on first load,0,0
"remove unused purephp classes in favor of third party libraries, usage of Illuminate Dispatcher and Illuminate string helpers, pure classes have been moved to the app/src dir, Controller class not found fix, and other minor changes, fixes and improvements",0,0
"* src/SDCCast.c (decorateType): fix promotion of unary minus * src/SDCCsymt.c (computeType): beautified * src/SDCCval.c (cheapestVal): beautified, old non-Ansi version removed, (valUnaryPM, valComplement, valNot): fix sign and promotion * support/regression/tests/uminus.c: speedup by removing superflous test case 'int' * support/regression/tests/onebyte.c: added promotion and signedness tests for unary minus * support/regressions/tests/bug-477927.c: disable warning about uninitialized variables",0,1
"Linux build fix  GCC does not allow local functor classes to be used with template algorithms, because template arguments must refer to an entity with external linkage.",0,0
"cpufreq_conservative: Improve support for micro idle accounting  The minimum samplerate calculations of the current conservative implementation assume that there is not micro idle accounting present, however, we do have that capability in our idle estimates.  As a result, we can support lower polling intervals just like ondemand does.",0,1
"Reset network credential on selection change  The ""authorize"" checkbox would remain checked whenever the credential type was changed, however it should be reset on each type change",0,0
"Use ContainerNode instead of Node where possible [URL]/show_bug.cgi?id=87220  Reviewed by Geoffrey Garen.  It's better to use a more specific type; in some cases we even generate more efficient code if we have a more specific type. Also, we want any type casts to be as close as possible to the corresponding type checks, so eliminating these uses of toContainerNode is a plus, also.  * dom/ContainerNodeAlgorithms.h: Changed insertionPoint to be a ContainerNode instead of a Node. Fixed spelling error ""inseretions"". Changed (WebCore::ChildFrameDisconnector::Target::Target): Changed type of frame owner element to HTMLFrameOwnerElement from Node.  * dom/DocumentType.cpp: (WebCore::DocumentType::insertedInto): (WebCore::DocumentType::removedFrom): * dom/DocumentType.h: * dom/Element.cpp: (WebCore::Element::insertedInto): (WebCore::Element::removedFrom): * dom/Element.h: * dom/Node.cpp: (WebCore::Node::insertedInto): (WebCore::Node::removedFrom): * dom/Node.h: * dom/ProcessingInstruction.cpp: (WebCore::ProcessingInstruction::insertedInto): (WebCore::ProcessingInstruction::removedFrom): * dom/ProcessingInstruction.h: * dom/ScriptElement.cpp: (WebCore::ScriptElement::insertedInto): * dom/ScriptElement.h: * html/FormAssociatedElement.cpp: (WebCore::FormAssociatedElement::insertedInto): (WebCore::FormAssociatedElement::removedFrom): * html/FormAssociatedElement.h: * html/HTMLBaseElement.cpp: (WebCore::HTMLBaseElement::insertedInto): (WebCore::HTMLBaseElement::removedFrom): * html/HTMLBaseElement.h: * html/HTMLBodyElement.cpp: (WebCore::HTMLBodyElement::insertedInto): (WebCore::HTMLBodyElement::didNotifyDescendantInsertions): * html/HTMLBodyElement.h: * html/HTMLFormControlElement.cpp: (WebCore::HTMLFormControlElement::insertedInto): (WebCore::HTMLFormControlElement::removedFrom): * html/HTMLFormControlElement.h: * html/HTMLFormElement.cpp: (WebCore::HTMLFormElement::insertedInto): (WebCore::HTMLFormElement::didNotifyDescendantInsertions): (WebCore::HTMLFormElement::removedFrom): * html/HTMLFormElement.h: * html/HTMLFrameElementBase.cpp: (WebCore::HTMLFrameElementBase::insertedInto): (WebCore::HTMLFrameElementBase::didNotifyDescendantInsertions): * html/HTMLFrameElementBase.h: * html/HTMLFrameSetElement.cpp: (WebCore::HTMLFrameSetElement::insertedInto): (WebCore::HTMLFrameSetElement::removedFrom): * html/HTMLFrameSetElement.h: * html/HTMLIFrameElement.cpp: (WebCore::HTMLIFrameElement::insertedInto): (WebCore::HTMLIFrameElement::removedFrom): * html/HTMLIFrameElement.h: * html/HTMLImageElement.cpp: (WebCore::HTMLImageElement::insertedInto): (WebCore::HTMLImageElement::removedFrom): * html/HTMLImageElement.h: * html/HTMLInputElement.cpp: (WebCore::HTMLInputElement::insertedInto): (WebCore::HTMLInputElement::removedFrom): * html/HTMLInputElement.h: * html/HTMLLinkElement.cpp: (WebCore::HTMLLinkElement::insertedInto): (WebCore::HTMLLinkElement::removedFrom): * html/HTMLLinkElement.h: * html/HTMLMapElement.cpp: (WebCore::HTMLMapElement::insertedInto): (WebCore::HTMLMapElement::removedFrom): * html/HTMLMapElement.h: * html/HTMLMediaElement.cpp: (WebCore::HTMLMediaElement::insertedInto): (WebCore::HTMLMediaElement::removedFrom): * html/HTMLMediaElement.h: * html/HTMLMetaElement.cpp: (WebCore::HTMLMetaElement::insertedInto): * html/HTMLMetaElement.h: * html/HTMLObjectElement.cpp: (WebCore::HTMLObjectElement::insertedInto): (WebCore::HTMLObjectElement::removedFrom): * html/HTMLObjectElement.h: * html/HTMLOptionElement.cpp: (WebCore::HTMLOptionElement::insertedInto): * html/HTMLOptionElement.h: * html/HTMLQuoteElement.cpp: (WebCore::HTMLQuoteElement::insertedInto): * html/HTMLQuoteElement.h: * html/HTMLScriptElement.cpp: (WebCore::HTMLScriptElement::insertedInto): * html/HTMLScriptElement.h: * html/HTMLSelectElement.cpp: (WebCore::HTMLSelectElement::insertedInto): * html/HTMLSelectElement.h: * html/HTMLSourceElement.cpp: (WebCore::HTMLSourceElement::insertedInto): (WebCore::HTMLSourceElement::removedFrom): * html/HTMLSourceElement.h: * html/HTMLStyleElement.cpp: (WebCore::HTMLStyleElement::insertedInto): (WebCore::HTMLStyleElement::removedFrom): * html/HTMLStyleElement.h: * html/HTMLTextFormControlElement.cpp: (WebCore::HTMLTextFormControlElement::insertedInto): * html/HTMLTextFormControlElement.h: * html/HTMLTitleElement.cpp: (WebCore::HTMLTitleElement::insertedInto): (WebCore::HTMLTitleElement::removedFrom): * html/HTMLTitleElement.h: * html/HTMLTrackElement.cpp: (WebCore::HTMLTrackElement::insertedInto): (WebCore::HTMLTrackElement::removedFrom): * html/HTMLTrackElement.h: * mathml/MathMLMathElement.cpp: (WebCore::MathMLMathElement::insertedInto): * mathml/MathMLMathElement.h: * svg/SVGElement.cpp: (WebCore::SVGElement::removedFrom): * svg/SVGElement.h: * svg/SVGFEImageElement.cpp: (WebCore::SVGFEImageElement::insertedInto): (WebCore::SVGFEImageElement::removedFrom): * svg/SVGFEImageElement.h: * svg/SVGFontFaceElement.cpp: (WebCore::SVGFontFaceElement::insertedInto): (WebCore::SVGFontFaceElement::removedFrom): * svg/SVGFontFaceElement.h: * svg/SVGFontFaceUriElement.cpp: (WebCore::SVGFontFaceUriElement::insertedInto): * svg/SVGFontFaceUriElement.h: * svg/SVGGlyphElement.cpp: (WebCore::SVGGlyphElement::insertedInto): (WebCore::SVGGlyphElement::removedFrom): * svg/SVGGlyphElement.h: * svg/SVGHKernElement.cpp: (WebCore::SVGHKernElement::insertedInto): (WebCore::SVGHKernElement::removedFrom): * svg/SVGHKernElement.h: * svg/SVGImageElement.cpp: (WebCore::SVGImageElement::insertedInto): * svg/SVGImageElement.h: * svg/SVGSVGElement.cpp: (WebCore::SVGSVGElement::insertedInto): (WebCore::SVGSVGElement::removedFrom): * svg/SVGSVGElement.h: * svg/SVGScriptElement.cpp: (WebCore::SVGScriptElement::insertedInto): * svg/SVGScriptElement.h: * svg/SVGStyleElement.cpp: (WebCore::SVGStyleElement::insertedInto): (WebCore::SVGStyleElement::removedFrom): * svg/SVGStyleElement.h: * svg/SVGStyledElement.cpp: (WebCore::SVGStyledElement::insertedInto): (WebCore::SVGStyledElement::removedFrom): * svg/SVGStyledElement.h: * svg/SVGTRefElement.cpp: (WebCore::SVGTRefElement::insertedInto): (WebCore::SVGTRefElement::removedFrom): * svg/SVGTRefElement.h: * svg/SVGTextPathElement.cpp: (WebCore::SVGTextPathElement::insertedInto): * svg/SVGTextPathElement.h: * svg/SVGTitleElement.cpp: (WebCore::SVGTitleElement::insertedInto): (WebCore::SVGTitleElement::removedFrom): * svg/SVGTitleElement.h: * svg/SVGUseElement.cpp: (WebCore::SVGUseElement::insertedInto): (WebCore::SVGUseElement::removedFrom): * svg/SVGUseElement.h: * svg/SVGVKernElement.cpp: (WebCore::SVGVKernElement::insertedInto): (WebCore::SVGVKernElement::removedFrom): * svg/SVGVKernElement.h: * svg/animation/SVGSMILElement.cpp: (WebCore::SVGSMILElement::insertedInto): (WebCore::SVGSMILElement::removedFrom): * svg/animation/SVGSMILElement.h: Changed arguments of insertedInto and removedFrom to ContainerNode instead of Node. Did the same with didNotifyDescendantInsertions, while fixing the typo in its name.  * editing/ReplaceSelectionCommand.cpp: (WebCore::ReplaceSelectionCommand::doApply): Put a typecast toHTMLElement here. The check for isListElement and isLegacyAppleStyleSpan takes care of the type checking. (WebCore::ReplaceSelectionCommand::insertAsListItems): Changed this function to take an HTMLElement instead of a Node, then we can drop use of the toContainerNode function. * editing/ReplaceSelectionCommand.h:  * editing/TextIterator.cpp: Fixed a typo in a comment.",0,1
Improve docs for Hopper Device example.,0,0
"Add ""performance"" folders into binary build (to help fix broken tests)",0,0
Improve h2 readability on mobile devices and update bold text style,0,0
"[Analysis] add isSplatValue() for vectors in IR  We have the related getSplatValue() already in IR (see code just above the proposed addition). But sometimes we only need to know that the value is a splat rather than capture the splatted scalar value. Also, we have an isSplatValue() function already in SDAG.  Motivation - recent bugs that would potentially benefit from improved splat analysis in IR: [URL]/show_bug.cgi?id=37428 [URL]/show_bug.cgi?id=42174  Differential Revision: [URL]/D63138",0,0
Merge branch 'master' of [URL]:acidgenomics/basejump into develop,0,0
"Improve response handling for asynchronous 'erpc' requests  receive_response/3, wait_response/3, and check_response/3 in 'erpc' can now take a collection of request identifiers as argument and handle any responses corresponding a request identifier in the collection.",0,0
"Changed GPU status line from ""A:xxxxx R:xxx"" to ""R:0.0%"". It shows (rejected/(accepted+rejected))*100, which is the percentage of rejections for a GPU. Total accepted and rejected in top status is unchanged.  GPU status lines now show both threads and intensity.",0,0
Merge pull request #6063 from ampproject/add/6053-add-wp-cli-wrapper-for-amp-binary  Refactor CLI subsystem and add optimize command,0,0
documenting algorithm for standard tibetan,0,0
Added new test suite to detect regressions for optimizations.,0,0
Merge pull request #174 from nlharris/patch-12  improved app name & description,0,0
"Register overutilization for arbitrary sequence sizes rework -This update brings generalization of register overutilization technique for arbitrary sequences. With it enabled, bigger sequences can be done in one upload to the chip, effectively bringing shared memory size to 128KB or even 256KB. It trades occupancy for lower number of memory transfers and can be useful for high-end GPUs with high CU count. Works both for non-strided and strided axes. Tested for C2C and single upload mode, no convolutions (will be improved in the future). Enabled for power of 2 sequences by default (works for non-power of 2 sequences as well, but performance gains are not yet tested). -Switched FFT exponent sign to be conformant with FFTW. Added an option to disable normalization in inverse FFT (enabled by default).",0,1
Small improvement of the benchmarks used for timing validation,0,1
chrony: upgrade 4.1 -> 4.2  refresh arm_eabi.patch  Changelog: ========== Enhancements -Add support for NTPv4 extension field improving synchronisation stability and resolution of root delay and dispersion (experimental) -Add support for NTP over PTP (experimental) -Add support for AES-CMAC and hash functions in GnuTLS -Improve server interleaved mode to be more reliable and support multiple clients behind NAT -Update seccomp filter -Add statistics about interleaved mode to serverstats report  Bug fixes -Fix RTC support with 64-bit time_t on 32-bit Linux -Fix seccomp filter to work correctly with bind*device directives -Suppress kernel adjustments of system clock (dosynctodr) on illumos  Other changes -Switch Solaris support to illumos,0,1
"kmem: First pass implementation of kmem - a general purpose kernel memory allocator  kmem: -- Allocates memory based on fixed-size power-of-2 sized blocks (for now it's 32B to 16KB) -- Each power-of-2 block size is allocated from a slab -- slabs are kept in an array so lookups for a given size are fast -- If a slab is out of blocks, _kmem_grow is invoked to calculate how much larger to increase the slab by -- Calculation is based off the ratio of allocations from that slab to to the total number of allocations across all slabs -- It will then try to steal free slab buffers from least recently used slabs -- Finally it will grab memory from vm_km to satisfy the rest of the size increase for the slab",0,1
Merge branch 'newtypeUID2' into performanceSpdFix,0,0
"Add migration support from agent to NSX dhcp/metadata services  This is feature patch (3 of 3) that introduces support for transitioning existing NSX-based deployments from the agent based model of providing dhcp and metadata proxy services to the new agentless based mode. In 'combined' mode, existing networks will still be served by the existing infrastructure, whereas new networks will be served by the new infrastructure.  Networks may be migrated to the model using a new CLI tool provided, called 'neutron-nsx-manage'. Currently the tool provides two admin-only commands:    neutron-nsx-manage net-report <net-id-or-name>  This will check that the network can be migrated and returns the resources currently in use. And:    neutron-nsx-manage net-migrate <net-id-or-name>  This will move the network over the new model and deallocate resources from the agent. Once a network has been migrated there is no turning back.  Completes-blueprint nsx-integrated-services",0,0
Switch index requests to updates with docAsUpsert  Switch all index statements to updates with docAsUpsert to make sure we don't throw out any fields maintained outside the normal index mechanism like local_sites_with_dupe.  This should be safe because the merging mechanism that docAsUpsert uses sits well with us because it won't try to merge lists.  Wonderful!  This does cost some performance on the Elasticsearch side but we're not really hurting there.  Bug: 58508,0,0
"Turns out that BGE_STATFLAG_UPDATED bit in the status block doesn't get properly updated by the newer hardware (seen in the TX completion case). This leads to very poor transmit performance in the beginning of a TCP connection.   Linux and FreeBSD don't rely on BGE_STATFLAG_UPDATED bit since they enable MSI and tagged status for 5717+.  Doing the same does indeed fix an issue.  Change was tested by David Imhoff on 5719, 5720 and 5721/5750, Hrvoje Popovski on 5704 B0, sthen@ on 5723/5784, benno@ on 5704 A3, and me on 5719, 5720 adn 5714/5715.  No objections from kettenis@ and",0,1
"Meta server: keep up to 8K of the most recently received from synchronous replication channel(s) ""future"" log blocks while inactive node is in the process of actively fetching / syncing log and retry merging these log blocks if / when log fetch ""catches up"" to the received log blocks sequence numbers. This mechanism is intended to handle the case when log sync finishes / exits prior to reaching the most recently received log block due to high RPC rate and / or network / IO latency. Implement debug instrumentation to test this logic by allowing to configure log fetch / sync to optionally discard received log data.",0,0
"Insert TRACE_EVENT macros for the sampling profiler into not performance-sensitive places  - Implement TraceEvent::SamplingState0Scope.  - Insert TraceEvent::SamplingState0Scope into where performance is not sensitive. I'll insert the macros to performance-sensitive places in a follow-up CL.  - Replace ""TraceEventAPIAtomicWord"" with ""long"", since it's implemented as long in the Chromium side. ""TraceEventAPIAtomicWord"" is confusing since it gives us an impression that it's already implemented as a thread-safe and atomic word.  R=abarth BUG=241743  Review URL: [URL]/17377006",0,0
"Synchronized to hipl--cert--2.6--patch-189 Patches applied:   * [URL]--hipl/hipl--cert--2.6--patch-156    Syncronized to hipl--userspace--2.6--patch-1461   * [URL]--hipl/hipl--cert--2.6--patch-157    save commit   * [URL]--hipl/hipl--cert--2.6--patch-158    save commit, x509 support not ready   * [URL]--hipl/hipl--cert--2.6--patch-159    save commit, almost done x509v3 creation functionality   * [URL]--hipl/hipl--cert--2.6--patch-160    save commit   * [URL]--hipl/hipl--cert--2.6--patch-161    x509 signing finished now it has to be sent back to the client   * [URL]--hipl/hipl--cert--2.6--patch-162    save commit: stack smashing problem   * [URL]--hipl/hipl--cert--2.6--patch-163    Fixed stack smashing discovered seg fault on another machine (this one works the other does not)   * [URL]--hipl/hipl--cert--2.6--patch-164    Removed some debug crap, 32 bit works spki and x509 both have some 64 bit issues, fixing...   * [URL]--hipl/hipl--cert--2.6--patch-165    Fixed spki msg init problem on 64 bit machine   * [URL]--hipl/hipl--cert--2.6--patch-166    fixed the x509 segfault on 64 bit machine   * [URL]--hipl/hipl--cert--2.6--patch-167    adding extensions to the x509 certificate works   * [URL]--hipl/hipl--cert--2.6--patch-168    Cleaned the code and added some communication stuff between daemon and the client, also added one debugging/displaying function for x509   * [URL]--hipl/hipl--cert--2.6--patch-169    save commit   * [URL]--hipl/hipl--cert--2.6--patch-170    something weird still with x509 creation because verification with my function and openssl one result in same error   * [URL]--hipl/hipl--cert--2.6--patch-171    Added x509v3 support that the self-signed cert can be verified, no someway to send 1,5K of certs from client to daemon is needed, because the verification needs the cert and the signers self-signed cert to be verified correctly   * [URL]--hipl/hipl--cert--2.6--patch-172    save commit, x509 in state of transition from pem to der encoding on the wire and the code seg faults   * [URL]--hipl/hipl--cert--2.6--patch-173    save commit   * [URL]--hipl/hipl--cert--2.6--patch-174    Transformation from PEM to DER is complete and both SPKI and X509 certificates can be signed and verified, builder for CERT parameter is missing   * [URL]--hipl/hipl--cert--2.6--patch-175    Added functionality to use get dsa key from hostid to dsa struct for certificates to use   * [URL]--hipl/hipl--cert--2.6--patch-176    Synchronized to hipl--userspace--2.6--patch-1524   * [URL]--hipl/hipl--cert--2.6--patch-177    Fixed spki signature and verification after merge   * [URL]--hipl/hipl--cert--2.6--patch-178    Added issue and subject alt name to be added always with IP: content   * [URL]--hipl/hipl--cert--2.6--patch-179    Cert algos RSA works, DSA signing SPKI works, other DSA stuff on the way   * [URL]--hipl/hipl--cert--2.6--patch-180    DSA SPKI verification works, now on todo list DSA to work with X.509.v3   * [URL]--hipl/hipl--cert--2.6--patch-181    Certs support DSA and RSA algorithms   * [URL]--hipl/hipl--cert--2.6--patch-182    Synchronized to hipl--userspace--2.6--patch-1630   * [URL]--hipl/hipl--cert--2.6--patch-183    Synchronized to hipl--userspace--2.6--patch-1640   * [URL]--hipl/hipl--cert--2.6--patch-184    Synchronized to hipl--userspace--2.6--patch-1650   * [URL]--hipl/hipl--cert--2.6--patch-185    Synchronized to hipl--userspace--2.6--patch-1660   * [URL]--hipl/hipl--cert--2.6--patch-186    Synchronized to hipl--userspace--2.6--patch-1670   * [URL]--hipl/hipl--cert--2.6--patch-187    Synchronized to hipl--userspace--2.6--patch-1600   * [URL]--hipl/hipl--cert--2.6--patch-188    Synchronized to hipl--userspace--2.6--patch-1614   * [URL]--hipl/hipl--cert--2.6--patch-189    Synchronized to hipl--userspace--2.6--patch-1621",0,0
New version: RecurrenceAnalysis v1.5.0 (#27763)  UUID: 639c3291-70d9-5ea2-8c5b-839eba1ee399 Repo: [URL]/JuliaDynamics/RecurrenceAnalysis.jl.git Tree: 7e3ba9dbb628119c8f8333516dd6f128b29c4a70  Registrator tree SHA: 7c16227cd1dc9bae38e25d6dc6f9c020f8ebca46,0,0
"arm: vfp: Fix memory corruption on PM suspend  Commit 36af2a47 (""ARM: vfp: Always save VFP state in vfp_pm_suspend"") introduced a potential use-after-free bug. On SMP systems, vfp_current_hw_state might hold dangling pointers in case a task which used the VFP last migrates to another CPU and then exits. If vfp_pm_suspend is called while vfp_current_hw_state still holds a pointer to the freed thread_info, that memory location will be written, potentially overwriting a new object allocated there.  The original problem is only relevant to UP systems in which the VFP state is stored lazily.  Fix this by only storing the VFP state on UP systems, and avoid doing so on SMP ones.",0,0
"Split ::optimizer into ::intraopt and ::interopt  These two classes don't really have anything to do with each other, so let them live in different namespaces.",0,0
"Add docker-compose, redis  ----------------------------  Add a docker-compose.yml config file that will spin up two containers on invocation of `docker-compose up`, one running the OTA bot and another running an instance of redis connected to the OTA bot via a local network link.  From the OTA bot, a connection to the redis instance is possible using the hostname of the redis container.  -----------------------------  The redis container uses a custom config that is copied in from `config/redis.conf`. A template was added to the config directory for this file that was modified from the official redis.conf for Redis 6.0 in the following way:  $ diff redis.conf redis.conf.template -y --suppress-common-lines   tcp-backlog 511                                                   | tcp-backlog 127   logfile """"                                                        | # logfile """"   # syslog-enabled no                                               | syslog-enabled yes   # syslog-ident redis                                              | syslog-ident redis   # syslog-facility local0                                          | syslog-facility local0   stop-writes-on-bgsave-error yes                                   | stop-writes-on-bgsave-error no  -----------------------------  To access the redis while it is running inside the container, modify your `docker-compose.yml` like so:  $ git diff docker-compose.yml   diff --git a/docker-compose.yml b/docker-compose.yml   index 78a6dd0..562b7a9 100644   --- a/docker-compose.yml   +++ b/docker-compose.yml   @@ -7,5 +7,7 @@ services:      redis:        image: ""redis:latest""        command: redis-server /usr/local/etc/redis/redis.conf   +    ports:   +      - ""6380:6379""        volumes:          - ./config/redis.conf:/usr/local/etc/redis/redis.conf  ------------------------------  You can run the following command from your local machine to test connectivity to the redis instance:  $ redis-cli -p 6380   127.0.0.1:6380> keys ""*""   (empty list or set)   127.0.0.1:6380>",0,0
msm: kgsl: Don't make assumptions about VMA regions  We cannot assume that a VMA region created as a result of an mmap belongs exclusively to us.  Allow the user to pass the size of the vmalloc region through the 'gpuaddr' member of the ioctl struct and do strict checking on the returned vma to make sure it is valid.  Wei Zou [URL]> Modded by faux123,0,0
"Initial provider tests (#1794)  * Initial provider tests    * Added VRC and wrapt (dependency) libs, added basic search test, initial use of cassettes instead of html, updated yaml test structure    * Rebased, fixed tests, added tests for zooqle and thepiratebay    * Update test_search    * Updated vcrpy to v1.10.5    * Added docstring    * rm extratorrent    * Add pubdate to tests    * Fix post-processing ignoring files in subdirectories    * Improve logging for post_processor    * Add anidex & fix pubdate tests    * Add vcrpy to requirements.txt    * Added torrentz2    * Fix elitetorrent & add tests    * Added tests for horriblesubs    * Added limetorrents test & removed dos    * Rewrite newptc and add tests, some other fixes to providers    * Fix newpct for guessit    * Added shanaproject    * Set newpct as public    * Added tokyotoshokan    * flake    * Fix torrent9 search and add tests    * Added rarbg tests    * Added nyaa tests",0,0
main/k8s-pool-management/check-pool-size-after-hours build 64794 adding unclaimed: biweekly-memory,0,0
"Reporting objectively bad reviews (#2038)  * Making clickable div show up as clickable.    Also laying in groundwork for ignoring and reporting reviews.    * No flagging highlighted reviews, gang.    * Simplified to one div for flag/edit icon.    Also, no flagging highlighted reviews.    * Simplifying review click dispatch.    * Added a class for reporting MALFEASANCE.    And calling it from flag click things.    * Don't report yourself, dummy.    * Whitespace.    * Reporting reviews should require confirmation.    Added UI bits to show/hide that.    * Are linebreaks at the end of imports needed?    I feel like I could be living in a state of sin otherwise.    * Building out click-to-really-report UI.    * My old eyes can't see the red on gray, but a different colored callout seems wrong?    * Theoretically, we can mark reviews as things to be ignored.    * Missing object in ctor.    * how method is invokd    * If we flag a user, we should ignore their other reviews.    * Fulfilling the API contract.    * Arrow function beats anonymous inline method.    * Supplying sync service to UserFilter.    * Touched changelog indicating flagging is here.    * Storage page will reflect how many ignored users you've got.    * SyncService is a promise, so we'll work within that for user filtering.    * You gotta be explicit about closing the flag context.    * Set the right key.    * Having a mechanism to empty out the ignored users list will be handy.    * Successfully emptying ignored users (in dev).    * Debug code oops'd.    * Linting fixes.    * Better styling on the review report buttons.    * Do the hamburger bars make it more obvious this is clickable?    * Improved styling of the callout div.    * Reporting a review shouldn't dismiss the popup.    * TIghtening up the click zone for the review workflow.    * Bonus styling on clickable elements - they should be links.    * Reviews are (hopefully) in vNext, not 4.6.0.    * Update CHANGELOG.md",0,0
"Rollback of rL355585.  Introduces memory leak in FunctionTest.GetPointerAlignment that breaks sanitizer buildbots:  ``` ================================================================= ==2453==ERROR: LeakSanitizer: detected memory leaks  Direct leak of 128 byte(s) in 1 object(s) allocated from:     #0 0x610428 in operator new(unsigned long) /b/sanitizer-x86_64-linux-bootstrap/build/llvm/projects/compiler-rt/lib/asan/asan_new_delete.cc:105     #1 0x16936bc in llvm::User::operator new(unsigned long) /b/sanitizer-x86_64-linux-bootstrap/build/llvm/lib/IR/User.cpp:151:19     #2 0x7c3fe9 in Create /b/sanitizer-x86_64-linux-bootstrap/build/llvm/include/llvm/IR/Function.h:144:12     #3 0x7c3fe9 in (anonymous namespace)::FunctionTest_GetPointerAlignment_Test::TestBody() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/unittests/IR/FunctionTest.cpp:136     #4 0x1a836a0 in HandleExceptionsInMethodIfSupported<testing::Test, void> /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc     #5 0x1a836a0 in testing::Test::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:2474     #6 0x1a85c55 in testing::TestInfo::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:2656:11     #7 0x1a870d0 in testing::TestCase::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:2774:28     #8 0x1aa5b84 in testing::internal::UnitTestImpl::RunAllTests() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:4649:43     #9 0x1aa4d30 in HandleExceptionsInMethodIfSupported<testing::internal::UnitTestImpl, bool> /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc     #10 0x1aa4d30 in testing::UnitTest::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:4257     #11 0x1a6b656 in RUN_ALL_TESTS /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/include/gtest/gtest.h:2233:46     #12 0x1a6b656 in main /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/UnitTestMain/TestMain.cpp:50     #13 0x7f5af37a22e0 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x202e0)  Indirect leak of 40 byte(s) in 1 object(s) allocated from:     #0 0x610428 in operator new(unsigned long) /b/sanitizer-x86_64-linux-bootstrap/build/llvm/projects/compiler-rt/lib/asan/asan_new_delete.cc:105     #1 0x151be6b in make_unique<llvm::ValueSymbolTable> /b/sanitizer-x86_64-linux-bootstrap/build/llvm/include/llvm/ADT/STLExtras.h:1349:29     #2 0x151be6b in llvm::Function::Function(llvm::FunctionType*, llvm::GlobalValue::LinkageTypes, unsigned int, llvm::Twine const&, llvm::Module*) /b/sanitizer-x86_64-linux-bootstrap/build/llvm/lib/IR/Function.cpp:241     #3 0x7c4006 in Create /b/sanitizer-x86_64-linux-bootstrap/build/llvm/include/llvm/IR/Function.h:144:16     #4 0x7c4006 in (anonymous namespace)::FunctionTest_GetPointerAlignment_Test::TestBody() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/unittests/IR/FunctionTest.cpp:136     #5 0x1a836a0 in HandleExceptionsInMethodIfSupported<testing::Test, void> /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc     #6 0x1a836a0 in testing::Test::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:2474     #7 0x1a85c55 in testing::TestInfo::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:2656:11     #8 0x1a870d0 in testing::TestCase::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:2774:28     #9 0x1aa5b84 in testing::internal::UnitTestImpl::RunAllTests() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:4649:43     #10 0x1aa4d30 in HandleExceptionsInMethodIfSupported<testing::internal::UnitTestImpl, bool> /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc     #11 0x1aa4d30 in testing::UnitTest::Run() /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/src/gtest.cc:4257     #12 0x1a6b656 in RUN_ALL_TESTS /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/googletest/include/gtest/gtest.h:2233:46     #13 0x1a6b656 in main /b/sanitizer-x86_64-linux-bootstrap/build/llvm/utils/unittest/UnitTestMain/TestMain.cpp:50     #14 0x7f5af37a22e0 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x202e0)  SUMMARY: AddressSanitizer: 168 byte(s) leaked in 2 allocation(s). ```  See [URL]:8011/builders/sanitizer-x86_64-linux-bootstrap/builds/11358/steps/check-llvm%20asan/logs/stdio for more information.  Also introduces use-of-uninitialized-value in ConstantsTest.FoldGlobalVariablePtr: ``` ==7070==WARNING: MemorySanitizer: use-of-uninitialized-value     #0 0x14e703c in User /b/sanitizer-x86_64-linux-fast/build/llvm/include/llvm/IR/User.h:79:5     #1 0x14e703c in Constant /b/sanitizer-x86_64-linux-fast/build/llvm/include/llvm/IR/Constant.h:44     #2 0x14e703c in llvm::GlobalValue::GlobalValue(llvm::Type*, llvm::Value::ValueTy, llvm::Use*, unsigned int, llvm::GlobalValue::LinkageTypes, llvm::Twine const&, unsigned int) /b/sanitizer-x86_64-linux-fast/build/llvm/include/llvm/IR/GlobalValue.h:78     #3 0x14e5467 in GlobalObject /b/sanitizer-x86_64-linux-fast/build/llvm/include/llvm/IR/GlobalObject.h:34:9     #4 0x14e5467 in llvm::GlobalVariable::GlobalVariable(llvm::Type*, bool, llvm::GlobalValue::LinkageTypes, llvm::Constant*, llvm::Twine const&, llvm::GlobalValue::ThreadLocalMode, unsigned int, bool) /b/sanitizer-x86_64-linux-fast/build/llvm/lib/IR/Globals.cpp:314     #5 0x6938f1 in llvm::(anonymous namespace)::ConstantsTest_FoldGlobalVariablePtr_Test::TestBody() /b/sanitizer-x86_64-linux-fast/build/llvm/unittests/IR/ConstantsTest.cpp:565:18     #6 0x1a240a1 in HandleExceptionsInMethodIfSupported<testing::Test, void> /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc     #7 0x1a240a1 in testing::Test::Run() /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc:2474     #8 0x1a26d26 in testing::TestInfo::Run() /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc:2656:11     #9 0x1a2815f in testing::TestCase::Run() /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc:2774:28     #10 0x1a43de8 in testing::internal::UnitTestImpl::RunAllTests() /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc:4649:43     #11 0x1a42c47 in HandleExceptionsInMethodIfSupported<testing::internal::UnitTestImpl, bool> /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc     #12 0x1a42c47 in testing::UnitTest::Run() /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/src/gtest.cc:4257     #13 0x1a0dfba in RUN_ALL_TESTS /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/googletest/include/gtest/gtest.h:2233:46     #14 0x1a0dfba in main /b/sanitizer-x86_64-linux-fast/build/llvm/utils/unittest/UnitTestMain/TestMain.cpp:50     #15 0x7f2081c412e0 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x202e0)     #16 0x4dff49 in _start (/b/sanitizer-x86_64-linux-fast/build/llvm_build_msan/unittests/IR/IRTests+0x4dff49)  SUMMARY: MemorySanitizer: use-of-uninitialized-value /b/sanitizer-x86_64-linux-fast/build/llvm/include/llvm/IR/User.h:79:5 in User ```  See [URL]:8011/builders/sanitizer-x86_64-linux-fast/builds/30222/steps/check-llvm%20msan/logs/stdio for more information.",0,0
"1. Add reverse hessian sparsity to user atomic functions (not yet tested). 2. In all sweep routines, resize vectors in groups with exact same size. 3. In sweep routines, improve comments about UserOp operator.  rev_sparse_hes.hpp: correction to documentation. sparse_set.hpp: comment about optimizing set operations. wish_list.omh: Add an item about optimizing set operations.",0,0
gpu: ion: Only map as much of the vma as the user requested,0,0
"cpufreq / powernow-k8: Remove usage of smp_processor_id() in preemptible code  BugLink: [URL]/bugs/1084539  commit e4df1cbcc1f329e53a1fff7450b2229e0addff20 upstream.  Commit 6889125b8b4e09c5e53e6ecab3433bed1ce198c9 (cpufreq/powernow-k8: workqueue user shouldn't migrate the kworker to another CPU) causes powernow-k8 to trigger a preempt warning, e.g.:    BUG: using smp_processor_id() in preemptible [00000000] code: cpufreq/3776   caller is powernowk8_target+0x20/0x49   Pid: 3776, comm: cpufreq Not tainted 3.6.0 #9   Call Trace:    [<ffffffff8125b447>] debug_smp_processor_id+0xc7/0xe0    [<ffffffff814877e7>] powernowk8_target+0x20/0x49    [<ffffffff81482b02>] __cpufreq_driver_target+0x82/0x8a    [<ffffffff81484fc6>] cpufreq_governor_performance+0x4e/0x54    [<ffffffff81482c50>] __cpufreq_governor+0x8c/0xc9    [<ffffffff81482e6f>] __cpufreq_set_policy+0x1a9/0x21e    [<ffffffff814839af>] store_scaling_governor+0x16f/0x19b    [<ffffffff81484f16>] ? cpufreq_update_policy+0x124/0x124    [<ffffffff8162b4a5>] ? _raw_spin_unlock_irqrestore+0x2c/0x49    [<ffffffff81483640>] store+0x60/0x88    [<ffffffff811708c0>] sysfs_write_file+0xf4/0x130    [<ffffffff8111243b>] vfs_write+0xb5/0x151    [<ffffffff811126e0>] sys_write+0x4a/0x71    [<ffffffff816319a9>] system_call_fastpath+0x16/0x1b  Fix this by by always using work_on_cpu().",0,0
major improvements to the scale bracelet visualization,0,0
Add EfficientNetV2 XL model defs,0,0
"Fix some bugs in StructTreeRoot parsing of parent tree  - Add support for parsing child nodes in the number tree - Number tree keys do not have to be consecutive numbers. Use   map instead of vector for parentTree. - Due to performance impact of iterating a map instead of   vector in parentTreeAdd, add a reverse mapping from Ref   to parentTree. - Add mcid parameter to findParentElement() to enable finding   the parent when there are multiple MCIDs on the same page. - Move RefCompare from pdfinfo.cc to Object.h so it can be   used by other files.  Bug #103912",0,1
Merge pull request #139 from macbre/select_star-improve-sql-comments-handling  is_select_query: improve handling of SQL comments,0,0
Remove Mac ASan Tests (1) from chromium.memory.  It doesn't exist anymore on [URL]/p/chromium.memory/builders.  [URL] BUG=  Review URL: [URL]/1197723006,0,0
"ACPI: Fix incompatibility with mcount-based function graph tracing  commit 61b79e16c68d703dde58c25d3935d67210b7d71b upstream.  Paul Menzel reported a warning:    WARNING: CPU: 0 PID: 774 at /build/linux-ROBWaj/linux-4.9.13/kernel/trace/trace_functions_graph.c:233 ftrace_return_to_handler+0x1aa/0x1e0   Bad frame pointer: expected f6919d98, received f6919db0     from func acpi_pm_device_sleep_wake return to c43b6f9d  The warning means that function graph tracing is broken for the acpi_pm_device_sleep_wake() function.  That's because the ACPI Makefile unconditionally sets the '-Os' gcc flag to optimize for size.  That's an issue because mcount-based function graph tracing is incompatible with '-Os' on x86, thanks to the following gcc bug:    [URL]/bugzilla/show_bug.cgi?id=42109  I have another patch pending which will ensure that mcount-based function graph tracing is never used with CONFIG_CC_OPTIMIZE_FOR_SIZE on x86.  But this patch is needed in addition to that one because the ACPI Makefile overrides that config option for no apparent reason.  It has had this flag since the beginning of git history, and there's no related comment, so I don't know why it's there.  As far as I can tell, there's no reason for it to be there.  The appropriate behavior is for it to honor CONFIG_CC_OPTIMIZE_FOR_{SIZE,PERFORMANCE} like the rest of the kernel.  Reported-by: Paul Menzel < >",0,0
Merge pull request #1840 from poanetwork/total_supply_bug  Handle case when total supply is nil,0,0
"Added missing platform dlls. Refractoring and bugfixes. Added SteamVR tab: Supersampling and reprojection settings and restart button. Added Statistics tab: rotation counter, performance statistics and others. Updated Move Playspace tab: Rotation and Seated mode support.",0,0
Add support for dynamic attendance.  E.g. 1 class meets 14 weeks. 1 class meets 15.,0,0
Improvement typing (#2735)  * Fix: Circular dependencies of internal files    * Change: dt.date for Date and dt.datetime for DateTime    * Use NewType if available    * FIX: Wrong version test    * Remove: Date and DateTime types due to error    * Change to HomeAssistantType    * General Improvement of Typing    * Improve typing config_validation    * Improve typing script    * General Typing Improvements    * Improve NewType check    * Improve typing db_migrator    * Improve util/__init__ typing    * Improve helpers/location typing    * Regroup imports and remove pylint: disable=ungrouped-imports    * General typing improvements,0,0
"igb: Make Tx budget for NAPI user adjustable  This change is to make the NAPI budget limits for transmit adjustable.  Currently they are only set to 128, and when the changes/improvements to NAPI occur to allow for adjustability, it would be possible to tune the value for optimal performance with applications such as routing.  v2: remove tie between NAPI and interrupt moderation     fix work limit define name (s/IXGBE/IGB/)     Update patch description to better reflect patch",0,1
Improved the list of used functions which is save in the COPASI file. Functions used in model quantities of type ASSIGNMENT or ODE were missed.,0,0
Merge pull request #392 from algolia/frontend_templates  Template improvements,0,0
"mm/huge_memory.c: respect FOLL_FORCE/FOLL_COW for thp  commit 8310d48b125d19fcd9521d83b8293e63eb1646aa upstream.  In commit 19be0eaffa3a (""mm: remove gup_flags FOLL_WRITE games from __get_user_pages()""), the mm code was changed from unsetting FOLL_WRITE after a COW was resolved to setting the (newly introduced) FOLL_COW instead.  Simultaneously, the check in gup.c was updated to still allow writes with FOLL_FORCE set if FOLL_COW had also been set.  However, a similar check in huge_memory.c was forgotten.  As a result, remote memory writes to ro regions of memory backed by transparent huge pages cause an infinite loop in the kernel (handle_mm_fault sets FOLL_COW and returns 0 causing a retry, but follow_trans_huge_pmd bails out immidiately because `(flags & FOLL_WRITE) && !pmd_write(*pmd)` is true.  While in this state the process is stil SIGKILLable, but little else works (e.g.  no ptrace attach, no other signals).  This is easily reproduced with the following code (assuming thp are set to always):      #include <assert.h>     #include <fcntl.h>     #include <stdint.h>     #include <stdio.h>     #include <string.h>     #include <sys/mman.h>     #include <sys/stat.h>     #include <sys/types.h>     #include <sys/wait.h>     #include <unistd.h>      #define TEST_SIZE 5 * 1024 * 1024      int main(void) {       int status;       pid_t child;       int fd = open(""/proc/self/mem"", O_RDWR);       void *addr = mmap(NULL, TEST_SIZE, PROT_READ,                         MAP_ANONYMOUS | MAP_PRIVATE, 0, 0);       assert(addr != MAP_FAILED);       pid_t parent_pid = getpid();       if ((child = fork()) == 0) {         void *addr2 = mmap(NULL, TEST_SIZE, PROT_READ | PROT_WRITE,                            MAP_ANONYMOUS | MAP_PRIVATE, 0, 0);         assert(addr2 != MAP_FAILED);         memset(addr2, 'a', TEST_SIZE);         pwrite(fd, addr2, TEST_SIZE, (uintptr_t)addr);         return 0;       }       assert(child == waitpid(child, &status, 0));       assert(WIFEXITED(status) && WEXITSTATUS(status) == 0);       return 0;     }  Fix this by updating follow_trans_huge_pmd in huge_memory.c analogously to the update in gup.c in the original commit.  The same pattern exists in follow_devmap_pmd.  However, we should not be able to reach that check with FOLL_COW set, so add WARN_ONCE to make sure we notice if we ever do.  [URL]: coding-style fixes] Link: [URL]",0,0
"python3-pillow: Upgrade 8.3.2 -> 9.0.0  Upgrade to release 9.0.0:  - Restrict builtins for ImageMath.eval() - Ensure JpegImagePlugin stops at the end of a truncated file - Fixed ImagePath.Path array handling - Remove consecutive duplicate tiles that only differ by their   offset - Removed redundant part of condition - Explicitly enable strip chopping for large uncompressed TIFFs - Use the Windows method to get TCL functions on Cygwin - Changed error type to allow for incremental WebP parsing - Improved I;16 operations on big endian - Ensure that BMP pixel data offset does not ignore palette - Limit quantized palette to number of colors - Use latin1 encoding to decode bytes - Fixed palette index for zeroed color in FASTOCTREE quantize - When saving RGBA to GIF, make use of first transparent palette   entry - Pass SAMPLEFORMAT to libtiff - Added rounding when converting P and PA - Improved putdata() documentation and data handling - Exclude carriage return in PDF regex to help prevent ReDoS - Image.NONE is only used for resampling and dithers - Fixed freeing pointer in ImageDraw.Outline.transform - Add Tidelift alignment action and badge - Replaced further direct invocations of setup.py - Added ImageShow support for xdg-open - Switched from deprecated ""setup.py install"" to ""pip install ."" - Support 16-bit grayscale ImageQt conversion - Fixed raising OSError in _safe_read when size is greater than   SAFEBLOCK - Convert subsequent GIF frames to RGB or RGBA - WebP: Fix memory leak during decoding on failure - Do not prematurely return in ImageFile when saving to stdout - Added support for top right and bottom right TGA orientations - Corrected ICNS file length in header - Block tile TIFF tags when saving - Added line width argument to ImageDraw polygon - Do not redeclare class each time when converting to NumPy - Only prevent repeated polygon pixels when drawing with   transparency - Fix pushes_fd method signature - Add support for pickling TrueType fonts - Only prefer command line tools SDK on macOS over default   MacOSX SDK - Fix compilation on 64-bit Termux - Replace 'setup.py sdist' with '-m build --sdist' - Use declarative package configuration - Use title for display in ImageShow - Fix for PyQt6 - Rename master to main",0,0
"kmix: Pass the signal for redrawing a single mixer right through to the KMixWindow.  This contains no functionality change, but it will allow us to redraw our window in a more efficient manner with some further development.  svn path=/trunk/KDE/kdemultimedia/kmix/; revision=1110904",0,0
Specs for dynamic token replacement and multiple captures,0,0
"chore: add grunt configure to run on pre-commit hook (#1244)  **Short Description:**  Preventing us to open PR's like this - [URL]/dequelabs/axe-core/pull/1184    **Long Description:**  There has been several PR's in the past, where changes are done, but the `rule-descriptions` are not updated, because `build` was not run as a part of the development efforts.    These usually happen when the metadata of a rule spec or check spec is changed.     Overhead being unrelated changes show up on other work.    This PR adds `grunt configure`, which builds `doc/rule-descriptions.md` as a part of pre-commit hook. This should alleviate the above     Closes issue: NA    ## Reviewer checks    **Required fields, to be filled out by PR reviewer(s)**  - [x] Follows the commit message policy, appropriate for next version  - [x] Has documentation updated, a DU ticket, or requires no documentation change  - [x] Includes new tests, or was unnecessary  - [x] Code is reviewed for security by: @WilcoFiers",0,0
msm: wfd: Free ion handle on unmap  This commit fixes a memory leak incurred by not freeing the acquired handle after ion_import_dma_buf.,0,0
"Use [URL] JSON format in results page [URL]/show_bug.cgi?id=110842  Reviewed by Benjamin Poulain.  PerformanceTests:   Updated the results page template to use the new JSON format.  Since new JSON format doesn't contain statistics such as stdev and min, added statistics.js to compute these values. Also use 95% percentile confidence interval instead of standard deviation in various places.  * resources/results-template.html: Added statistics.js as dependency. (TestResult): Updated to take a metric instead of its test. Replaced stdev() with confidenceIntervalDelta() now that we have a fancy Statistics class.  (TestRun.webkitRevision): (PerfTestMetric): Renamed from PerfTest since this object now encapsulates each measurement (such as time, JS heap, and malloc) in test. Also added a conversion table from a metric name to a unit since new format doesn't contain units. (PerfTestMetric.name): Updated to compute the full metric name from test name and metric name, matching the old behavior. (PerfTestMetric.isMemoryTest): Explicitly look for 'JSHeap' and 'Malloc' tests. (PerfTestMetric.smallerIsBetter):  (attachPlot): Deleted the code to deal with tests that don't provide individual iteration measurement since such tests no longer exist. Also fixed up the code compute y-axis range.  (createTableRow.markupForRun): Updated to use confidenceIntervalDelta() instead of stdev().          (init.addTests): Added. Recursively add metrics.  * resources/statistics.js: Added. Imported from [URL]. (Statistics.max): (Statistics.min): (Statistics.sum): (Statistics.squareSum): (Statistics.sampleStandardDeviation): (Statistics.supportedConfidenceLevels): (Statistics.confidenceIntervalDelta): (Statistics.confidenceInterval):  Tools:   Change the default JSON format from that of [URL] to that of [URL].  A whole bunch of integration tests have been updated to use the new JSON format.  * Scripts/webkitpy/performance_tests/perftestsrunner.py: (PerfTestsRunner._generate_and_show_results): Renamed output and output_path to legacy_output and legacy_output_json_path respectively. (PerfTestsRunner._generate_results_dict): Don't assume meta build information is always available. (PerfTestsRunner._generate_output_files): Make json_output, which is used to generate the default JSON file and the results page out of perf_webkit_output instead of legacy_output.  * Scripts/webkitpy/performance_tests/perftestsrunner_integrationtest.py: (MainTest.test_run_memory_test): (MainTest._test_run_with_json_output.mock_upload_json): (MainTest): (MainTest.test_run_with_json_output): (MainTest.test_run_with_description): (MainTest.test_run_generates_json_by_default): (MainTest.test_run_merges_output_by_default): (MainTest.test_run_respects_reset_results): (MainTest.test_run_generates_and_show_results_page): (MainTest.test_run_with_slave_config_json): (MainTest.test_run_with_multiple_repositories): (MainTest.test_run_with_upload_json): (MainTest.test_run_with_upload_json_should_generate_perf_webkit_json):",0,0
"Portlet AnnotationMethodHandlerAdapter resolves PortletPreferences, PortletMode, WindowState, PortalContext arguments; improved exception messages",0,0
"Merge #13194: Remove template matching and pseudo opcodes  c814e2e7e81fd01fcb07f4a28435741bdc463801 Remove template matching and pseudo opcodes (Pieter Wuille)  Pull request description:    The current code contains a rather complex script template matching engine, which is only used for 3 particular script types (P2PK, P2PKH, multisig). The first two of these are trivial to match for otherwise, and a specialized matcher for multisig is both more compact and more efficient than a generic one.    The goal is being more flexible, so that for example larger standard multisigs inside SegWit outputs are easier to implement.    As a side-effect, it also gets rid of the pseudo opcodes hack.  Tree-SHA512: 643b409c5c36821519f613a43efd399af0ec99b6131f35cd4024decfb2d483d719e0e921cd088bc9832a7ac797cb4a6b1158b8574c82f7fbebb75f1b31b359df",0,0
"kernel/smp.c: free related resources when failure occurs in hotplug_cfd()  When failure occurs in hotplug_cfd(), need release related resources, or will cause memory leak.",0,0
boot:dtsi: Add the active current values in uA for the cpus in device tree.  Bug: 21498425,0,0
Merge pull request #5 from chef-buddy/add_logging  fixed bug in food compound normalization algorithm,0,0
improved looks of performance data screen,0,0
(Fdo_auto_save): Handle the case that echo_area_message is set. (Finsert_file_contents): Prevent redisplay optimizations. (Fread_file_name): Call it. (report_file_error): Return void.,0,0
"From 7bddc2ba16a2a15773c2ea8947059afa27727764 Mon Sep 17 00:00:00 2001 From: Alan Coopersmith <alan.coopersmith at [URL]> Date: Mon, 16 Sep 2013 21:47:16 -0700 Subject: [PATCH] Avoid use-after-free in dix/dixfonts.c: doImageText()  [CVE-2013-4396]  Save a pointer to the passed in closure structure before copying it and overwriting the *c pointer to point to our copy instead of the original.  If we hit an error, once we free(c), reset c to point to the original structure before jumping to the cleanup code that references *c.  Since one of the errors being checked for is whether the server was able to malloc(c->nChars * itemSize), the client can potentially pass a number of characters chosen to cause the malloc to fail and the error path to be taken, resulting in the read from freed memory.  Since the memory is accessed almost immediately afterwards, and the X server is mostly single threaded, the odds of the free memory having invalid contents are low with most malloc implementations when not using memory debugging features, but some allocators will definitely overwrite the memory there, leading to a likely crash.  Reported-by: Pedro Ribeiro <pedrib at [URL]>",0,0
Added Tests/HistoricalReferenceOutput/PerformanceDump-v2.0a114-x86-ReleaseU.txt (very slight speedups except sharedptr slower - cuz actually deleting more I'm guessing) - maybe nothing significant,0,0
padd dynamic_id to process.   	* operations/file-io/exr-load.cpp: padd dynamic_id to process.,0,0
"Bring back the Connect to dialog. It still needs some work, but it's  2008-02-21  Vincent Untz  [URL]>  	Bring back the Connect to dialog. It still needs some work, but it's 	better than nothing.  	* libnautilus-private/nautilus-bookmark.c: (nautilus_bookmark_new): 	Actually save the name in the bookmark, instead of forgetting it.  	* src/Makefile.am: Updated to build the connect dialog stuff. 	* src/nautilus-connect-server-dialog-main.c: (show_uri), 	(nautilus_connect_server_dialog_present_uri), (main): 	Port to gio. We use g_app_info_launch_default_for_uri() to open the 	URI, but it will need some more work because it doesn't automount the 	URI. 	* src/nautilus-connect-server-dialog-nonmain.c: 	(nautilus_connect_server_dialog_present_uri): Trivial update. 	* src/nautilus-connect-server-dialog.[ch]: (get_method_description), 	(nautilus_connect_server_dialog_finalize), (connect_to_server), 	(response_callback), (setup_for_type), (display_server_location), 	(nautilus_connect_server_dialog_init), 	(nautilus_connect_server_dialog_new): Port to gio. Add bookmark saving 	feature, to replace the old gnome-vfs network volumes. Remove the 	Browse button, which isn't really needed there. Needs some more polish. 	* src/nautilus-shell-ui.xml: Uncomment the ""Connect to"" action 	* src/nautilus-window-menus.c: (action_connect_to_server_callback): 	Uncomment code to make use of the dialog  svn path=/trunk/; revision=13797",0,0
"mtd: fix: avoid race condition when accessing mtd->usecount  commit 073db4a51ee43ccb827f54a4261c0583b028d5ab upstream.  On A MIPS 32-cores machine a BUG_ON was triggered because some acesses to mtd->usecount were done without taking mtd_table_mutex. kernel: Call Trace: kernel: [<ffffffff80401818>] __put_mtd_device+0x20/0x50 kernel: [<ffffffff804086f4>] blktrans_release+0x8c/0xd8 kernel: [<ffffffff802577e0>] __blkdev_put+0x1a8/0x200 kernel: [<ffffffff802579a4>] blkdev_close+0x1c/0x30 kernel: [<ffffffff8022006c>] __fput+0xac/0x250 kernel: [<ffffffff80171208>] task_work_run+0xd8/0x120 kernel: [<ffffffff8012c23c>] work_notifysig+0x10/0x18 kernel: kernel:         Code: 2442ffff  ac8202d8  000217fe <00020336> dc820128  10400003                00000000  0040f809  00000000 kernel: ---[ end trace 080fbb4579b47a73 ]---  Fixed by taking the mutex in blktrans_open and blktrans_release.  Note that this locking is already suggested in include/linux/mtd/blktrans.h:  struct mtd_blktrans_ops { ... 	/* Called with mtd_table_mutex held; no race with add/remove */ 	int (*open)(struct mtd_blktrans_dev *dev); 	void (*release)(struct mtd_blktrans_dev *dev); ... };  But we weren't following it.  Originally reported by (and patched by) Zhang and Giuseppe, independently. Improved and rewritten.  Reported-by: Zhang Xingcai [URL]> Reported-by: Giuseppe Cantavenera [URL]> Tested-by: Giuseppe Cantavenera [URL]> Acked-by: Alexander Sverdlin [URL]>",0,0
Add AZ64 encoding  AZ64 encoding was added to redshift on 10/8/19 and is now the default encoding for many datatypes.  let's support it.  [URL]/about-aws/whats-new/2019/10/amazon-redshift-introduces-az64-a-new-compression-encoding-for-optimized-storage-and-high-query-performance/,0,1
"Cult Overhaul  Cult is awful, so let's try to improve it. Idea by KorPhaeron. I also took some inspiration from adrix89's sacrifice cult, so credits to him. Also thanks a lot specially to MrPerson and Iamgoofball for helping me brainstorm this, and Joan for the sprites for the summoning orb, the large nar-sie shell, and the new cult antag hud.  Basically, we remove conversion, and turn cult into a magic version of nuke, with a small team of stealth elite cultists that have to build a base in the station and sacrifice people in order to build an army of constructs and get materials to eventually summon Nar-Sie.  Stun talismans and conversion are gone. Nar-Sie is now the only objective. Sacrifice runes now provide summoning orbs, which you can use to drop a large shell. Insert enough orbs in the shell and you trigger a Delta. Defend the shell for 3 minutes and Nar-sie will arise. This shell is bombproof and singularityproof. It may be summoned up to three times if destroyed, but you will have to start from the beginning sac-wise.  Runes are now RNG. Each cultist only gets 50% of the runes. Inspiration is basically The Binding of Isaac here (thank you MrPerson for this!). Furthermore, many old runes were merged/removed and other new ones were added. Almost all were massively rebalanced. Cult now also has a stealthy ritual dagger with high bleeding and throw effects.",0,0
"PM / devfreq: Add cache HW monitor governor  The cache HW monitor devfreq governor uses the hardware counters to determine the load on the cache and the appropriate frequency needed to support that load. This governor can be used in conjunction with the cache devfreq device to dynamically scale the cache frequency based on the demand/actual usage from the CPU subsystem.  The governor is written to be agnostic of the actual counters used to determine the load. On Krait based CPUs, the governor uses the Krait L2 PM counters which can conflict with certain profiling tools.  The Krait L2 performance monitor counters have the capability to count different types of requests going to the L2 cache. They also have the capability to raise interrupts when they overflow. This driver uses those counters to determine the true usage of L2 from the Krait processor subsystem and then recommends L2 frequency based on the measured values and the following tunable parameters.  The driver provides various tunables that allow it to be tuned more in favor of power or performance:  - cycles_per_high_req: The no. of cache clock cycles that are necessary to   efficiently process a high-work request to the cache. A higher value   means higher power and potentially higher performance. A lower value   means lower power and potentially lower performance.  - cycles_per_med_req: The no. of cache clock cycles that are necessary to   efficiently process a medium-work request to the cache. A higher value   means higher power and potentially higher performance. A lower value   means lower power and potentially lower performance.  - polling_ms: The sampling period in milliseconds. This only affects the   sampling period when cache use is ramping down or is increasing very   slowly (See tolerance_mrps).  - min_busy: The minimum percentage of time the cache should be busy. This   is also applied as a lower bound to the measured busy percentage before   it's used in calculations. This has to be lower than or equal to   max_busy. Lower values will make the scaling more aggressive.  - max_busy: The maximum percentage of time the cache should be busy. This   is also applied as an upper bound to the measured busy percentage before   it's used in calculations. This has to be greater than or equal to   min_busy. Lower values will make the scaling more aggressive.  - tolerance_mrps: The minimum increase (in millions of requests per second)   in cache requests, compared to previous sample, that will trigger an IRQ   to immediately re-evaluate the cache frequency.  - decay_rate: The parameter controls the rate at which the history is   forgotten when ramping down. This is expressed as a percentage of history   to be forgotten. So 100% means ignore history, 0% means never forget the   historical max. The default 90% means forget 90% of history each time.  - guard_band_mhz: This is a margin that's added to the computed cache   frequency to account for the time it takes between the load increasing   and the governor/device finishes ramping up the cache frequency.",0,1
"Enable certain config options without segfault  Fixes the `show_recruit_stats` and `use_endurance` configuration options so they will no longer cause a segmentation fault. The need_alloc fields for the corresponding entries in the config_string array were accidentally being set non-zero. This caused inappropriate memory reallocation attempts, leading to a segmentation fault.",0,0
BigSwitch: sync state on disassociate floating ip  Sends the state of port's parent network to the backend controller when a floating IP is disassociated from a port.  Closes-Bug: #1235074,0,0
"Use absolute-url instead of passing baseUrl's around  While at it, some minor fixes and improvements, and make account enrollment emails contain the right url.",0,0
Merge branch 'master' into use-pebblebed-wildcards  * master:   Don't open up for injection attacks   Set proper Cache-control header   Add `direction` option for getting posts.   Add filtering on external id   Update bengler-capistrano   Minor readability improvement   Use a common method for both POST and PUT   Add put method   Logging passes tests   Silenced activerecord log,0,0
"rcu: Remove comment referring to __stop_machine()  Although it used to be that CPU_DYING notifiers executed on the outgoing CPU with interrupts disabled and with all other CPUs spinning, this is no longer the case.  This commit therefore removes this obsolete comment.",0,0
Merge commit '502e64fe23f19c086d42f6178cdda19e58996080' into upstream-merge  * commit '502e64fe23f19c086d42f6178cdda19e58996080': (23 commits)   target-arm: fix strexd   linux-user: fix build with gcc-4.1   linuxboot.bin is a generated file   qemu-nbd: fix OpenBSD linker warning   e1000: add link to data sheet   qemu-io: suppress a warning with gcc 4.0.2   Compile qemu-nbd also on OpenBSD and Solaris   USB: Improve usbdevice error messages   target-alpha: Initialize fpcr   tcg-sparc: Implement brcond2.   tcg-sparc: Use TCG_TARGET_REG_BITS in conditional compilation.   tcg-sparc: Improve tcg_out_movi for sparc64.   tcg-sparc: Fix imm13 check in movi.   ARM PBX-A9 memory map tweaks   LAN9118 improvements   PPC: Make DCR uint32_t   PPC64: Fix alternate timebase   PPC64: Fix timebase   target-alpha: Emit tcg debug_insn_start.   linux-user: Add aliases for some Alpha syscalls   ...,0,0
"improve logging set up to survive multiple command executions  This patch improves geogit cli logging set up to properly resolve the logging file and current dir upon multiple command executions and makes geogit-console batch mode (runFile()) to set up logging too, and also avoids code duplication in cli exception handling between cli and console.",0,0
Use global memory for the various _str functions as much as possible,0,0
Start sender after receivers to improve debugability,0,0
Add comment referencing Chrome performance bug for Array.splice.,0,0
new file:   clean_extra_files.sh 	modified:   compile_modules_extra.sh 	modified:   doc/install.txt 	new file:   ircd.log 	modified:   settings/network/sslcerts.conf 	modified:   settings/vhost/vhost.conf,0,0
powerpc/oprofile: Handle events that raise an exception without overflowing  commit ad5d5292f16c6c1d7d3e257c4c7407594286b97e upstream.  Commit 0837e3242c73566fc1c0196b4ec61779c25ffc93 fixes a situation on POWER7 where events can roll back if a specualtive event doesn't actually complete. This can raise a performance monitor exception.  We need to catch this to ensure that we reset the PMC.  In all cases the PMC will be less than 256 cycles from overflow.  This patch lifts Anton's fix for the problem in perf and applies it to oprofile as well.,0,1
Merge pull request #2 from M4R7iNP/master  Improved indenting and syntax highlighting,0,0
Restore inband due to memory issues,0,0
"Increase serialize(no-crc) target benchmark  Following changes to the Linux Kernel to handle RETBLEED mitigations Skylake CPUs perform signicantly worse.  This affects the Firecracker baseline for all Intel testing. Until Firecracker's CI and performance pipelines can move off of Skylake, we will need drop our baseline to prevent unrelated disruptions to our pipeline.",0,0
[Druid] Minor Feral APL (incarnation improvement) and regenerate profiles.,0,0
chore(main): release 0.167.0 (#3482)  :robot: I have created a release *beep* *boop* ---   ## [URL]/googleapis/java-cloud-bom/compare/v0.166.0...v0.167.0) (2022-02-07)   ### Features  * add google-cloud-logging-servlet-initializer [URL]/googleapis/java-cloud-bom/issues/3496)) [URL]/googleapis/java-cloud-bom/commit/a147d91d6846323cc47590b0eaf5420e7c45d9e9))   ### Dependencies  * **java:** update actions/github-script action to v5 [URL]/googleapis/java-cloud-bom/issues/1339)) [URL]/googleapis/java-cloud-bom/issues/3487)) [URL]/googleapis/java-cloud-bom/commit/952a72c4d8dbd7f1403b0a411233d01388d178f5)) * update actions/github-script action to v5 [URL]/googleapis/java-cloud-bom/issues/3485)) [URL]/googleapis/java-cloud-bom/commit/d28173dabf03b1265d21dd986a75b3c0eba800d7)) * update dependency com.google.cloud:google-cloud-accessapproval-bom to v2.1.10 [URL]/googleapis/java-cloud-bom/issues/3499)) [URL]/googleapis/java-cloud-bom/commit/3fdf876465e2c4fc06c7262f0881a8fc576eccb2)) * update dependency com.google.cloud:google-cloud-aiplatform-bom to v2.6.0 [URL]/googleapis/java-cloud-bom/issues/3524)) [URL]/googleapis/java-cloud-bom/commit/83429c2dece64417f006ed52c9536b0c8486e8f1)) * update dependency com.google.cloud:google-cloud-api-gateway-bom to v2.1.7 [URL]/googleapis/java-cloud-bom/issues/3500)) [URL]/googleapis/java-cloud-bom/commit/1750d638d6fc914254d41e7c077e44961028b540)) * update dependency com.google.cloud:google-cloud-artifact-registry to v1.0.0 [URL]/googleapis/java-cloud-bom/issues/3556)) [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-asset-bom to v3.2.14 [URL]/googleapis/java-cloud-bom/issues/3501)) [URL]/googleapis/java-cloud-bom/commit/a8d899f5deb7a4f86042e0724c94c860a568a7fd)) * update dependency com.google.cloud:google-cloud-assured-workloads to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-automl-bom to v2.1.13 [URL]/googleapis/java-cloud-bom/issues/3468)) [URL]/googleapis/java-cloud-bom/commit/b3b073db99f5500dee0d9b4826e83c90249bc612)) * update dependency com.google.cloud:google-cloud-automl-bom to v2.1.14 [URL]/googleapis/java-cloud-bom/issues/3559)) [URL]/googleapis/java-cloud-bom/commit/69f96b988c02456d63de30ae5e4977cd045961ff)) * update dependency com.google.cloud:google-cloud-bigquery to v2.6.2 [URL]/googleapis/java-cloud-bom/issues/3474)) [URL]/googleapis/java-cloud-bom/commit/e51135e8de7daa847dca2a1d25a30f74728208df)) * update dependency com.google.cloud:google-cloud-bigquery to v2.7.1 [URL]/googleapis/java-cloud-bom/issues/3489)) [URL]/googleapis/java-cloud-bom/commit/a4478a990eb25e2311dc098deeeb6ec780f1a2e3)) * update dependency com.google.cloud:google-cloud-bigquery to v2.8.0 [URL]/googleapis/java-cloud-bom/issues/3495)) [URL]/googleapis/java-cloud-bom/commit/524adaf8c4d80fbea3ccde7768b69bf88b4f31fe)) * update dependency com.google.cloud:google-cloud-bigqueryconnection-bom to v2.1.9 [URL]/googleapis/java-cloud-bom/issues/3560)) [URL]/googleapis/java-cloud-bom/commit/f0fb44722077df7fce896400470e32fb93844d9d)) * update dependency com.google.cloud:google-cloud-bigquerydatatransfer-bom to v2.1.0 [URL]/googleapis/java-cloud-bom/issues/3491)) [URL]/googleapis/java-cloud-bom/commit/c9b9ca30ffbb9adb9c28e007030c123a88c97552)) * update dependency com.google.cloud:google-cloud-bigquerydatatransfer-bom to v2.1.1 [URL]/googleapis/java-cloud-bom/issues/3561)) [URL]/googleapis/java-cloud-bom/commit/7f248e6c51baf49ea266fb8d5b4b5b05063f21be)) * update dependency com.google.cloud:google-cloud-bigqueryreservation-bom to v2.2.2 [URL]/googleapis/java-cloud-bom/issues/3571)) [URL]/googleapis/java-cloud-bom/commit/52542f7aa272ec0383c2582a18190aed70ac7fbd)) * update dependency com.google.cloud:google-cloud-bigquerystorage-bom to v2.8.3 [URL]/googleapis/java-cloud-bom/issues/3488)) [URL]/googleapis/java-cloud-bom/commit/6d56f31004eae92678f6635667d1a621c98ba874)) * update dependency com.google.cloud:google-cloud-bigquerystorage-bom to v2.8.4 [URL]/googleapis/java-cloud-bom/issues/3562)) [URL]/googleapis/java-cloud-bom/commit/51efe46bb86082d8ff6feb16163165c898d5a4e3)) * update dependency com.google.cloud:google-cloud-bigtable-bom to v2.5.2 [URL]/googleapis/java-cloud-bom/issues/3492)) [URL]/googleapis/java-cloud-bom/commit/0177bc1faa63a18bc12fe756153cbb8ef082d1c8)) * update dependency com.google.cloud:google-cloud-billing-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3502)) [URL]/googleapis/java-cloud-bom/commit/004e924af73d9a65990d72c0be2a1e01011a15cc)) * update dependency com.google.cloud:google-cloud-billingbudgets-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3503)) [URL]/googleapis/java-cloud-bom/commit/976336a368a8b482aa7cf8277e714cbd22a6b541)) * update dependency com.google.cloud:google-cloud-binary-authorization to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-build-bom to v3.3.8 [URL]/googleapis/java-cloud-bom/issues/3504)) [URL]/googleapis/java-cloud-bom/commit/6ae8d67334f6b6e809314701cdf551f31746ff55)) * update dependency com.google.cloud:google-cloud-channel-bom to v3.4.0 [URL]/googleapis/java-cloud-bom/issues/3525)) [URL]/googleapis/java-cloud-bom/commit/5c92f019d265eb3d707efed1fe4b77e40a2e97e6)) * update dependency com.google.cloud:google-cloud-compute-bom to v1.7.0 [URL]/googleapis/java-cloud-bom/issues/3478)) [URL]/googleapis/java-cloud-bom/commit/b8dcf89bf535b7f1b53a48becbee994c2d523b4c)) * update dependency com.google.cloud:google-cloud-compute-bom to v1.7.1 [URL]/googleapis/java-cloud-bom/issues/3586)) [URL]/googleapis/java-cloud-bom/commit/b990333f32a1ca2b9e6adce07ca14a26395001eb)) * update dependency com.google.cloud:google-cloud-container-bom to v2.3.2 [URL]/googleapis/java-cloud-bom/issues/3493)) [URL]/googleapis/java-cloud-bom/commit/1343394033432efdb151272a0d1d8d29658c7a04)) * update dependency com.google.cloud:google-cloud-containeranalysis-bom to v2.2.7 [URL]/googleapis/java-cloud-bom/issues/3563)) [URL]/googleapis/java-cloud-bom/commit/45ef652350a74c77e0c4ca177177c3eb239f810d)) * update dependency com.google.cloud:google-cloud-data-fusion to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-datacatalog-bom to v1.6.3 [URL]/googleapis/java-cloud-bom/issues/3505)) [URL]/googleapis/java-cloud-bom/commit/27eec33e09f1f8f34d84c1ec41511a8ff38078bf)) * update dependency com.google.cloud:google-cloud-datalabeling-bom to v0.122.6 [URL]/googleapis/java-cloud-bom/issues/3506)) [URL]/googleapis/java-cloud-bom/commit/aac9ce19f7d17cdc54a889a06bb7a74e905c11ae)) * update dependency com.google.cloud:google-cloud-dataproc-bom to v2.3.2 [URL]/googleapis/java-cloud-bom/issues/3507)) [URL]/googleapis/java-cloud-bom/commit/719612834b12bde62ad6c8262ae6e052f569eaba)) * update dependency com.google.cloud:google-cloud-dataproc-metastore-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3528)) [URL]/googleapis/java-cloud-bom/commit/c017036d3f3ed1eb2c06ac0d65e97e72b78b30ed)) * update dependency com.google.cloud:google-cloud-datastore-bom to v2.2.3 [URL]/googleapis/java-cloud-bom/issues/3494)) [URL]/googleapis/java-cloud-bom/commit/a3f965e46d2a60fdb07a3518ba607b4fe93574a1)) * update dependency com.google.cloud:google-cloud-datastore-bom to v2.2.4 [URL]/googleapis/java-cloud-bom/issues/3564)) [URL]/googleapis/java-cloud-bom/commit/7873e94ba03c88d3cd0a1fb8bfb527d415900de9)) * update dependency com.google.cloud:google-cloud-debugger-client-bom to v1.1.6 [URL]/googleapis/java-cloud-bom/issues/3529)) [URL]/googleapis/java-cloud-bom/commit/fab1bc70a67102283ce683244d2ef4c13ccc801e)) * update dependency com.google.cloud:google-cloud-deploy to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-dialogflow-bom to v4.5.0 [URL]/googleapis/java-cloud-bom/issues/3526)) [URL]/googleapis/java-cloud-bom/commit/0a2bdd6165ca4259ee5e50abc0421301c5beb3c6)) * update dependency com.google.cloud:google-cloud-dlp-bom to v3.1.2 [URL]/googleapis/java-cloud-bom/issues/3530)) [URL]/googleapis/java-cloud-bom/commit/72da3e120a081f63e8389d23d2fea05e0744c70b)) * update dependency com.google.cloud:google-cloud-dms-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3531)) [URL]/googleapis/java-cloud-bom/commit/e2c755687c3c58549c0619f2cdc2fb09b03002ef)) * update dependency com.google.cloud:google-cloud-dns to v2.0.5 [URL]/googleapis/java-cloud-bom/issues/3532)) [URL]/googleapis/java-cloud-bom/commit/b41a6080f6573df9ad949011fa17fc65698546de)) * update dependency com.google.cloud:google-cloud-document-ai-bom to v2.2.0 [URL]/googleapis/java-cloud-bom/issues/3569)) [URL]/googleapis/java-cloud-bom/commit/3dad26a0c2949460fa1ebc6838d8c65e0920a4c1)) * update dependency com.google.cloud:google-cloud-errorreporting-bom to v0.122.11-beta [URL]/googleapis/java-cloud-bom/issues/3472)) [URL]/googleapis/java-cloud-bom/commit/f26db2236827066aa4761eede894195213822254)) * update dependency com.google.cloud:google-cloud-errorreporting-bom to v0.122.12-beta [URL]/googleapis/java-cloud-bom/issues/3533)) [URL]/googleapis/java-cloud-bom/commit/c33b96c7c92fc9d36368affb37ab7ebc49673dfa)) * update dependency com.google.cloud:google-cloud-essential-contacts-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3534)) [URL]/googleapis/java-cloud-bom/commit/61e58a5242ead9a0045952c3c10436f4950c75e2)) * update dependency com.google.cloud:google-cloud-eventarc-bom to v1.2.0 [URL]/googleapis/java-cloud-bom/issues/3570)) [URL]/googleapis/java-cloud-bom/commit/55d4e926444d616e3d2c84813655cd126f248b3b)) * update dependency com.google.cloud:google-cloud-filestore-bom to v1.1.6 [URL]/googleapis/java-cloud-bom/issues/3555)) [URL]/googleapis/java-cloud-bom/commit/9e65a1e12e5791b1f62b8fc21e61caa0ce8dea3a)) * update dependency com.google.cloud:google-cloud-firestore-bom to v3.0.11 [URL]/googleapis/java-cloud-bom/issues/3490)) [URL]/googleapis/java-cloud-bom/commit/81d522936c81eab6a13daea4c87402ed253608b3)) * update dependency com.google.cloud:google-cloud-firestore-bom to v3.0.12 [URL]/googleapis/java-cloud-bom/issues/3590)) [URL]/googleapis/java-cloud-bom/commit/44a5c94b7f2160a2a14dc8d9455274e946830768)) * update dependency com.google.cloud:google-cloud-functions-bom to v2.3.2 [URL]/googleapis/java-cloud-bom/issues/3572)) [URL]/googleapis/java-cloud-bom/commit/c1fea47f6156adea885bcec70220e2e36a2b5001)) * update dependency com.google.cloud:google-cloud-game-servers-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3535)) [URL]/googleapis/java-cloud-bom/commit/03af3e3dc6d15920280338f4c570cb8212aa5de2)) * update dependency com.google.cloud:google-cloud-gkehub to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-gsuite-addons-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3565)) [URL]/googleapis/java-cloud-bom/commit/a968dc643f7078ee4c68a4a17927dbeafb1eda24)) * update dependency com.google.cloud:google-cloud-iamcredentials-bom to v2.0.9 [URL]/googleapis/java-cloud-bom/issues/3566)) [URL]/googleapis/java-cloud-bom/commit/47f37a88667f08a24c9f4b6a47176f81d3d718a4)) * update dependency com.google.cloud:google-cloud-ids to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-iot-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3546)) [URL]/googleapis/java-cloud-bom/commit/f6dc218c04bba216c35bad159017cf1d7a26b742)) * update dependency com.google.cloud:google-cloud-kms-bom to v2.4.0 [URL]/googleapis/java-cloud-bom/issues/3527)) [URL]/googleapis/java-cloud-bom/commit/28052d4fcff1c8408f77eae7c237e135bc26ec04)) * update dependency com.google.cloud:google-cloud-language-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3547)) [URL]/googleapis/java-cloud-bom/commit/0bda6a2ebf78c21a3837ad3c6c455240fba5a02d)) * update dependency com.google.cloud:google-cloud-logging-bom to v3.6.0 [URL]/googleapis/java-cloud-bom/issues/3475)) [URL]/googleapis/java-cloud-bom/commit/4891d92e6d4df3e3af286b0cb24e2ba2ccbfbf35)) * update dependency com.google.cloud:google-cloud-logging-bom to v3.6.1 [URL]/googleapis/java-cloud-bom/issues/3484)) [URL]/googleapis/java-cloud-bom/commit/7acdc3ae1974984ba2ae6836ba7ed9d75c619fd5)) * update dependency com.google.cloud:google-cloud-logging-bom to v3.6.2 [URL]/googleapis/java-cloud-bom/issues/3573)) [URL]/googleapis/java-cloud-bom/commit/ef8b8cefb8356da7fa60db0da89cb234ec2cea9c)) * update dependency com.google.cloud:google-cloud-logging-logback to v0.122.9-alpha [URL]/googleapis/java-cloud-bom/issues/3469)) [URL]/googleapis/java-cloud-bom/commit/b06e24f95c7499c2ae18bdbd5324ac444a97e951)) * update dependency com.google.cloud:google-cloud-logging-logback to v0.123.0-alpha [URL]/googleapis/java-cloud-bom/issues/3483)) [URL]/googleapis/java-cloud-bom/commit/73a1ef0e2f07a4a0c00c92f8fbe7e2ff11be31c1)) * update dependency com.google.cloud:google-cloud-logging-logback to v0.123.1-alpha [URL]/googleapis/java-cloud-bom/issues/3574)) [URL]/googleapis/java-cloud-bom/commit/19c46bfd8c0affe3c60b0f5843eecd3cdc295ce2)) * update dependency com.google.cloud:google-cloud-managed-identities to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-mediatranslation-bom to v0.7.6 [URL]/googleapis/java-cloud-bom/issues/3548)) [URL]/googleapis/java-cloud-bom/commit/92f395f6c5a8040125aa4fcb0f7b37bf8bf47cd0)) * update dependency com.google.cloud:google-cloud-memcache-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3557)) [URL]/googleapis/java-cloud-bom/commit/55b951972961d54679ad6cfed4244093d671de0c)) * update dependency com.google.cloud:google-cloud-monitoring-bom to v3.2.2 [URL]/googleapis/java-cloud-bom/issues/3549)) [URL]/googleapis/java-cloud-bom/commit/fc71b1c441aa832714c264899f5f3b45633d2710)) * update dependency com.google.cloud:google-cloud-monitoring-dashboard-bom to v2.2.2 [URL]/googleapis/java-cloud-bom/issues/3558)) [URL]/googleapis/java-cloud-bom/commit/3d387e8cc093dd27238e8b7d0a268615586655c1)) * update dependency com.google.cloud:google-cloud-network-management-bom to v1.1.6 [URL]/googleapis/java-cloud-bom/issues/3508)) [URL]/googleapis/java-cloud-bom/commit/c662afdc810602de3f04fa3581f123fa75483abd)) * update dependency com.google.cloud:google-cloud-networkconnectivity to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-nio to v0.123.19 [URL]/googleapis/java-cloud-bom/issues/3509)) [URL]/googleapis/java-cloud-bom/commit/13279cfe7f9c83e4668879335d9290f057b9c26b)) * update dependency com.google.cloud:google-cloud-notification to v0.122.17-beta [URL]/googleapis/java-cloud-bom/issues/3575)) [URL]/googleapis/java-cloud-bom/commit/7665f59a49d90416fbd1634afc31d1f3f7e552ce)) * update dependency com.google.cloud:google-cloud-orchestration-airflow-bom to v1.1.2 [URL]/googleapis/java-cloud-bom/issues/3510)) [URL]/googleapis/java-cloud-bom/commit/cafdbce481feee4cfbddc0d6fc51950e27eb4ef6)) * update dependency com.google.cloud:google-cloud-orgpolicy-bom to v2.0.9 [URL]/googleapis/java-cloud-bom/issues/3511)) [URL]/googleapis/java-cloud-bom/commit/0b43c681fdfdb1f1a0a2837a0a3f74c2cca944f7)) * update dependency com.google.cloud:google-cloud-os-config-bom to v2.3.2 [URL]/googleapis/java-cloud-bom/issues/3582)) [URL]/googleapis/java-cloud-bom/commit/987ad62bf2ae1578ad06ade27d2875c93fa8dabd)) * update dependency com.google.cloud:google-cloud-os-login-bom to v2.0.9 [URL]/googleapis/java-cloud-bom/issues/3512)) [URL]/googleapis/java-cloud-bom/commit/edafd522232ee2dd822b975a8a34dc1f26f3dc55)) * update dependency com.google.cloud:google-cloud-phishingprotection-bom to v0.32.6 [URL]/googleapis/java-cloud-bom/issues/3576)) [URL]/googleapis/java-cloud-bom/commit/5f159606e4f818a514a1184ad0f234c1dde69035)) * update dependency com.google.cloud:google-cloud-policy-troubleshooter to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-profiler-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3513)) [URL]/googleapis/java-cloud-bom/commit/05e90621ebdc7100707f8728194c0ca4259a09f5)) * update dependency com.google.cloud:google-cloud-pubsub-bom to v1.115.2 [URL]/googleapis/java-cloud-bom/issues/3514)) [URL]/googleapis/java-cloud-bom/commit/95cb1b96555980552e288d680c60cd9e8e4fdd14)) * update dependency com.google.cloud:google-cloud-pubsublite-bom to v1.4.9 [URL]/googleapis/java-cloud-bom/issues/3583)) [URL]/googleapis/java-cloud-bom/commit/239a0ca4ad3d2cc3e7d70b92484246ce50123f15)) * update dependency com.google.cloud:google-cloud-recaptchaenterprise-bom to v2.4.1 [URL]/googleapis/java-cloud-bom/issues/3515)) [URL]/googleapis/java-cloud-bom/commit/f565b5d8a7a15d89bda3f6b8779169de0ea39006)) * update dependency com.google.cloud:google-cloud-recommender-bom to v2.2.0 [URL]/googleapis/java-cloud-bom/issues/3551)) [URL]/googleapis/java-cloud-bom/commit/4ec6cd034225267cb71092b74a7a6fa737a4e868)) * update dependency com.google.cloud:google-cloud-redis-bom to v2.2.0 [URL]/googleapis/java-cloud-bom/issues/3592)) [URL]/googleapis/java-cloud-bom/commit/525ab66ece3c72d9529c3f1d43518809f041ac85)) * update dependency com.google.cloud:google-cloud-resource-settings-bom to v1.1.6 [URL]/googleapis/java-cloud-bom/issues/3516)) [URL]/googleapis/java-cloud-bom/commit/5414c6588cb45f143dac0c36635bd3f6d35e5d24)) * update dependency com.google.cloud:google-cloud-resourcemanager-bom to v1.2.2 [URL]/googleapis/java-cloud-bom/issues/3517)) [URL]/googleapis/java-cloud-bom/commit/30c5958c1d62a83f038870d565a3478a01d437bd)) * update dependency com.google.cloud:google-cloud-retail-bom to v2.0.8 [URL]/googleapis/java-cloud-bom/issues/3536)) [URL]/googleapis/java-cloud-bom/commit/a44096fa49b61685ef2cb22b13c92f46d8b9d37a)) * update dependency com.google.cloud:google-cloud-scheduler-bom to v2.1.12 [URL]/googleapis/java-cloud-bom/issues/3537)) [URL]/googleapis/java-cloud-bom/commit/e1845de0e83b6b81773b7c04a676607479cb7f0e)) * update dependency com.google.cloud:google-cloud-secretmanager-bom to v2.1.0 [URL]/googleapis/java-cloud-bom/issues/3552)) [URL]/googleapis/java-cloud-bom/commit/00c41a78a9ad8771d3b6e7a336450d312fe83dbd)) * update dependency com.google.cloud:google-cloud-security-private-ca-bom to v2.2.3 [URL]/googleapis/java-cloud-bom/issues/3538)) [URL]/googleapis/java-cloud-bom/commit/cde364768e0f13b886003a5b6bc0d0b657f6f05f)) * update dependency com.google.cloud:google-cloud-securitycenter-bom to v2.4.0 [URL]/googleapis/java-cloud-bom/issues/3553)) [URL]/googleapis/java-cloud-bom/commit/4bd76f12429f03cbb07368dc683082edbb7f5468)) * update dependency com.google.cloud:google-cloud-service-control-bom to v1.1.6 [URL]/googleapis/java-cloud-bom/issues/3577)) [URL]/googleapis/java-cloud-bom/commit/da41ede1573c6243f428fa270d40c8be278fdf79)) * update dependency com.google.cloud:google-cloud-service-management-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3578)) [URL]/googleapis/java-cloud-bom/commit/8df77cd623dcef63b461a3e3b170a9c184650fa6)) * update dependency com.google.cloud:google-cloud-service-usage-bom to v2.2.2 [URL]/googleapis/java-cloud-bom/issues/3579)) [URL]/googleapis/java-cloud-bom/commit/3a4e217b4915433494fb38d55d213a4a670f4962)) * update dependency com.google.cloud:google-cloud-servicedirectory-bom to v2.2.3 [URL]/googleapis/java-cloud-bom/issues/3539)) [URL]/googleapis/java-cloud-bom/commit/21b387ffdbe966091b8090aa741be5a49492cd19)) * update dependency com.google.cloud:google-cloud-shell-bom to v2.1.8 [URL]/googleapis/java-cloud-bom/issues/3540)) [URL]/googleapis/java-cloud-bom/commit/8ffef010eaf638e2b95d756f36192be2729430d3)) * update dependency com.google.cloud:google-cloud-spanner-bom to v6.18.0 [URL]/googleapis/java-cloud-bom/issues/3584)) [URL]/googleapis/java-cloud-bom/commit/5840ecb4f58f74fc84b2c32d08a41e37a45cb28b)) * update dependency com.google.cloud:google-cloud-spanner-jdbc to v2.5.8 [URL]/googleapis/java-cloud-bom/issues/3471)) [URL]/googleapis/java-cloud-bom/commit/3bcba61d0e5fb1417d8e18af5785e95cbbdc765c)) * update dependency com.google.cloud:google-cloud-spanner-jdbc to v2.5.9 [URL]/googleapis/java-cloud-bom/issues/3541)) [URL]/googleapis/java-cloud-bom/commit/c321a3927db00e80d794dec89ba8cc8dcf2d8d7f)) * update dependency com.google.cloud:google-cloud-speech-bom to v2.2.3 [URL]/googleapis/java-cloud-bom/issues/3542)) [URL]/googleapis/java-cloud-bom/commit/20b73b4ef36f0fc49e351a8018c723f1db8f4290)) * update dependency com.google.cloud:google-cloud-storage to v2.3.0 [URL]/googleapis/java-cloud-bom/issues/3481)) [URL]/googleapis/java-cloud-bom/commit/0f2302757abdbdd96669334572b51319ea2db270)) * update dependency com.google.cloud:google-cloud-storage to v2.4.0 [URL]/googleapis/java-cloud-bom/issues/3554)) [URL]/googleapis/java-cloud-bom/commit/6e5ef424d68b072a3647ce7a85827a80c72a1258)) * update dependency com.google.cloud:google-cloud-storage-transfer to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-talent-bom to v2.2.5 [URL]/googleapis/java-cloud-bom/issues/3543)) [URL]/googleapis/java-cloud-bom/commit/c68f7cae59778ddacb3f1f8d85fc9ccd8bff0f6d)) * update dependency com.google.cloud:google-cloud-tasks-bom to v2.1.2 [URL]/googleapis/java-cloud-bom/issues/3544)) [URL]/googleapis/java-cloud-bom/commit/528309e483d8782ce06ecc85dba3aa821214cd88)) * update dependency com.google.cloud:google-cloud-texttospeech-bom to v2.1.2 [URL]/googleapis/java-cloud-bom/issues/3545)) [URL]/googleapis/java-cloud-bom/commit/3c864acc80eedf275baa20cdfc24e437f4dc4a45)) * update dependency com.google.cloud:google-cloud-tpu-bom to v2.2.2 [URL]/googleapis/java-cloud-bom/issues/3589)) [URL]/googleapis/java-cloud-bom/commit/f9645374235cc72e053cf1f2d539ca5a865a5b06)) * update dependency com.google.cloud:google-cloud-trace-bom to v2.1.2 [URL]/googleapis/java-cloud-bom/issues/3550)) [URL]/googleapis/java-cloud-bom/commit/079fbd23b5a29b9ae7be4856872e3aef05eea09e)) * update dependency com.google.cloud:google-cloud-translate-bom to v2.1.10 [URL]/googleapis/java-cloud-bom/issues/3518)) [URL]/googleapis/java-cloud-bom/commit/03abf3969a6f13d4570669268039c03f77498dce)) * update dependency com.google.cloud:google-cloud-video-intelligence-bom to v2.0.14 [URL]/googleapis/java-cloud-bom/issues/3473)) [URL]/googleapis/java-cloud-bom/commit/a900b42f937f465c57658d39a446eaf2ef43f2f9)) * update dependency com.google.cloud:google-cloud-video-intelligence-bom to v2.0.15 [URL]/googleapis/java-cloud-bom/issues/3519)) [URL]/googleapis/java-cloud-bom/commit/e05fba40ff2568c083c98555e553445207a80aca)) * update dependency com.google.cloud:google-cloud-video-transcoder to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-vision-bom to v2.0.18 [URL]/googleapis/java-cloud-bom/issues/3470)) [URL]/googleapis/java-cloud-bom/commit/313d3af99faba8a761cff664c3e565372ec64cdd)) * update dependency com.google.cloud:google-cloud-vision-bom to v2.0.19 [URL]/googleapis/java-cloud-bom/issues/3567)) [URL]/googleapis/java-cloud-bom/commit/161197c43adba44d202497bd6d5b88bf2894b66a)) * update dependency com.google.cloud:google-cloud-vmmigration to v1.0.0 [URL]/googleapis/java-cloud-bom/commit/71b697306abcd70649591984ee9b7a4e780c67e0)) * update dependency com.google.cloud:google-cloud-vpcaccess-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3520)) [URL]/googleapis/java-cloud-bom/commit/dd6d2a0dcc869e249faeff45e6fcfd3371fbbad4)) * update dependency com.google.cloud:google-cloud-webrisk-bom to v2.0.9 [URL]/googleapis/java-cloud-bom/issues/3521)) [URL]/googleapis/java-cloud-bom/commit/68e8e5b0dcefe810eb93f53e9f140afff2cd5c36)) * update dependency com.google.cloud:google-cloud-websecurityscanner-bom to v2.0.10 [URL]/googleapis/java-cloud-bom/issues/3522)) [URL]/googleapis/java-cloud-bom/commit/21407ba766108980448a24761fe78113bdcd1b69)) * update dependency com.google.cloud:google-cloud-workflow-executions-bom to v2.1.2 [URL]/googleapis/java-cloud-bom/issues/3523)) [URL]/googleapis/java-cloud-bom/commit/eec9ee506eae9b1e6cee555607aefed883527c5d)) * update dependency com.google.cloud:google-cloud-workflows-bom to v2.1.6 [URL]/googleapis/java-cloud-bom/issues/3580)) [URL]/googleapis/java-cloud-bom/commit/0b96f98a4512d2bee8c43ee20f1a9c1c796bc2c0)) * update dependency com.google.cloud:google-iam-admin-bom to v1.1.2 [URL]/googleapis/java-cloud-bom/issues/3568)) [URL]/googleapis/java-cloud-bom/commit/4cfc5143e88c07611281a124112794cf016f4d33))  --- This PR was generated with [Release [URL]/googleapis/release-please). See [URL]/googleapis/release-please#release-please).,0,0
"go/printer, gofmt: improved comma placement  Not a Go 1 issue, but appeared to be fairly easy to fix.  - Note that a few existing test cases look slightly worse but   those cases were not representative for real code. All real   code looks better now.  - Manual move of the comment in go/scanner/example_test.go   before applying gofmt.  - gofmt -w $GOROOT/src $GOROOT/misc  Fixes issue 3062.  R=rsc CC=golang-dev [URL]/5674093",0,0
Developed method for solving the bottom cross  Sketch uses 16996 bytes (52%) of program storage space. Global variables use 688 bytes (33%) of dynamic memory,0,1
"cpumask: prepare for iterators to only go to nr_cpu_ids/nr_cpumask_bits.: parisc  Impact: cleanup, futureproof  In fact, all cpumask ops will only be valid (in general) for bit numbers < nr_cpu_ids.  So use that instead of NR_CPUS in various places.  This is always safe: no cpu number can be >= nr_cpu_ids, and nr_cpu_ids is initialized to NR_CPUS at boot.",0,0
KVM: x86: Improve thread safety in pit  commit 2febc839133280d5a5e8e1179c94ea674489dae2 upstream.  There's a race condition in the PIT emulation code in KVM.  In __kvm_migrate_pit_timer the pit_timer object is accessed without synchronization.  If the race condition occurs at the wrong time this can crash the host kernel.  This fixes CVE-2014-3611.,0,0
Added description to StructuredCoalescentTree and corrected times to be positive. Improved example figure (in beast-graphics) to draw 6 random structured coalescent trees on the same individuals and the same time scale.,0,0
"power: pm8921-bms: Update the FCC learning algorithm  1. Add configurable parameters to 	- enable/disable fcc learning 	- minimum soc to start FCC learning 	- minimum ocv (pc) to start FCC learning 	- minimum cycles to update fcc vs temp. table  2. New FCC is calculated using the cc count- 	FCC_NEW = (cc_end - cc_start) / (soc2 - soc1) 	cc_end = CC count when charing ends 	cc_start = CC count when charging starts 	soc1, soc2 = starting and ending SOC_rbatt value  3. Add a new sysfs entries to update the learnt fcc values    to userspace. These values are restored back on    reboot.  CRs-Fixed: 417288",0,0
dynamic-threads: remove all pipe communication and start threads only when needed (unstable). only camd3 and newcamd working so far.,0,0
Added to the card management interface and stubbed out an in-memory implementation.,0,0
"Emergency backout of rev 1.152.  This is a 100% guaranteed way to totally hose your system.  You end up with just about everything statically linked (except for libpam.so), which then causes all the pam users to fail. eg: login, sshd, su etc all stop working because dlopen no longer works because there is no libc.so in memory anymore.  gcc passes -L/usr/lib to ld.  The /usr/lib/libxxx.so symlink is *not* a compatability link.  It is actually the primary link.  There should be no symlinks in /lib at all.  Only /lib/libXX.so.Y.   [9:27pm]/usr/bin-104> file yppasswd yppasswd: setuid ELF 32-bit LSB executable, Intel 80386, version 1 (FreeBSD), for FreeBSD 5.1.1, dynamically linked (uses shared libs), stripped  [9:27pm]/usr/bin-105> ldd yppasswd yppasswd:         libpam.so.2 => /usr/lib/libpam.so.2 (0x280d1000)  [9:28pm]/usr/bin-106>  Note no libc.so.5.  Hence libpam.so.2 has unresolved dependencies.  I believe this is also the cause of the recent buildworld failures when pam_krb5.so references -lcrypto stuff etc and when librpcsvc.so references des_setparity() etc.  This change could not possibly have worked, unless there are other missing changes to the gcc configuration.  It won't work with ports versions of gcc either.",0,0
"Added stack testing program pushpop.s Added char view for memory, use 'mb' at prompt. Added support for labels in DATA to put a symbol in the table but not save anything. Fixed bug in STRB,STRH trying to save words instead of their respective sizes.",0,0
PG-1285: Made change to prevent exception when changing versification causes chapter change.ChangeToEnglishVersification.  Note: decided against trying for a more efficient approach to only changing the versification once since I couldn't come up with one that seemed certain to be more efficient and would also leave the code clean and readable.,0,0
Merge branch 'sprint-1' into ignite-128  Conflicts: 	examples/src/main/java/org/apache/ignite/examples/datagrid/hibernate/HibernateL2CacheExampleNodeStartup.java 	modules/clients/src/test/java/org/apache/ignite/client/ClientPutPortableTask.java 	modules/clients/src/test/java/org/apache/ignite/client/integration/package.html 	modules/clients/src/test/java/org/apache/ignite/client/router/package.html 	modules/clients/src/test/java/org/apache/ignite/internal/TaskEventSubjectIdSelfTest.java 	modules/clients/src/test/java/org/apache/ignite/internal/client/ClientPortableArgumentTask.java 	modules/clients/src/test/java/org/apache/ignite/internal/client/ClientPutPortableTask.java 	modules/clients/src/test/java/org/apache/ignite/internal/client/ClientTestPortable.java 	modules/clients/src/test/java/org/apache/ignite/internal/client/ClientTestPortableAffinityKeyTask.java 	modules/clients/src/test/java/org/apache/ignite/internal/client/integration/ClientAbstractSelfTest.java 	modules/clients/src/test/java/org/apache/ignite/internal/processors/rest/RestBinaryProtocolSelfTest.java 	modules/clients/src/test/java/org/apache/ignite/internal/processors/rest/RestProcessorMultiStartSelfTest.java 	modules/clients/src/test/java/org/apache/ignite/internal/processors/rest/TaskCommandHandlerSelfTest.java 	modules/clients/src/test/java/org/apache/ignite/internal/processors/rest/TestBinaryClient.java 	modules/clients/src/test/java/org/apache/ignite/jdbc/JdbcComplexQuerySelfTest.java 	modules/clients/src/test/java/org/apache/ignite/jdbc/JdbcEmptyCacheSelfTest.java 	modules/clients/src/test/java/org/apache/ignite/jdbc/JdbcLocalCachesSelfTest.java 	modules/clients/src/test/java/org/apache/ignite/jdbc/JdbcMetadataSelfTest.java 	modules/clients/src/test/java/org/apache/ignite/jdbc/JdbcPreparedStatementSelfTest.java 	modules/clients/src/test/java/org/apache/ignite/jdbc/JdbcResultSetSelfTest.java 	modules/clients/src/test/java/org/apache/ignite/jdbc/JdbcStatementSelfTest.java 	modules/clients/src/test/java/org/apache/ignite/loadtests/client/ClientTcpSslLoadTest.java 	modules/clients/src/test/resources/spring-cache.xml 	modules/clients/src/test/resources/spring-server-node.xml 	modules/clients/src/test/resources/spring-server-ssl-node.xml 	modules/core/src/main/java/org/apache/ignite/IgniteBasicWarmupClosure.java 	modules/core/src/main/java/org/apache/ignite/client/balancer/package.html 	modules/core/src/main/java/org/apache/ignite/client/impl/package.html 	modules/core/src/main/java/org/apache/ignite/client/marshaller/jdk/package.html 	modules/core/src/main/java/org/apache/ignite/client/marshaller/optimized/package.html 	modules/core/src/main/java/org/apache/ignite/client/marshaller/package.html 	modules/core/src/main/java/org/apache/ignite/client/package.html 	modules/core/src/main/java/org/apache/ignite/client/router/impl/package.html 	modules/core/src/main/java/org/apache/ignite/client/router/package.html 	modules/core/src/main/java/org/apache/ignite/client/ssl/package.html 	modules/core/src/main/java/org/apache/ignite/client/util/package.html 	modules/core/src/main/java/org/apache/ignite/configuration/ConnectorConfiguration.java 	modules/core/src/main/java/org/apache/ignite/configuration/IgniteConfiguration.java 	modules/core/src/main/java/org/apache/ignite/internal/IgniteKernal.java 	modules/core/src/main/java/org/apache/ignite/internal/IgnitionEx.java 	modules/core/src/main/java/org/apache/ignite/internal/client/GridClientCompute.java 	modules/core/src/main/java/org/apache/ignite/internal/client/GridClientConfiguration.java 	modules/core/src/main/java/org/apache/ignite/internal/client/impl/GridClientComputeImpl.java 	modules/core/src/main/java/org/apache/ignite/internal/client/impl/GridClientImpl.java 	modules/core/src/main/java/org/apache/ignite/internal/client/impl/connection/GridClientConnectionManagerAdapter.java 	modules/core/src/main/java/org/apache/ignite/internal/client/marshaller/optimized/GridClientOptimizedMarshaller.java 	modules/core/src/main/java/org/apache/ignite/internal/processors/portable/GridPortableProcessor.java 	modules/core/src/main/java/org/apache/ignite/internal/processors/portable/os/GridOsPortableProcessor.java 	modules/core/src/main/java/org/apache/ignite/internal/processors/rest/GridRestProcessor.java 	modules/core/src/main/java/org/apache/ignite/internal/processors/rest/client/message/GridClientLogRequest.java 	modules/core/src/main/java/org/apache/ignite/internal/processors/rest/handlers/log/GridLogCommandHandler.java 	modules/core/src/main/java/org/apache/ignite/internal/processors/rest/handlers/log/package.html 	modules/core/src/main/java/org/apache/ignite/internal/processors/rest/protocols/tcp/GridTcpRestDirectParser.java 	modules/core/src/main/java/org/apache/ignite/internal/visor/node/VisorExecutorServiceConfiguration.java 	modules/core/src/test/config/default-spring-url-testing.xml 	modules/core/src/test/config/example-cache.xml 	modules/core/src/test/config/io-manager-benchmark.xml 	modules/core/src/test/config/job-loadtest/client.xml 	modules/core/src/test/config/job-loadtest/server.xml 	modules/core/src/test/config/jobs-load-base.xml 	modules/core/src/test/config/load/cache-benchmark.xml 	modules/core/src/test/config/load/cache-client-benchmark.xml 	modules/core/src/test/config/load/dsi-load-base.xml 	modules/core/src/test/config/load/merge-sort-base.xml 	modules/core/src/test/config/loaders/grid-cfg-2-grids.xml 	modules/core/src/test/config/loaders/grid-cfg.xml 	modules/core/src/test/config/spring-cache-put-remove-load.xml 	modules/core/src/test/config/spring-start-nodes-attr.xml 	modules/core/src/test/config/spring-start-nodes.xml 	modules/core/src/test/config/streamer/spring-streamer-base.xml 	modules/core/src/test/config/websession/spring-cache-1.xml 	modules/core/src/test/config/websession/spring-cache-2.xml 	modules/core/src/test/config/websession/spring-cache-3.xml 	modules/core/src/test/java/org/apache/ignite/internal/GridDiscoveryEventSelfTest.java 	modules/core/src/test/java/org/apache/ignite/internal/GridStartStopSelfTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/cache/GridCacheDaemonNodeAbstractSelfTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/cache/GridCacheDeploymentSelfTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/cache/GridCacheLuceneQueryIndexTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/cache/datastructures/GridCacheQueueMultiNodeAbstractSelfTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/cache/distributed/GridCacheMultithreadedFailoverAbstractTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/cache/distributed/GridCachePreloadLifecycleAbstractTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/cache/distributed/near/GridCacheNearReaderPreloadSelfTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/cache/distributed/near/GridCachePartitionedLockSelfTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/dataload/GridDataLoaderPerformanceTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/fs/GridCacheGgfsPerBlockLruEvictionPolicySelfTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/fs/GridGgfsAbstractSelfTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/fs/GridGgfsModesSelfTest.java 	modules/core/src/test/java/org/apache/ignite/internal/processors/rest/handlers/cache/GridCacheCommandHandlerSelfTest.java 	modules/core/src/test/java/org/apache/ignite/internal/util/GridStartupWithUndefinedIgniteHomeSelfTest.java 	modules/core/src/test/java/org/apache/ignite/spi/GridTcpSpiForwardingSelfTest.java 	modules/core/src/test/java/org/apache/ignite/spi/discovery/tcp/TcpDiscoverySelfTest.java 	modules/core/src/test/java/org/apache/ignite/spi/discovery/tcp/TcpDiscoverySnapshotHistoryTest.java 	modules/core/src/test/java/org/apache/ignite/testframework/junits/GridAbstractTest.java 	modules/hadoop/src/test/java/org/apache/ignite/ignitefs/GridGgfsHadoopDualAbstractSelfTest.java 	modules/hadoop/src/test/java/org/apache/ignite/ignitefs/GridGgfsHadoopFileSystemHandshakeSelfTest.java 	modules/hadoop/src/test/java/org/apache/ignite/ignitefs/GridGgfsHadoopFileSystemLoggerStateSelfTest.java 	modules/hadoop/src/test/java/org/apache/ignite/internal/processors/hadoop/GridHadoopAbstractSelfTest.java 	modules/log4j/src/test/java/org/apache/ignite/logger/log4j/GridLog4jCorrectFileNameTest.java 	modules/spring/src/test/java/org/apache/ignite/internal/GridFactorySelfTest.java 	modules/spring/src/test/java/org/apache/ignite/internal/GridSpringBeanSerializationSelfTest.java 	modules/yardstick/config/ignite-base-config.xml 	modules/yardstick/config/ignite-store-config.xml 	modules/yardstick/src/main/java/org/apache/ignite/yardstick/cache/store/jdbc/IgniteJdbcStoreGetTxBenchmark.java 	pom.xml,0,0
"SWITCHYARD-1314 Message Validator improvement  Contains:  - [URL]/browse/SWITCHYARD-1315 - Return Details of Message Validation Error    -- validate() method returns ValidationResult object, which has getDetail() method to return error details when validation fails  - [URL]/browse/SWITCHYARD-1257 - Support multiple Schemas in XmlValidator    -- added SchemaFiles element in validate.xml to specify multiple schema files and removed schemaFile attribute    -- XmlValidator now supports namespace aware validation as well with setting 'namespaceAware' attribute as true  - [URL]/browse/SWITCHYARD-1312 - Add XML Catalog support to XML Validator    -- added SchemaCatalogs element in validate.xml to specify multiple schema catalogs",0,0
"Roll Skia from 02d77df60e62 to a28795fd64a4 (1 revision)  [URL]/skia.git/+log/02d77df60e62..a28795fd64a4  2021-08-08 [URL] Update SKP version  If this roll has caused a breakage, revert this CL and stop the roller using the controls here: [URL]/r/skia-autoroll Please CC [URL] on the revert to ensure that a human is aware of the problem.  To report a problem with the AutoRoller itself, please file a bug: [URL]/p/skia/issues/entry?template=Autoroller+Bug  Documentation for the AutoRoller is here: [URL]/buildbot/+doc/main/autoroll/README.md  Cq-Include-Trybots: luci.chromium.try:android_optional_gpu_tests_rel;luci.chromium.try:linux-blink-rel;luci.chromium.try:linux-chromeos-compile-dbg;luci.chromium.try:linux_optional_gpu_tests_rel;luci.chromium.try:mac_optional_gpu_tests_rel;luci.chromium.try:win_optional_gpu_tests_rel Cq-Do-Not-Cancel-Tryjobs: true Bug: None Tbr: [URL]",0,0
"Tweaks and bugfixes.  Most of this code will be replaced this week, but hey...  * subversion/libsvn_delta/diff.c    (svn_diff__tree_insert_token): Minor optimization.  We already know the     ordering of the tokens will be incremental when we get them, so we can     safely remove the test to see if there is an offset larger than the     one we are inserting already at the beginning of the list.    (svn_diff__lcs_reverse): Typo in comment.    (svn_diff__lcs): 2 bugfixes.  Correct the determination of 'k'.  Actually     reuse the lcs nodes that aren't needed anymore.  A new node was being     allocated all the time since the pointer to the node to be reused was     being NULL'd.",0,0
implement 'down' part of MARCO algorithm,0,0
"Add handling of scale restrictions for TF ops  This change generalized current design in QuantizationDriver to not only look for FixedOutputRangeInterface and SameScalesOpInterface, but also adds an option to denote scale requirements dynamically. This enables the other dialects to flexibly add the scale requirements without changing the dialect definition  itself.  PiperOrigin-RevId: 435264865",0,0
GBE-438: Let dynamic configuration use a single datastore for all shapefile layers,0,0
"Revert ""r225811 - Revert ""r225808 - [PowerPC] Add StackMap/PatchPoint support""""  This re-applies r225808, fixed to avoid problems with SDAG dependencies along with the preceding fix to ScheduleDAGSDNodes::RegDefIter::InitNodeNumDefs. These problems caused the original regression tests to assert/segfault on many (but not all) systems.  Original commit message:  This commit does two things:   1. Refactors PPCFastISel to use more of the common infrastructure for call     lowering (this lets us take advantage of this common code for lowering some     common intrinsics, stackmap/patchpoint among them).   2. Adds support for stackmap/patchpoint lowering. For the most part, this is     very similar to the support in the AArch64 target, with the obvious differences     (different registers, NOP instructions, etc.). The test cases are adapted     from the AArch64 test cases.  One difference of note is that the patchpoint call sequence takes 24 bytes, so you can't use less than that (on AArch64 you can go down to 16). Also, as noted in the docs, we take the patchpoint address to be the actual code address (assuming the call is local in the TOC-sharing sense), which should yield higher performance than generating the full cross-DSO indirect-call sequence and is likely just as useful for JITed code (if not, we'll change it).  StackMaps and Patchpoints are still marked as experimental, and so this support is doubly experimental. So go ahead and experiment!",0,0
Track the original assets more efficiently in Phase.  [URL] BUG=  Review URL: [URL]//26598002,0,0
sal: PVS-Studio V611 memory was allocated using 'new T[]' operator  ... but was released using the 'delete' operator,0,0
"netns: let net_generic take pointer-to-const args  This commit is same in nature as v2.6.37-rc1-755-g3654654; the network namespace itself is not modified when calling net_generic, so the parameter can be const.",0,0
Run msvc analysis with single CPU  Hopefully this avoids out of heap memory errors.,0,0
ARM: Exynos: switch to using generic cpufreq driver for Exynos5250  The new CPU clock type allows the use of generic CPUfreq driver. Switch Exynos5250 to using generic cpufreq driver.  Changes by Bartlomiej: - split Exynos5250 support from the original patch  Cc: Tomasz Figa [URL]> Cc: Kukjin Kim [URL]> Cc: Javier Martinez Canillas < > Cc: Chander Kashyap [URL]>,0,0
"memory: emif: Add Kconfig dependency for TI EMIF controller  Make TI_EMIF depends on ARCH_OMAP2PLUS to avoid build breaks on other architectures. In future if other TI non OMAP socs start using it, the dependency can be extended.",0,0
Update Test Password Entry with Validation with verifying match - parameterized fixlet - Universal.bes  optimizing 2nd relevance query. Needs tested.,0,0
Add warning in docs on performance when using EXSLT regexp functions,0,0
Improve the error message for noIdentity,0,0
"Merge pull request #99 from Daniel-at-github/patch-scipy-2016  scipy 2016, merge and improve :+1:",0,0
Merge pull request #131 from googlegenomics/staging-2  Initial v1beta2 -> v1 migration guide,0,0
:  remco | 2007-02-16 14:09:32 +0100  improve test,0,0
"ipq40xx: wpj428: fix missing MDIO GPIO reset and pinmux  The bootloader does not always initialize the MDIO pins before booting Linux. E.g. on version ""U-Boot 2012.07 [Chaos Calmer 15.05.1,r35193] (Jul 25 2017 - 11:36:26)"" this is the case when booting automatically without activating the U-Boot console.  Without this change, the kernel boot will complain about missing PHYs:   libphy: ipq40xx_mdio: probed  ar40xx c000000.ess-switch: Probe failed - Missing PHYs!  libphy: Fixed MDIO Bus: probed  With this change it will work as expected:   libphy: ipq40xx_mdio: probed  ESS reset ok!  ESS reset ok!  libphy: Fixed MDIO Bus: probed  Ref: GH-2835 Tested-by: Fredrik Olofsson [URL]>",0,0
"acpuclock: Set 192mhz min freq, also deactivate some unused Frequencies like in my 4.2.2 Kernel.",0,0
"catch exceptions on webhook, DriverException, improve template compilation",0,0
"(PDB-4895) storage: add a few new type annotations  These aren't likely performance critical, but were noticed when examining the input hashing performance and won't hurt.  Though this doesn't fix all the reflection warnings.  I left some date operations alone for now.",0,0
chore(Errors): Slighly improve descriptions of errors shown to the users (#2293),0,0
Minor improvement to README. Supervisor should now work. Resolves #11,0,0
Merge pull request #2567 from nonifier/filter_journeys_before_fallback  Jormun: Filter journeys before streetnetwork fallback [Distributed],0,0
"some clearification in the readme, nicer output  changed to clang to produce better looking assembly (it seems clang helps on performance as well)",0,1
"Add both IPv4 and IPv6 DHCP options if interface has both  It is possible that an interface has both IPv4 and IPv6 addresses, primarily when using SLAAC with OpenStack Neutron.  When this is the case, it is very likely that the first fixed IP would be a SLAAC assigned port and the second IP is the IPv4 address.  In an environment where you are looking to boot via IPv4, no DHCPv6 infrastructure exists as IPv6 connectivity is provided via SLAAC, you would not be able to use this network to boot off of.  This patch instead grabs all the fixed IP addresses, then inserts the options that match the IP versions which are attached to the interface, potentially resulting in both IPv4 and IPv6 options being included (though the IPv6 ones would be largely omitted).  In environments where only IPv4 or IPv6 is in use on the port, it will still only insert the options for those specific IP versions.  Story #2008660 Task #41933",0,0
Rewrote some things and improved errors,0,0
"*** EFM32 branch *** 1. Remove ""RT_USING_NETUTILS"" defined in ""rtconfig.h"" to avoid compiling error    - Warning: Due to the memory limitation, running lwIP on Gecko devices (EFM32G) is not properly tested.    - Warning: To test lwIP, please revert the file, ""components etlwipsrcarchsys_arch.c"", to revision 1620. There is a runtime error when working with the latest revision of that file. This error is currently under evaluation.",0,0
Make Graphite Optimizations a config option to easily enable/disable it,0,0
"mm: hugetlbfs: close race during teardown of hugetlbfs shared page tables  If a process creates a large hugetlbfs mapping that is eligible for page table sharing and forks heavily with children some of whom fault and others which destroy the mapping then it is possible for page tables to get corrupted.  Some teardowns of the mapping encounter a ""bad pmd"" and output a message to the kernel log.  The final teardown will trigger a BUG_ON in mm/filemap.c.  This was reproduced in 3.4 but is known to have existed for a long time and goes back at least as far as 2.6.37.  It was probably was introduced in 2.6.20 by [39dde65c: shared page table for hugetlb page].  The messages look like this;  [  ..........] Lots of bad pmd messages followed by this [  127.164256] mm/memory.c:391: bad pmd ffff880412e04fe8(80000003de4000e7). [  127.164257] mm/memory.c:391: bad pmd ffff880412e04ff0(80000003de6000e7). [  127.164258] mm/memory.c:391: bad pmd ffff880412e04ff8(80000003de0000e7). [  127.186778] ------------[ cut here ]------------ [  127.186781] kernel BUG at mm/filemap.c:134! [  127.186782] invalid opcode: 0000 [#1] SMP [  127.186783] CPU 7 [  127.186784] Modules linked in: af_packet cpufreq_conservative cpufreq_userspace cpufreq_powersave acpi_cpufreq mperf ext3 jbd dm_mod coretemp crc32c_intel usb_storage ghash_clmulni_intel aesni_intel i2c_i801 r8169 mii uas sr_mod cdrom sg iTCO_wdt iTCO_vendor_support shpchp serio_raw cryptd aes_x86_64 e1000e pci_hotplug dcdbas aes_generic container microcode ext4 mbcache jbd2 crc16 sd_mod crc_t10dif i915 drm_kms_helper drm i2c_algo_bit ehci_hcd ahci libahci usbcore rtc_cmos usb_common button i2c_core intel_agp video intel_gtt fan processor thermal thermal_sys hwmon ata_generic pata_atiixp libata scsi_mod [  127.186801] [  127.186802] Pid: 9017, comm: hugetlbfs-test Not tainted 3.4.0-autobuild #53 Dell Inc. OptiPlex 990/06D7TR [  127.186804] RIP: 0010:[<ffffffff810ed6ce>]  [<ffffffff810ed6ce>] __delete_from_page_cache+0x15e/0x160 [  127.186809] RSP: 0000:ffff8804144b5c08  EFLAGS: 00010002 [  127.186810] RAX: 0000000000000001 RBX: ffffea000a5c9000 RCX: 00000000ffffffc0 [  127.186811] RDX: 0000000000000000 RSI: 0000000000000009 RDI: ffff88042dfdad00 [  127.186812] RBP: ffff8804144b5c18 R08: 0000000000000009 R09: 0000000000000003 [  127.186813] R10: 0000000000000000 R11: 000000000000002d R12: ffff880412ff83d8 [  127.186814] R13: ffff880412ff83d8 R14: 0000000000000000 R15: ffff880412ff83d8 [  127.186815] FS:  00007fe18ed2c700(0000) GS:ffff88042dce0000(0000) knlGS:0000000000000000 [  127.186816] CS:  0010 DS: 0000 ES: 0000 CR0: 000000008005003b [  127.186817] CR2: 00007fe340000503 CR3: 0000000417a14000 CR4: 00000000000407e0 [  127.186818] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000 [  127.186819] DR3: 0000000000000000 DR6: 00000000ffff0ff0 DR7: 0000000000000400 [  127.186820] Process hugetlbfs-test (pid: 9017, threadinfo ffff8804144b4000, task ffff880417f803c0) [  127.186821] Stack: [  127.186822]  ffffea000a5c9000 0000000000000000 ffff8804144b5c48 ffffffff810ed83b [  127.186824]  ffff8804144b5c48 000000000000138a 0000000000001387 ffff8804144b5c98 [  127.186825]  ffff8804144b5d48 ffffffff811bc925 ffff8804144b5cb8 0000000000000000 [  127.186827] Call Trace: [  127.186829]  [<ffffffff810ed83b>] delete_from_page_cache+0x3b/0x80 [  127.186832]  [<ffffffff811bc925>] truncate_hugepages+0x115/0x220 [  127.186834]  [<ffffffff811bca43>] hugetlbfs_evict_inode+0x13/0x30 [  127.186837]  [<ffffffff811655c7>] evict+0xa7/0x1b0 [  127.186839]  [<ffffffff811657a3>] iput_final+0xd3/0x1f0 [  127.186840]  [<ffffffff811658f9>] iput+0x39/0x50 [  127.186842]  [<ffffffff81162708>] d_kill+0xf8/0x130 [  127.186843]  [<ffffffff81162812>] dput+0xd2/0x1a0 [  127.186845]  [<ffffffff8114e2d0>] __fput+0x170/0x230 [  127.186848]  [<ffffffff81236e0e>] ? rb_erase+0xce/0x150 [  127.186849]  [<ffffffff8114e3ad>] fput+0x1d/0x30 [  127.186851]  [<ffffffff81117db7>] remove_vma+0x37/0x80 [  127.186853]  [<ffffffff81119182>] do_munmap+0x2d2/0x360 [  127.186855]  [<ffffffff811cc639>] sys_shmdt+0xc9/0x170 [  127.186857]  [<ffffffff81410a39>] system_call_fastpath+0x16/0x1b [  127.186858] Code: 0f 1f 44 00 00 48 8b 43 08 48 8b 00 48 8b 40 28 8b b0 40 03 00 00 85 f6 0f 88 df fe ff ff 48 89 df e8 e7 cb 05 00 e9 d2 fe ff ff <0f> 0b 55 83 e2 fd 48 89 e5 48 83 ec 30 48 89 5d d8 4c 89 65 e0 [  127.186868] RIP  [<ffffffff810ed6ce>] __delete_from_page_cache+0x15e/0x160 [  127.186870]  RSP <ffff8804144b5c08> [  127.186871] ---[ end trace 7cbac5d1db69f426 ]---  The bug is a race and not always easy to reproduce.  To reproduce it I was doing the following on a single socket I7-based machine with 16G of RAM.  $ hugeadm --pool-pages-max DEFAULT:13G $ echo $((18*1048576*1024)) > /proc/sys/kernel/shmmax $ echo $((18*1048576*1024)) > /proc/sys/kernel/shmall $ for i in `seq 1 9000`; do ./hugetlbfs-test; done  On my particular machine, it usually triggers within 10 minutes but enabling debug options can change the timing such that it never hits. Once the bug is triggered, the machine is in trouble and needs to be rebooted.  The machine will respond but processes accessing proc like ""ps aux"" will hang due to the BUG_ON.  shutdown will also hang and needs a hard reset or a sysrq-b.  The basic problem is a race between page table sharing and teardown.  For the most part page table sharing depends on i_mmap_mutex.  In some cases, it is also taking the mm->page_table_lock for the PTE updates but with shared page tables, it is the i_mmap_mutex that is more important.  Unfortunately it appears to be also insufficient. Consider the following situation  Process A					Process B ---------					--------- hugetlb_fault					shmdt   						LockWrite(mmap_sem)     						  do_munmap 						    unmap_region 						      unmap_vmas 						        unmap_single_vma 						          unmap_hugepage_range       						            Lock(i_mmap_mutex) 							    Lock(mm->page_table_lock) 							    huge_pmd_unshare/unmap tables <--- (1) 							    Unlock(mm->page_table_lock)       						            Unlock(i_mmap_mutex)   huge_pte_alloc				      ...     Lock(i_mmap_mutex)				      ...     vma_prio_walk, find svma, spte		      ...     Lock(mm->page_table_lock)			      ...     share spte					      ...     Unlock(mm->page_table_lock)			      ...     Unlock(i_mmap_mutex)			      ...   hugetlb_no_page									  <--- (2) 						      free_pgtables 						        unlink_file_vma 							hugetlb_free_pgd_range 						    remove_vma_list  In this scenario, it is possible for Process A to share page tables with Process B that is trying to tear them down.  The i_mmap_mutex on its own does not prevent Process A walking Process B's page tables.  At (1) above, the page tables are not shared yet so it unmaps the PMDs.  Process A sets up page table sharing and at (2) faults a new entry.  Process B then trips up on it in free_pgtables.  This patch fixes the problem by adding a new function __unmap_hugepage_range_final that is only called when the VMA is about to be destroyed.  This function clears VM_MAYSHARE during unmap_hugepage_range() under the i_mmap_mutex.  This makes the VMA ineligible for sharing and avoids the race.  Superficially this looks like it would then be vunerable to truncate and madvise issues but hugetlbfs has its own truncate handlers so does not use unmap_mapping_range() and does not support madvise(DONTNEED).  This should be treated as a -stable candidate if it is merged.  Test program is as follows. The test case was mostly written by Michal Hocko with a few minor changes to reproduce this bug.  ==== CUT HERE ====  static size_t huge_page_size = (2UL << 20); static size_t nr_huge_page_A = 512; static size_t nr_huge_page_B = 5632;  unsigned int get_random(unsigned int max) { 	struct timeval tv;  	gettimeofday(&tv, NULL); 	srandom(tv.tv_usec); 	return random() % max; }  static void play(void *addr, size_t size) { 	unsigned char *start = addr, 		      *end = start + size, 		      *a; 	start += get_random(size/2);  	/* we could itterate on huge pages but let's give it more time. */ 	for (a = start; a < end; a += 4096) 		*a = 0; }  int main(int argc, char **argv) { 	key_t key = IPC_PRIVATE; 	size_t sizeA = nr_huge_page_A * huge_page_size; 	size_t sizeB = nr_huge_page_B * huge_page_size; 	int shmidA, shmidB; 	void *addrA = NULL, *addrB = NULL; 	int nr_children = 300, n = 0;  	if ((shmidA = shmget(key, sizeA, IPC_CREAT|SHM_HUGETLB|0660)) == -1) { 		perror(""shmget:""); 		return 1; 	}  	if ((addrA = shmat(shmidA, addrA, SHM_R|SHM_W)) == (void *)-1UL) { 		perror(""shmat""); 		return 1; 	} 	if ((shmidB = shmget(key, sizeB, IPC_CREAT|SHM_HUGETLB|0660)) == -1) { 		perror(""shmget:""); 		return 1; 	}  	if ((addrB = shmat(shmidB, addrB, SHM_R|SHM_W)) == (void *)-1UL) { 		perror(""shmat""); 		return 1; 	}  fork_child: 	switch(fork()) { 		case 0: 			switch (n%3) { 			case 0: 				play(addrA, sizeA); 				break; 			case 1: 				play(addrB, sizeB); 				break; 			case 2: 				break; 			} 			break; 		case -1: 			perror(""fork:""); 			break; 		default: 			if (++n < nr_children) 				goto fork_child; 			play(addrA, sizeA); 			break; 	} 	shmdt(addrA); 	shmdt(addrB); 	do { 		wait(NULL); 	} while (--n > 0); 	shmctl(shmidA, IPC_RMID, NULL); 	shmctl(shmidB, IPC_RMID, NULL); 	return 0; }  [URL]: name the declaration's args, fix CONFIG_HUGETLBFS=n build]",0,0
[app] improve treeview  * open/close on double-click * expose open status to label comp,0,0
"several trunc* bugs fixed - to accomplish that, search algorithm was somewhat changed.",0,0
Added new post. Improved Dated Files.,0,0
Improved help output and added -tc list.,0,0
Some styling improvements.  Log In function is coming next,0,0
"perf script: Enable printing of branch stack  This patch improves perf script by enabling printing of the branch stack via the 'brstack' and 'brstacksym' arguments to the field selection option -F. The option is off by default and operates only if the perf.data file has branch stack content.  The branches are printed in to/from pairs. The most recent branch is printed first. The number of branch entries vary based on the underlying hardware and filtering used.  The brstack prints FROM/TO addresses in raw hexadecimal format. The brstacksym prints FROM/TO addresses in symbolic form wherever possible.   $ perf script -F ip,brstack   5d3000 0x401aa0/0x5d2000/M/-/-/-/0 ...   $ perf script -F ip,brstacksym   4011e0 noploop+0x0/noploop+0x0/P/-/-/0  The notation F/T/M/X/A/C describes the attributes of the branch. F=from, T=to, M/P=misprediction/prediction, X=TSX, A=TSX abort, C=cycles (SKL)",0,1
"Core/Spells: Fix potions cooldown in combat  Fix a cooldown issue related to potions allowing Players in combat to use more than 1 potion in a row, especially with high latency. This also fixes an exploit about using infinite potions in combat just by skipping the client-side check. The original implementation c064c2e2e1eebd43b273365583dd181293bafa22 was missing a check in Spell::CheckCast() about this particular case since Potion cooldown is added only after the Player goes out of combat. Fixes #1259 .",0,0
Merge pull request #939 from andrey-helldar/patch-2018-11-10  Visual improvements todo list,0,0
Re-implement socket configurability  This was dropped in the networking overhaul.,0,0
arm: irq: warn only when affinity really breaks  Following change causes unnecessary warnings printed for those IRQ's which are affine to several CPU's when one of these CPU's is taken off line. It shouldn't be considered a broken affinity when one online CPU can satisfy the IRQ's affinity preference.  commit 5bfaecc21018973f73bc4dc839699848b448c0e7 Author: Praveen Chidambaram [URL]> Date:   Mon Jun 23 08:58:08 2014 -0600  arm: irq: Notify affinity change when migrating IRQs during hotplug  Hotplug causes IRQs affine to a core that is being taken down to migrate to an online core. This is done by directly calling the irq_set_affinity associated with the irq_chip structure. Instead using the irq_set_affinity() api lets the notifications bubble through.,0,0
2011-10-18	Jennifer Averett [URL]>  	PR 1917/bsps 	* shared/console/conscfg.c: Modifications to add dynamic tables for 	libchip serial drivers.,0,0
ImageDownload rewritten using QNetworkAccessManager. Images cache moved from Core to ImageDownload.,0,0
"Notebookfixes (#166)  * MAINT make performance table flexible, show only what is needed    * FIX automl-signature + logo    * ADD tabs for budgets    * FIX cmd-line toggle of cfp-timeslider    * ADD explanation to missing plot (alt text), add budgets to docs    * RM irrelevant info from overview-table    * ADD axis labels to bohb plot    * RM Performance Table tag    * ADD color-selection in bohb-plot    * FIX adjust bohb-plot-widget-sizes    * FIX verbose OFF filters everything",0,0
Improved type safety of policy consequence value check,0,0
Improve sharee controller remote user search tests,0,0
Merge pull request #392 from algolia/frontend_templates  Template improvements,0,0
Improved auto-completion  Now you can press tab to choose among incomplete commands.,0,0
Improve math/linalg to support both f32 and f64 basic procedures for the specific*.odin files,0,0
"Added stack testing program pushpop.s Added char view for memory, use 'mb' at prompt. Added support for labels in DATA to put a symbol in the table but not save anything. Fixed bug in STRB,STRH trying to save words instead of their respective sizes.",0,0
"Add support for XFAILing valgrind runs with memory leak checking independently of runs without leak checking.  We add -vg to the triple for non-checked runs, or -vg_leak for checked runs.  Also use this to XFAIL the TableGen tests, since tablegen leaks like a sieve.  This includes some valgrindArgs refactoring.",0,0
